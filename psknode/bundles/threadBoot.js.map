{"version":3,"sources":["node_modules/browser-pack/_prelude.js","builds/tmp/threadBoot.js","builds/tmp/threadBoot_intermediar.js","modules/adler32/lib/Hash.js","modules/adler32/lib/algorithm.js","modules/adler32/lib/register.js","modules/bar-fs-adapter/lib/FsAdapter.js","modules/bar-fs-adapter/lib/PathAsyncIterator.js","modules/bar/lib/Archive.js","modules/bar/lib/ArchiveConfigurator.js","modules/bar/lib/Brick.js","modules/bar/lib/FileBarMap.js","modules/bar/lib/FileBrickStorage.js","modules/bar/lib/FolderBarMap.js","modules/bar/lib/FolderBrickStorage.js","modules/bar/lib/Seed.js","modules/bar/lib/base58.js","modules/bar/lib/transforms/BrickTransform.js","modules/bar/lib/transforms/BrickTransformFactory.js","modules/bar/lib/transforms/CompressionEncryptionGenerator.js","modules/bar/lib/transforms/CompressionGenerator.js","modules/bar/lib/transforms/EncryptionGenerator.js","modules/bar/utils/AsyncDispatcher.js","modules/bar/utils/isStream.js","modules/bar/utils/utilities.js","modules/edfs-brick-storage/EDFSBrickStorage.js","modules/edfs/brickTransportStrategies/FetchBrickTransportStrategy.js","modules/edfs/brickTransportStrategies/HTTPBrickTransportStrategy.js","modules/edfs/brickTransportStrategies/brickTransportStrategiesRegistry.js","modules/edfs/lib/EDFS.js","modules/edfs/lib/RawDossier.js","modules/edfs/moduleConstants.js","modules/edfs/seedCage/BrowserSeedCage.js","modules/edfs/seedCage/NodeSeedCage.js","modules/edfs/seedCage/index.js","modules/overwrite-require/moduleConstants.js","modules/overwrite-require/standardGlobalSymbols.js","modules/psk-cache/lib/Cache.js","modules/psk-http-client/lib/psk-abstract-client.js","modules/psk-http-client/lib/psk-browser-client.js","modules/psk-http-client/lib/psk-node-client.js","modules/pskcrypto/lib/PskCrypto.js","modules/pskcrypto/lib/PskEncryption.js","modules/pskcrypto/lib/utils/DuplexStream.js","modules/pskcrypto/lib/utils/cryptoUtils.js","modules/pskcrypto/lib/utils/isStream.js","modules/pskcrypto/signsensusDS/ssutil.js","modules/swarm-engine/bootScripts/BootEngine.js","modules/swarmutils/lib/Combos.js","modules/swarmutils/lib/OwM.js","modules/swarmutils/lib/Queue.js","modules/swarmutils/lib/SwarmPacker.js","modules/swarmutils/lib/TaskCounter.js","modules/swarmutils/lib/beesHealer.js","modules/swarmutils/lib/path.js","modules/swarmutils/lib/pingpongFork.js","modules/swarmutils/lib/pskconsole.js","modules/swarmutils/lib/safe-uuid.js","modules/swarmutils/lib/uidGenerator.js","node_modules/is-buffer/index.js","node_modules/source-map/lib/array-set.js","node_modules/source-map/lib/base64-vlq.js","node_modules/source-map/lib/base64.js","node_modules/source-map/lib/binary-search.js","node_modules/source-map/lib/mapping-list.js","node_modules/source-map/lib/quick-sort.js","node_modules/source-map/lib/source-map-consumer.js","node_modules/source-map/lib/source-map-generator.js","node_modules/source-map/lib/source-node.js","node_modules/source-map/lib/util.js","modules/adler32/index.js","modules/bar-fs-adapter/index.js","modules/bar/index.js","node_modules/buffer-from/index.js","modules/edfs-brick-storage/index.js","modules/edfs/index.js","modules/overwrite-require/index.js","modules/psk-cache/index.js","modules/psk-http-client/index.js","modules/pskcrypto/index.js","node_modules/source-map-support/source-map-support.js","node_modules/source-map/source-map.js","modules/swarm-engine/bootScripts/ThreadWorkerBootScript.js","modules/swarmutils/index.js"],"names":[],"mappings":"AAAA;ACAA;AACA;AACA;AACA;AACA;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACj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nzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC3JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC7YA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACjGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACnHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACn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eA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACrTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC/ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACvLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACpKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACrGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1jCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACXA;AACA;AACA;AACA;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACrEA;AACA;AACA;AACA;AACA;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACjVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACn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lBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"generated.js","sourceRoot":"../..","sourcesContent":["(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c=\"function\"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error(\"Cannot find module '\"+i+\"'\");throw a.code=\"MODULE_NOT_FOUND\",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u=\"function\"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()","const or = require('overwrite-require');\nprocess.env.NO_LOGS = true;\nor.enableForEnvironment(or.constants.THREAD_ENVIRONMENT_TYPE);\n\nrequire(\"./threadBoot_intermediar\");","global.threadBootLoadModules = function(){ \n\n\tif(typeof $$.__runtimeModules[\"source-map-support\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"source-map-support\"] = require(\"source-map-support\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"source-map\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"source-map\"] = require(\"source-map\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"buffer-from\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"buffer-from\"] = require(\"buffer-from\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"overwrite-require\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"overwrite-require\"] = require(\"overwrite-require\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"edfs\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"edfs\"] = require(\"edfs\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"bar\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"bar\"] = require(\"bar\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"bar-fs-adapter\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"bar-fs-adapter\"] = require(\"bar-fs-adapter\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"edfs-brick-storage\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"edfs-brick-storage\"] = require(\"edfs-brick-storage\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"swarmutils\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"swarmutils\"] = require(\"swarmutils\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"adler32\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"adler32\"] = require(\"adler32\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"psk-cache\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"psk-cache\"] = require(\"psk-cache\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"pskcrypto\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"pskcrypto\"] = require(\"pskcrypto\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"psk-http-client\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"psk-http-client\"] = require(\"psk-http-client\");\n\t}\n\n\tif(typeof $$.__runtimeModules[\"boot-script\"] === \"undefined\"){\n\t\t$$.__runtimeModules[\"boot-script\"] = require(\"swarm-engine/bootScripts/ThreadWorkerBootScript\");\n\t}\n};\nif (true) {\n\tthreadBootLoadModules();\n}\nglobal.threadBootRequire = require;\nif (typeof $$ !== \"undefined\") {\n\t$$.requireBundle(\"threadBoot\");\n}\nrequire('source-map-support').install({});","\"use strict\";\n\nvar util = require('util');\nvar Transform = require('stream').Transform;\nvar crypto = require('crypto');\nvar algorithm = require('./algorithm');\n\n// Provides a node.js Hash style interface for _sum32: http://nodejs.org/api/crypto.html#crypto_class_hash\nvar Hash = module.exports = function Hash(options)\n{\n\tif (!(this instanceof Hash))\n\t\treturn new Hash(options);\n\n\tTransform.call(this, options);\n\n\tthis._sum = 1;\n};\n\nutil.inherits(Hash, Transform);\n\nHash.prototype.update = function(data, encoding)\n{\n\tif (this._done)\n\t\tthrow new TypeError('HashUpdate fail');\n\n\tencoding = encoding || crypto.DEFAULT_ENCODING;\n\n\tif (!(data instanceof Buffer)) {\n\t\tdata = new Buffer(''+data, encoding === 'buffer' ? 'binary' : encoding);\n\t}\n\n\tthis._sum = algorithm.sum(data, this._sum);\n\n\treturn this;\n};\n\nHash.prototype.digest = function(encoding)\n{\n\tif (this._done)\n\t\tthrow new Error('Not initialized');\n\t\n\tthis._done = true;\n\n\tvar buf = new Buffer(4);\n\tbuf.writeUInt32BE(this._sum, 0);\n\n\tencoding = encoding || crypto.DEFAULT_ENCODING;\n\n\tif (encoding === 'buffer')\n\t\treturn buf;\n\telse\n\t\treturn buf.toString(encoding);\n};\n\nHash.prototype._transform = function(chunk, encoding, callback)\n{\n\tthis.update(chunk, encoding);\n\tcallback();\n};\n\nHash.prototype._flush = function(callback)\n{\n\tvar encoding = this._readableState.encoding || 'buffer';\n\tthis.push(this.digest(encoding), encoding);\n\tcallback();\n};","\"use strict\";\n\n/**\n * Largest prime smaller than 2^16 (65536)\n */\nvar BASE = 65521;\n\n/**\n * Largest value n such that 255n(n+1)/2 + (n+1)(BASE-1) <= 2^32-1\n *\n * NMAX is just how often modulo needs to be taken of the two checksum word halves to prevent overflowing a 32 bit\n * integer. This is an optimization. We \"could\" take the modulo after each byte, and it must be taken before each\n * digest.\n */\nvar NMAX = 5552;\n\nexports.sum = function(buf, sum)\n{\n\tif (sum == null)\n\t\tsum = 1;\n\n\tvar a = sum & 0xFFFF,\n\t\tb = (sum >>> 16) & 0xFFFF,\n\t\ti = 0,\n\t\tmax = buf.length,\n\t\tn, value;\n\n\twhile (i < max)\n\t{\n\t\tn = Math.min(NMAX, max - i);\n\n\t\tdo\n\t\t{\n\t\t\ta += buf[i++]<<0;\n\t\t\tb += a;\n\t\t}\n\t\twhile (--n);\n\n\t\ta %= BASE;\n\t\tb %= BASE;\n\t}\n\n\treturn ((b << 16) | a) >>> 0;\n};\n\nexports.roll = function(sum, length, oldByte, newByte)\n{\n\tvar a = sum & 0xFFFF,\n\t\tb = (sum >>> 16) & 0xFFFF;\n\n\tif (newByte != null)\n\t{\n\t\ta = (a - oldByte + newByte + BASE) % BASE;\n\t\tb = (b - ((length * oldByte) % BASE) + a - 1 + BASE) % BASE;\n\t}\n\telse\n\t{\n\t\ta = (a - oldByte + BASE) % BASE;\n\t\tb = (b - ((length * oldByte) % BASE) - 1 + BASE) % BASE;\n\t}\n\n\treturn ((b << 16) | a) >>> 0;\n};","\"use strict\";\n\nmodule.exports = function()\n{\n\tvar crypto = require('crypto');\n\tvar Hash = require('./Hash');\n\n\t// Silently abort if the adler32 algorithm is already supported by the\n\t// crypto module.\n\tif (crypto.getHashes().indexOf('adler32') != -1)\n\t\treturn;\n\n\tcrypto.getHashes = function()\n\t{\n\t\treturn this().concat(['adler32']);\n\t}\n\t.bind(crypto.getHashes.bind(crypto));\n\n\tcrypto.createHash = function(algorithm)\n\t{\n\t\tif (algorithm === 'adler32')\n\t\t\treturn new Hash();\n\t\telse\n\t\t\treturn this(algorithm);\n\t}\n\t.bind(crypto.createHash.bind(this));\n};","const fsModule = \"fs\";\nconst fs = require(fsModule);\nconst pathModule = \"path\";\nconst path = require(pathModule);\nconst PathAsyncIterator = require('./PathAsyncIterator');\n\nfunction FsAdapter() {\n\n    this.getFileSize = function (filePath, callback) {\n        fs.stat(filePath, (err, stats) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, stats.size);\n        });\n    };\n\n    this.readBlockFromFile = function (filePath, blockStart, blockEnd, callback) {\n        const readStream = fs.createReadStream(filePath, {\n            start: blockStart,\n            end: blockEnd\n        });\n\n        let data = Buffer.alloc(0);\n\n        readStream.on(\"data\", (chunk) => {\n            data = Buffer.concat([data, chunk]);\n        });\n\n        readStream.on(\"error\", (err) => {\n            callback(err);\n        });\n\n        readStream.on(\"end\", () => {\n            callback(undefined, data);\n        });\n    };\n\n    this.getFilesIterator = function (inputPath) {\n        return new PathAsyncIterator(inputPath);\n    };\n\n    this.appendBlockToFile = function (filePath, data, callback) {\n        fs.access(filePath, (err) => {\n            if (err) {\n                fs.mkdir(path.dirname(filePath), {recursive: true}, (err) => {\n                    if (err && err.code !== \"EEXIST\") {\n                        return callback(err);\n                    }\n\n                    fs.appendFile(filePath, data, callback);\n                });\n            } else {\n                fs.appendFile(filePath, data, callback);\n            }\n        });\n    };\n}\n\nmodule.exports = FsAdapter;","const fsModule = \"fs\";\nconst fs = require(fsModule);\nconst pathModule = \"path\";\nconst path = require(pathModule);\nconst TaskCounter = require(\"swarmutils\").TaskCounter;\n\n\nfunction PathAsyncIterator(inputPath) {\n    inputPath = path.normalize(inputPath);\n    let removablePathLen;\n    const fileList = [];\n    const folderList = [];\n    let isFirstCall = true;\n    let pathIsFolder;\n\n    this.next = function (callback) {\n        if (isFirstCall === true) {\n            isDir(inputPath, (err, status) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                isFirstCall = false;\n                pathIsFolder = status;\n                if (status === true) {\n                    if(!inputPath.endsWith(path.sep)) {\n                        inputPath += path.sep;\n                    }\n\n                    removablePathLen = inputPath.length;\n                    folderList.push(inputPath);\n                    getNextFileFromFolder(callback);\n                } else {\n                    const fileName = path.basename(inputPath);\n                    const fileParentFolder = path.dirname(inputPath);\n                    callback(undefined, fileName, fileParentFolder);\n                }\n            });\n        } else if (pathIsFolder) {\n            getNextFileFromFolder(callback);\n        } else {\n            callback();\n        }\n    };\n\n    function walkFolder(folderPath, callback) {\n        const taskCounter = new TaskCounter((errors, results) => {\n            if (fileList.length > 0) {\n                const fileName = fileList.shift();\n                return callback(undefined, fileName, inputPath);\n            }\n\n            if (folderList.length > 0) {\n                const folderName = folderList.shift();\n                return walkFolder(folderName, callback);\n            }\n\n            return callback();\n        });\n\n        fs.readdir(folderPath, (err, files) => {\n            if (err) {\n                return callback(err);\n            }\n\n            if (files.length === 0 && folderList.length === 0) {\n                return callback();\n            }\n\n            if (files.length === 0) {\n                walkFolder(folderList.shift(), callback);\n            }\n            taskCounter.increment(files.length);\n\n            files.forEach(file => {\n                let filePath = path.join(folderPath, file);\n                isDir(filePath, (err, status) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    if (status) {\n                        folderList.push(filePath);\n                    } else {\n                        fileList.push(filePath.substring(removablePathLen));\n                    }\n\n                    taskCounter.decrement();\n                });\n            });\n        });\n    }\n\n    function isDir(filePath, callback) {\n        fs.stat(filePath, (err, stats) => {\n            if (err) {\n                return callback(err);\n            }\n\n            return callback(undefined, stats.isDirectory());\n        });\n    }\n\n    function getNextFileFromFolder(callback) {\n        if (fileList.length === 0 && folderList.length === 0) {\n            return callback();\n        }\n\n        if (fileList.length > 0) {\n            const fileName = fileList.shift();\n            return callback(undefined, fileName, inputPath);\n        }\n\n\n        walkFolder(folderList.shift(), (err, file) => {\n            if (err) {\n                return callback(err);\n            }\n\n            callback(undefined, file, inputPath);\n        });\n    }\n}\n\nmodule.exports = PathAsyncIterator;","const Brick = require('./Brick');\nconst pathModule = \"path\";\nconst path = require(pathModule);\nconst isStream = require(\"../utils/isStream\");\nconst stream = require('stream');\nconst swarmutils = require(\"swarmutils\");\nconst TaskCounter = swarmutils.TaskCounter;\nconst pskPth = swarmutils.path;\nconst crypto = require('pskcrypto');\nconst adler32 = require('adler32');\n\nfunction Archive(archiveConfigurator) {\n\n    const archiveFsAdapter = archiveConfigurator.getFsAdapter();\n    const storageProvider = archiveConfigurator.getStorageProvider();\n    const cache = archiveConfigurator.getCache();\n    let cachedSEED;\n    let barMap;\n    let cachedMapDigest;\n\n    this.getMapDigest = () => {\n        if (cachedMapDigest) {\n            return cachedMapDigest;\n        }\n\n        cachedMapDigest = archiveConfigurator.getMapDigest();\n        return cachedMapDigest;\n    };\n\n    this.setSeed = (seed) => {\n        cachedSEED = seed;\n        archiveConfigurator.setSeed(Buffer.from(seed));\n    };\n\n    this.getSeed = () => {\n        if (cachedSEED) {\n            return cachedSEED;\n        }\n\n        cachedSEED = archiveConfigurator.getSeed().toString();\n        return cachedSEED;\n    };\n\n    this.getFileHash = (barPath, callback) => {\n        barPath = pskPth.normalize(barPath);\n        loadBarMapThenExecute(() => {\n            callback(undefined, __computeFileHash(barPath).toString(\"hex\"));\n        }, callback)\n    };\n\n    this.getFolderHash = (barPath, callback) => {\n        barPath = pskPth.normalize(barPath);\n        loadBarMapThenExecute(() => {\n            const fileList = barMap.getFileList(barPath);\n            if (fileList.length === 1) {\n                return callback(undefined, __computeFileHash(pskPth.join(barPath, fileList[0]).toString(\"hex\")));\n            }\n            fileList.sort();\n\n            let xor = __computeFileHash(pskPth.join(barPath, fileList[0]));\n            for (let i = 0; i < fileList.length - 1; i++) {\n                xor = crypto.xorBuffers(xor, __computeFileHash(pskPth.join(barPath, fileList[i + 1])));\n            }\n\n            callback(undefined, crypto.pskHash(xor, \"hex\"));\n        }, callback);\n    };\n\n    this.writeFile = (barPath, data, options, callback) => {\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {};\n            options.encrypt = true;\n        }\n        barPath = pskPth.normalize(barPath);\n\n        loadBarMapThenExecute(__addData, callback);\n\n        function __addData() {\n            if (typeof data === \"string\") {\n                data = Buffer.from(data);\n            }\n\n            if (!isStream.isReadable(data) && !Buffer.isBuffer(data)) {\n                return callback(Error(`Type of data is ${typeof data}. Expected Buffer or Stream.Readable`));\n            }\n\n            createBricksFromData(data, barPath, archiveConfigurator.getBufferSize(), options.encrypt, (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                barMap.setConfig(archiveConfigurator);\n                if (archiveConfigurator.getMapEncryptionKey()) {\n                    barMap.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n                }\n\n                storageProvider.putBarMap(barMap, callback);\n            });\n        }\n    };\n\n    this.readFile = (barPath, callback) => {\n        barPath = pskPth.normalize(barPath);\n        loadBarMapThenExecute(__readFile, callback);\n\n        function __readFile() {\n            let fileData = Buffer.alloc(0);\n            let brickIds;\n            try {\n                brickIds = barMap.getHashList(barPath);\n            } catch (err) {\n                return callback(err);\n            }\n\n            getFileRecursively(0, callback);\n\n            function getFileRecursively(brickIndex, callback) {\n                const brickId = brickIds[brickIndex];\n                getBrickData(brickId, (err, data) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    fileData = Buffer.concat([fileData, data]);\n                    ++brickIndex;\n\n                    if (brickIndex < brickIds.length) {\n                        getFileRecursively(brickIndex, callback);\n                    } else {\n                        callback(undefined, fileData);\n                    }\n\n                });\n            }\n        }\n    };\n\n    this.createReadStream = (barPath, callback) => {\n        barPath = pskPth.normalize(barPath);\n        loadBarMapThenExecute(__prepareStream, callback);\n\n        function __prepareStream() {\n            let brickIndex = 0;\n            let brickIds;\n\n            try {\n                brickIds = barMap.getHashList(barPath);\n            } catch (err) {\n                return callback(err);\n            }\n\n            const readableStream = new stream.Readable({\n                read(size) {\n                    if (brickIndex < brickIds.length) {\n                        this.readBrickData(brickIndex++);\n                    }\n                }\n            });\n\n            // Get a brick and push it into the stream\n            readableStream.readBrickData = function (brickIndex) {\n                const brickId = brickIds[brickIndex];\n                getBrickData(brickId, (err, data) => {\n                    if (err) {\n                        this.destroy(err);\n                        return;\n                    }\n\n                    this.push(data);\n\n                    if (brickIndex >= (brickIds.length - 1)) {\n                        this.push(null);\n                    }\n                });\n            };\n\n            callback(null, readableStream);\n        }\n    };\n\n    this.addFile = (fsFilePath, barPath, options, callback) => {\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {};\n            options.encrypt = true;\n        }\n\n        barPath = pskPth.normalize(barPath);\n\n        loadBarMapThenExecute(__addFile, callback);\n\n        function __addFile() {\n            createBricks(fsFilePath, barPath, archiveConfigurator.getBufferSize(), options.encrypt, (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                barMap.setConfig(archiveConfigurator);\n                if (archiveConfigurator.getMapEncryptionKey()) {\n                    barMap.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n                }\n\n                storageProvider.putBarMap(barMap, callback);\n            });\n        }\n    };\n\n    this.addFiles = (arrWithFilePaths, barPath, options, callback) => {\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {};\n            options.encrypt = true;\n        }\n\n        barPath = pskPth.normalize(barPath);\n\n        let arr = arrWithFilePaths.slice();\n\n        loadBarMapThenExecute(() => {\n            recAdd()\n        }, callback);\n\n        function recAdd() {\n            if (arr.length > 0) {\n                let filePath = arr.pop();\n                let fileName = path.basename(filePath);\n\n                createBricks(filePath, pskPth.join(barPath, fileName), archiveConfigurator.getBufferSize(), options.encrypt, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    recAdd();\n                });\n            } else {\n                barMap.setConfig(archiveConfigurator);\n                if (archiveConfigurator.getMapEncryptionKey()) {\n                    barMap.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n                }\n                storageProvider.putBarMap(barMap, callback);\n            }\n        }\n    };\n\n    this.extractFile = (fsFilePath, barPath, callback) => {\n        if (typeof barPath === \"function\") {\n            callback = barPath;\n            barPath = pskPth.normalize(fsFilePath);\n        }\n\n\n        loadBarMapThenExecute(__extractFile, callback);\n\n        function __extractFile() {\n            const brickIds = barMap.getHashList(barPath);\n            getFileRecursively(0, callback);\n\n            function getFileRecursively(brickIndex, callback) {\n                const brickId = brickIds[brickIndex];\n                getBrickData(brickId, (err, data) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    archiveFsAdapter.appendBlockToFile(fsFilePath, data, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        ++brickIndex;\n                        if (brickIndex < brickIds.length) {\n                            getFileRecursively(brickIndex, callback);\n                        } else {\n                            callback();\n                        }\n                    });\n                })\n            }\n        }\n    };\n\n    this.appendToFile = (filePath, data, callback) => {\n\n        loadBarMapThenExecute(__appendToFile, callback);\n\n        function __appendToFile() {\n            filePath = path.normalize(filePath);\n\n            if (typeof data === \"string\") {\n                data = Buffer.from(data);\n            }\n            if (Buffer.isBuffer(data)) {\n                const dataBrick = new Brick(data);\n                storageProvider.putBrick(dataBrick, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    barMap.add(filePath, dataBrick);\n                    putBarMap(callback);\n                });\n                return;\n            }\n\n            if (isStream.isReadable(data)) {\n                data.on('error', (err) => {\n                    return callback(err);\n                }).on('data', (chunk) => {\n                    const dataBrick = new Brick(chunk);\n                    barMap.add(filePath, dataBrick);\n                    storageProvider.putBrick(dataBrick, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n                    });\n                }).on(\"end\", () => {\n                    putBarMap(callback);\n                });\n                return;\n            }\n            callback(new Error(\"Invalid type of parameter data\"));\n        }\n    };\n\n\n    this.replaceFile = (fileName, stream, callback) => {\n        if (typeof stream !== 'object') {\n            return callback(new Error('Wrong stream!'));\n        }\n\n        loadBarMapThenExecute(__replaceFile, callback);\n\n        function __replaceFile() {\n            fileName = path.normalize(fileName);\n            stream.on('error', () => {\n                return callback(new Error(\"File does not exist!\"));\n            }).on('open', () => {\n                storageProvider.deleteFile(fileName, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    barMap.emptyList(fileName);\n                });\n            }).on('data', (chunk) => {\n                let tempBrick = new Brick(chunk);\n                barMap.add(fileName, tempBrick);\n                storageProvider.putBrick(tempBrick, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    putBarMap(callback);\n                });\n            });\n        }\n    };\n\n    this.addFolder = (fsFolderPath, barPath, options, callback) => {\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {};\n            options.encrypt = true;\n        }\n        barPath = pskPth.normalize(barPath);\n        const filesIterator = archiveFsAdapter.getFilesIterator(fsFolderPath);\n\n        loadBarMapThenExecute(__addFolder, callback);\n\n        function __addFolder() {\n\n            filesIterator.next(readFileCb);\n\n            function readFileCb(err, file, rootFsPath) {\n                if (err) {\n                    return callback(err);\n                }\n\n                if (typeof file !== \"undefined\") {\n                    createBricks(path.join(rootFsPath, file), pskPth.join(barPath, file), archiveConfigurator.getBufferSize(), options.encrypt, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        filesIterator.next(readFileCb);\n                    });\n                } else {\n                    storageProvider.putBarMap(barMap, (err, mapDigest) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        archiveConfigurator.setMapDigest(mapDigest);\n                        callback(undefined, mapDigest);\n                    });\n                }\n            }\n        }\n    };\n\n\n    this.extractFolder = (fsFolderPath, barPath, callback) => {\n        if (typeof barPath === \"function\") {\n            callback = barPath;\n            barPath = pskPth.normalize(fsFolderPath);\n        }\n\n        loadBarMapThenExecute(() => {\n            const filePaths = barMap.getFileList(barPath);\n            const taskCounter = new TaskCounter(() => {\n                callback();\n            });\n            taskCounter.increment(filePaths.length);\n            filePaths.forEach(filePath => {\n                let actualPath;\n                if (fsFolderPath) {\n                    if (fsFolderPath.includes(filePath)) {\n                        actualPath = fsFolderPath;\n                    } else {\n                        actualPath = path.join(fsFolderPath, filePath);\n                    }\n                } else {\n                    actualPath = filePath;\n                }\n\n                this.extractFile(actualPath, filePath, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    taskCounter.decrement();\n                });\n            });\n        }, callback);\n    };\n\n    this.store = (callback) => {\n        storageProvider.putBarMap(barMap, callback);\n    };\n\n    this.delete = (barPath, callback) => {\n        loadBarMapThenExecute(() => {\n            barMap.delete(barPath);\n            callback();\n        }, callback);\n    };\n\n    this.listFiles = (folderBarPath, recursive, callback) => {\n        if (typeof recursive === \"function\") {\n            callback = recursive;\n            recursive = true;\n        } else if (typeof folderBarPath === \"function\") {\n            callback = folderBarPath;\n            recursive = true;\n            folderBarPath = \"/\";\n        }\n\n\n        loadBarMapThenExecute(() => {\n            let fileList;\n            try {\n                fileList = barMap.getFileList(folderBarPath, recursive);\n            } catch (e) {\n                return callback(e);\n            }\n\n            callback(undefined, fileList);\n        }, callback);\n    };\n\n    this.listFolders = (folderBarPath, recursive, callback) => {\n        if (typeof recursive === \"function\") {\n            callback = recursive;\n            recursive = true;\n        }\n\n        loadBarMapThenExecute(() => {\n            callback(undefined, barMap.getFolderList(folderBarPath, recursive));\n        }, callback);\n    };\n\n    this.clone = (targetStorage, preserveKeys = true, callback) => {\n        targetStorage.getBarMap((err, targetBarMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            loadBarMapThenExecute(__cloneBricks, callback);\n\n            function __cloneBricks() {\n                const fileList = barMap.getFileList(\"/\");\n\n                __getFilesRecursively(fileList, 0, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    cachedSEED = archiveConfigurator.getSeed();\n                    archiveConfigurator.generateSeed();\n                    targetBarMap.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n                    targetBarMap.setConfig(archiveConfigurator);\n                    targetStorage.putBarMap(targetBarMap, err => callback(err, archiveConfigurator.getSeed()));\n                });\n            }\n\n            function __getFilesRecursively(fileList, fileIndex, callback) {\n                const filePath = fileList[fileIndex];\n                __getBricksRecursively(filePath, barMap.getHashList(filePath), 0, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    ++fileIndex;\n                    if (fileIndex === fileList.length) {\n                        return callback();\n                    }\n\n                    __getFilesRecursively(fileList, fileIndex, callback);\n                });\n            }\n\n            function __getBricksRecursively(filePath, brickList, brickIndex, callback) {\n                storageProvider.getBrick(brickList[brickIndex], (err, brick) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    if (barMap.getTransformParameters(brickList[brickIndex])) {\n                        brick.setTransformParameters(barMap.getTransformParameters(brickList[brickIndex]));\n                    }\n                    __addBrickToTarget(brick, callback);\n                });\n\n                function __addBrickToTarget(brick, callback) {\n                    brick.setConfig(archiveConfigurator);\n                    if (!preserveKeys) {\n                        brick.createNewTransform();\n                    }\n\n                    ++brickIndex;\n                    targetBarMap.add(filePath, brick);\n                    targetStorage.putBrick(brick, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        if (brickIndex === brickList.length) {\n                            return callback();\n                        }\n\n                        __getBricksRecursively(filePath, brickList, brickIndex, callback);\n                    });\n                }\n            }\n        });\n    };\n\n    //------------------------------------------- internal methods -----------------------------------------------------\n\n    function __computeFileHash(fileBarPath) {\n        const hashList = barMap.getHashList(fileBarPath);\n        const PskHash = crypto.PskHash;\n        const pskHash = new PskHash();\n        hashList.forEach(hash => {\n            pskHash.update(hash);\n        });\n\n        return pskHash.digest();\n    }\n\n    function putBarMap(callback) {\n        if (typeof archiveConfigurator.getMapDigest() !== \"undefined\") {\n            storageProvider.deleteFile(archiveConfigurator.getMapDigest(), (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                __putBarMap(callback);\n            });\n            return;\n        }\n        __putBarMap(callback);\n    }\n\n    function __putBarMap(callback) {\n        storageProvider.putBarMap(barMap, (err, newMapDigest) => {\n            if (err) {\n                return callback(err);\n            }\n\n            archiveConfigurator.setMapDigest(newMapDigest);\n            callback(undefined, archiveConfigurator.getMapDigest());\n        });\n    }\n\n    function createBricks(fsFilePath, barPath, blockSize, areEncrypted, callback) {\n        if (typeof areEncrypted === \"function\") {\n            callback = areEncrypted;\n            areEncrypted = true;\n        }\n        archiveFsAdapter.getFileSize(fsFilePath, (err, fileSize) => {\n            if (err) {\n                return callback(err);\n            }\n\n            let noBlocks = Math.floor(fileSize / blockSize);\n            if (fileSize % blockSize > 0) {\n                ++noBlocks;\n            }\n\n            if (!barMap.isEmpty(barPath)) {\n                barMap.emptyList(barPath);\n            }\n            __createBricksRecursively(0, callback);\n\n            function __createBricksRecursively(blockIndex, callback) {\n                archiveFsAdapter.readBlockFromFile(fsFilePath, blockIndex * blockSize, (blockIndex + 1) * blockSize - 1, (err, blockData) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    archiveConfigurator.setIsEncrypted(areEncrypted);\n                    const brick = new Brick(archiveConfigurator);\n                    brick.setRawData(blockData);\n                    barMap.add(barPath, brick);\n                    storageProvider.putBrick(brick, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        ++blockIndex;\n                        if (blockIndex < noBlocks) {\n                            __createBricksRecursively(blockIndex, callback);\n                        } else {\n                            callback();\n                        }\n                    });\n                });\n            }\n        });\n    }\n\n    /**\n     * Create bricks from a Buffer or a readable stream\n     * @param {Buffer|stream.Readable} data\n     * @param {string} barPath\n     * @param {number} blockSize\n     * @param {boolean} areEncrypted\n     * @param {callback} callback\n     */\n    function createBricksFromData(data, barPath, blockSize, areEncrypted, callback) {\n        if (typeof areEncrypted === \"function\") {\n            callback = areEncrypted;\n            areEncrypted = true;\n        }\n\n        if (typeof data === 'string') {\n            data = Buffer.from(data);\n        }\n\n        if (!barMap.isEmpty(barPath)) {\n            barMap.emptyList(barPath);\n        }\n\n        /**\n         * Break the Buffer into bricks\n         * @param {Buffer} data\n         * @param {number} _blockSize\n         * @param {callback} callback\n         */\n        function __createBricksFromBuffer(data, _blockSize, callback) {\n            if (typeof _blockSize === 'function') {\n                callback = _blockSize;\n                _blockSize = blockSize; // set the default blockSize\n            }\n\n            let noBlocks = Math.floor(data.length / _blockSize);\n            if ((data.length % _blockSize) > 0) {\n                ++noBlocks;\n            }\n\n            function __createBricksRecursively(blockIndex, callback) {\n                const blockData = data.slice(blockIndex * _blockSize, (blockIndex + 1) * _blockSize);\n\n                archiveConfigurator.setIsEncrypted(areEncrypted);\n                const brick = new Brick(archiveConfigurator);\n\n                brick.setRawData(blockData);\n                barMap.add(barPath, brick);\n                storageProvider.putBrick(brick, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    ++blockIndex;\n                    if (blockIndex < noBlocks) {\n                        __createBricksRecursively(blockIndex, callback);\n                    } else {\n                        callback();\n                    }\n                });\n\n            }\n\n            __createBricksRecursively(0, callback);\n        }\n\n        if (isStream.isReadable(data)) {\n            data.on('data', (chunk) => {\n                if (typeof chunk === 'string') {\n                    chunk = Buffer.from(chunk);\n                }\n                data.pause();\n\n                // When reading from a stream, set the block size to the chunk's length\n                __createBricksFromBuffer(chunk, chunk.length, (err) => {\n                    if (err) {\n                        data.destroy(err);\n                        return callback(err);\n                    }\n                    data.resume();\n                });\n            });\n            data.on('error', (err) => {\n                callback(err);\n            });\n            data.on('end', () => {\n                callback();\n            });\n        } else { // Data is buffer\n            __createBricksFromBuffer(data, (err) => {\n                callback(err);\n            });\n        }\n    }\n\n    /**\n     * @param {*} key\n     * @return {Boolean}\n     */\n    function hasInCache(key) {\n        if (!cache) {\n            return false;\n        }\n\n        return cache.has(key);\n    }\n\n    /**\n     * @param {*} key\n     * @param {*} value\n     */\n    function storeInCache(key, value) {\n        if (!cache) {\n            return;\n        }\n\n        cache.set(key, value);\n    }\n\n    /**\n     * Try and get brick data from cache\n     * Fallback to storage provide if not found in cache\n     *\n     * @param {string} hash\n     * @param {callback} callback\n     */\n    function getBrickData(hash, callback) {\n        if (!hasInCache(hash)) {\n            return storageProvider.getBrick(hash, (err, brick) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                brick.setConfig(archiveConfigurator);\n                brick.setTransformParameters(barMap.getTransformParameters(hash));\n                const data = brick.getRawData();\n                storeInCache(hash, data);\n                callback(undefined, data);\n            });\n        }\n\n        const data = cache.get(hash);\n        callback(undefined, data);\n    }\n\n    function loadBarMapThenExecute(functionToBeExecuted, callback) {\n        const digest = archiveConfigurator.getMapDigest();\n        if (!digest || !hasInCache(digest)) {\n            return storageProvider.getBarMap(digest, (err, map) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                if (archiveConfigurator.getMapEncryptionKey()) {\n                    map.setEncryptionKey(archiveConfigurator.getMapEncryptionKey());\n                }\n\n                if (!map.getConfig()) {\n                    map.setConfig(archiveConfigurator);\n                }\n\n                map.load();\n                barMap = map;\n                if (digest) {\n                    storeInCache(digest, barMap);\n                }\n                storageProvider.setBarMap(barMap);\n                functionToBeExecuted();\n            });\n        }\n\n        const map = cache.get(digest);\n        barMap = map;\n        storageProvider.setBarMap(barMap);\n        functionToBeExecuted();\n    }\n}\n\nmodule.exports = Archive;\n","const storageProviders = {};\nconst fsAdapters = {};\nconst Seed = require(\"./Seed\");\n\nfunction ArchiveConfigurator() {\n    const config = {};\n    let cache;\n\n    let self = this;\n    this.setBufferSize = (bufferSize) => {\n        if (bufferSize < 65535) {\n            throw Error(`Brick size should be equal to or greater than 65535. The provided brick size is ${bufferSize}`);\n        }\n        config.bufferSize = bufferSize;\n    };\n\n    this.getBufferSize = () => {\n        return config.bufferSize;\n    };\n\n    this.setIsEncrypted = (flag) => {\n        config.isEncrypted = flag;\n    };\n\n    this.getIsEncrypted = () => {\n        return config.isEncrypted;\n    };\n\n    this.setStorageProvider = (storageProviderName, ...args) => {\n        if (!storageProviders[storageProviderName]) {\n            throw new Error(storageProviderName + \" is not registered! Did you forget to register it?\");\n        }\n        config.storageProvider = storageProviders[storageProviderName](...args);\n    };\n\n    this.getStorageProvider = () => {\n        return config.storageProvider;\n    };\n\n    this.setFsAdapter = (fsAdapterName, ...args) => {\n        config.fsAdapter = fsAdapters[fsAdapterName](...args);\n    };\n\n    this.getFsAdapter = () => {\n        return config.fsAdapter;\n    };\n\n    this.setMapDigest = (mapDigest) => {\n        config.mapDigest = mapDigest;\n    };\n\n    this.getMapDigest = () => {\n        return config.mapDigest;\n    };\n\n    this.setEncryptionAlgorithm = (algorithm) => {\n        if (!config.encryption) {\n            config.encryption = {};\n        }\n\n        config.encryption.algorithm = algorithm;\n    };\n\n    this.getEncryptionAlgorithm = () => {\n        if (!config.encryption) {\n            return;\n        }\n        return config.encryption.algorithm;\n    };\n\n    this.setEncryptionOptions = (options) => {\n        if (!config.encryption) {\n            config.encryption = {};\n        }\n\n        config.encryption.encOptions = options;\n    };\n\n    this.getEncryptionOptions = () => {\n        if (!config.encryption) {\n            return;\n        }\n        return config.encryption.encOptions;\n    };\n\n    this.setCompressionAlgorithm = (algorithm) => {\n        if (!config.compression) {\n            config.compression = {};\n        }\n\n        config.compression.algorithm = algorithm;\n    };\n\n    this.getCompressionAlgorithm = () => {\n        if (!config.compression) {\n            return;\n        }\n\n        return config.compression.algorithm;\n\n    };\n\n    this.setCompressionOptions = (options) => {\n        if (!config.compression) {\n            config.compression = {};\n        }\n\n        config.compression.options = options;\n    };\n\n    this.getCompressionOptions = () => {\n        if (!config.compression) {\n            return;\n        }\n        return config.compression.options;\n    };\n\n    this.setAuthTagLength = (authTagLength = 16) => {\n        const encOptions = this.getEncryptionOptions();\n        if (!encOptions) {\n            config.encryption.encOptions = {};\n        }\n\n        config.encryption.encOptions.authTagLength = authTagLength;\n    };\n\n    this.getAuthTagLength = () => {\n        if (!config.encryption || !config.encryption.encOptions) {\n            return;\n        }\n\n        return config.encryption.encOptions.authTagLength;\n    };\n\n    this.setSeedEndpoint = (endpoint) => {\n        config.seedEndpoint = endpoint;\n    };\n\n    this.setSeedKey = (key) => {\n        config.seed.setKey(key);\n        this.setMapDigest(key);\n    };\n\n    this.getSeedKey = () => {\n        loadSeed();\n        if (config.seed) {\n            return config.seed.getKey();\n        }\n    };\n\n    this.setSeed = (compactSeed) => {\n        config.seed = new Seed(compactSeed);\n        const endpoint = config.seed.getEndpoint();\n        if (endpoint) {\n            this.setStorageProvider(\"EDFSBrickStorage\", endpoint);\n        }\n        this.setMapDigest(config.seed.getKey());\n    };\n\n    this.getSeed = () => {\n        loadSeed();\n        if (config.seed) {\n            return config.seed.getCompactForm();\n        }\n    };\n\n    this.getMapEncryptionKey = () => {\n        loadSeed();\n        if (!config.seed) {\n            return;\n        }\n\n        if (!config.encryption) {\n            return;\n        }\n\n        return config.seed.getEncryptionKey(config.encryption.algorithm);\n    };\n\n    this.generateSeed = () => {\n        if (!config.seedEndpoint && config.seed) {\n            config.seedEndpoint = config.seed.getEndpoint();\n        }\n        config.seed = new Seed(undefined, config.seedEndpoint);\n        if (config.seed.getKey()) {\n            self.setMapDigest(config.seed.getKey());\n        }\n    };\n\n    this.setCache = (cacheInstance) => {\n        cache = cacheInstance;\n    };\n\n    this.getCache = () => {\n        return cache;\n    };\n\n    //--------------------------\n    function loadSeed() {\n        if (!config.seed) {\n            config.seed = new Seed(undefined, config.seedEndpoint);\n        }\n    }\n}\n\nArchiveConfigurator.prototype.registerStorageProvider = (storageProviderName, factory) => {\n    storageProviders[storageProviderName] = factory;\n};\n\nArchiveConfigurator.prototype.registerFsAdapter = (fsAdapterName, factory) => {\n    fsAdapters[fsAdapterName] = factory;\n};\n\nmodule.exports = ArchiveConfigurator;\n","const crypto = require('pskcrypto');\nconst BrickTransformFactory = require(\"./transforms/BrickTransformFactory\");\nconst transformFactory = new BrickTransformFactory();\nconst adler32 = require('adler32');\n\nfunction Brick(config) {\n    let rawData;\n    let transformedData;\n    let hash;\n    let transformParameters;\n    let transform = transformFactory.createBrickTransform(config);\n\n    this.setConfig = (newConfig) => {\n        config = newConfig;\n        if (transform) {\n            transform.setConfig(newConfig);\n        } else {\n            transform = transformFactory.createBrickTransform(config);\n        }\n    };\n\n    this.createNewTransform = () => {\n        transform = transformFactory.createBrickTransform(config);\n        transformParameters = undefined;\n        transformData();\n    };\n\n    this.getHash = () => {\n        if (!hash) {\n            hash = crypto.pskHash(this.getTransformedData()).toString(\"hex\");\n        }\n\n        return hash;\n    };\n\n    this.getKey = () => {\n        const seedId = config.getSeedKey();\n        if (seedId) {\n            return seedId;\n        }\n        return config.getMapDigest();\n    };\n\n    this.setKey = (key) => {\n        config.setSeedKey(key);\n    };\n\n    this.getSeed = () => {\n        return config.getSeed().toString();\n    };\n    this.getAdler32 = () => {\n        return adler32.sum(this.getTransformedData());\n    };\n\n    this.setRawData = function (data) {\n        rawData = data;\n        if (!transform) {\n            transformedData = rawData;\n        }\n    };\n\n    this.getRawData = () => {\n        if (rawData) {\n            return rawData;\n        }\n\n        if (transformedData) {\n            if (!transform) {\n                return transformedData;\n            }\n\n            rawData = transform.applyInverseTransform(transformedData, transformParameters);\n            if (rawData) {\n                return rawData;\n            }\n\n            return transformedData;\n        }\n\n        throw new Error(\"The brick does not contain any data.\");\n    };\n\n    this.setTransformedData = (data) => {\n        transformedData = data;\n    };\n\n    this.getTransformedData = () => {\n        if (!transformedData) {\n            transformData();\n        }\n\n        if (transformedData) {\n            return transformedData;\n        }\n\n        if (rawData) {\n            return rawData;\n        }\n\n        throw new Error(\"The brick does not contain any data.\");\n    };\n\n    this.getTransformParameters = () => {\n        if (!transformedData) {\n            transformData();\n        }\n        return transformParameters;\n    };\n\n    this.setTransformParameters = (newTransformParams) => {\n        if (!newTransformParams) {\n            return;\n        }\n\n        if (!transformParameters) {\n            transformParameters = newTransformParams;\n            return;\n        }\n\n        Object.keys(newTransformParams).forEach(key => {\n            transformParameters[key] = newTransformParams[key];\n        });\n    };\n\n    this.getRawSize = () => {\n        return rawData.length;\n    };\n\n    this.getTransformedSize = () => {\n        if (!transformedData) {\n            return rawData.length;\n        }\n\n        return transformedData.length;\n    };\n\n//----------------------------------------------- internal methods -----------------------------------------------------\n    function transformData() {\n        if (!transform) {\n            throw new Error(\"transform undefined\");\n        }\n\n        if (rawData) {\n            transformedData = transform.applyDirectTransform(rawData, transformParameters);\n            if (!transformedData) {\n                transformedData = rawData;\n            }\n        }\n\n        transformParameters = transform.getTransformParameters();\n    }\n\n}\n\nmodule.exports = Brick;\n","const Brick = require(\"./Brick\");\nconst util = require(\"../utils/utilities\");\nconst pathModule = \"path\";\nconst path = require(pathModule);\n\nfunction FileBarMap(header) {\n    header = header || {};\n\n    let brickOffset = util.getBarMapOffsetSize();\n    let archiveConfig;\n    let encryptionKey;\n\n    this.add = (filePath, brick) => {\n        filePath = filePath.split(path.sep).join(path.posix.sep);\n        this.load();\n        if (typeof header[filePath] === \"undefined\") {\n            header[filePath] = [];\n        }\n\n        const brickObj = {\n            checkSum: brick.getAdler32(),\n            offset: brickOffset,\n            hash: brick.getHash()\n        };\n\n        const encKey = brick.getTransformParameters() ? brick.getTransformParameters().key : undefined;\n        if (encKey) {\n            brickObj.key = encKey;\n        }\n\n        header[filePath].push(brickObj);\n        brickOffset += brick.getTransformedSize();\n    };\n\n    this.getHashList = (filePath) => {\n        this.load();\n        return header[filePath].map(brickObj => brickObj.offset);\n    };\n\n    this.getFileList = (folderBarPath) => {\n        this.load();\n        if (!folderBarPath) {\n            return Object.keys(header);\n        }\n        return Object.keys(header).filter(fileName => fileName.includes(folderBarPath));\n    };\n\n    this.getDictionaryObject = () => {\n        let objectDict = {};\n        Object.keys(header).forEach((fileName) => {\n            let brickObjects = header[fileName];\n            for (let j = 0; j < brickObjects.length; j++) {\n                if (typeof objectDict[brickObjects[j]['checkSum']] === 'undefined') {\n                    objectDict[brickObjects[j]['checkSum']] = [];\n                }\n                objectDict[brickObjects[j]['checkSum']].push(brickObjects[j]['hash']);\n            }\n        });\n        return objectDict;\n    };\n\n    this.getTransformParameters = (brickId) => {\n        if (!brickId) {\n            return encryptionKey ? {key: encryptionKey} : {};\n        }\n\n        this.load();\n        let bricks = [];\n        const files = this.getFileList();\n\n        files.forEach(filePath => {\n            bricks = bricks.concat(header[filePath]);\n        });\n\n        const brickObj = bricks.find(brick => {\n            return brick.offset === brickId;\n        });\n\n        const addTransformData = {};\n        if (brickObj.key) {\n            addTransformData.key = Buffer.from(brickObj.key);\n        }\n\n        return addTransformData;\n    };\n\n    this.toBrick = () => {\n        this.load();\n        const brick = new Brick(archiveConfig);\n        brick.setTransformParameters({key: encryptionKey});\n        brick.setRawData(Buffer.from(JSON.stringify(header)));\n        return brick;\n    };\n\n    this.load = () => {\n        if (header instanceof Brick) {\n            header.setConfig(archiveConfig);\n            if (encryptionKey) {\n                header.setTransformParameters({key: encryptionKey});\n            }\n            header = JSON.parse(header.getRawData().toString());\n        }\n    };\n\n    this.setConfig = (config) => {\n        archiveConfig = config;\n    };\n\n    this.getConfig = () => {\n        return archiveConfig;\n    };\n\n    this.setEncryptionKey = (encKey) => {\n        encryptionKey = encKey;\n    };\n\n    this.removeFile = (filePath) => {\n        this.load();\n        delete header[filePath];\n    };\n}\n\nmodule.exports = FileBarMap;","const BarMap = require(\"./FileBarMap\");\nconst util = require(\"../utils/utilities\");\nconst fs = require(\"fs\");\nconst Brick = require(\"./Brick\");\nconst AsyncDispatcher = require(\"../utils/AsyncDispatcher\");\n\nfunction FileBrickStorage(filePath) {\n\n    let isFirstBrick = true;\n    let map;\n    let mapOffset;\n\n    this.setBarMap = (barMap) => {\n        map = barMap;\n    };\n\n    this.putBrick = (brick, callback) => {\n        if (isFirstBrick) {\n            isFirstBrick = false;\n            const writeStream = fs.createWriteStream(filePath, {start: util.getBarMapOffsetSize()});\n            writeStream.on(\"error\", (err) => {\n                return callback(err);\n            });\n\n            writeStream.write(brick.getTransformedData(), callback);\n        } else {\n            fs.appendFile(filePath, brick.getTransformedData(), callback);\n        }\n    };\n\n    this.getBrick = (brickId, callback) => {\n        this.getBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n            let brickOffsets = [];\n            const fileList = barMap.getFileList();\n            fileList.forEach(file => {\n                brickOffsets = brickOffsets.concat(barMap.getHashList(file));\n            });\n\n            const brickIndex = brickOffsets.findIndex(el => {\n                return el === brickId;\n            });\n\n            let nextBrickId = brickOffsets[brickIndex + 1];\n            if (!nextBrickId) {\n                nextBrickId = Number(mapOffset);\n            }\n\n            readBrick(brickId, nextBrickId, callback);\n        });\n\n    };\n\n    this.deleteFile = (fileName, callback) => {\n        this.getBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            barMap.removeFile(fileName);\n            this.putBarMap(barMap, callback);\n        });\n    };\n\n\n    this.putBarMap = (barMap, callback) => {\n        map = barMap;\n        readBarMapOffset((err, offset) => {\n            if(offset) {\n                offset = Number(offset);\n                fs.truncate(filePath, offset, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    __writeBarMap(offset);\n                });\n            }else{\n                fs.stat(filePath, (err, stats) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    const barMapOffset = stats.size;\n\n                    const bufferBarMapOffset = Buffer.alloc(util.getBarMapOffsetSize());\n                    bufferBarMapOffset.writeBigUInt64LE(BigInt(barMapOffset));\n                    mapOffset = barMapOffset;\n                    const offsetWriteStream = fs.createWriteStream(filePath, {flags: \"r+\", start: 0});\n\n                    offsetWriteStream.on(\"error\", (err) => {\n                        return callback(err);\n                    });\n\n                    offsetWriteStream.write(bufferBarMapOffset, (err) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        __writeBarMap(barMapOffset);\n                    });\n                });\n            }\n        });\n\n        function __writeBarMap(offset) {\n            const mapWriteStream = fs.createWriteStream(filePath, {flags: \"r+\", start: offset});\n            mapWriteStream.on(\"error\", (err) => {\n                return callback(err);\n            });\n\n            const mapBrick = barMap.toBrick();\n            mapBrick.setTransformParameters(barMap.getTransformParameters());\n            mapWriteStream.write(mapBrick.getTransformedData(), callback);\n        }\n\n    };\n\n    this.getBarMap = (mapDigest, callback) => {\n        if (typeof mapDigest === \"function\") {\n            callback = mapDigest;\n        }\n\n        if (map) {\n            return callback(undefined, map);\n        }\n\n        readBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            map = barMap;\n            callback(undefined, barMap);\n        });\n    };\n\n    //------------------------------------------ Internal functions ---------------------------------------------------\n\n    function readBarMapOffset(callback) {\n        const readStream = fs.createReadStream(filePath, {start: 0, end: util.getBarMapOffsetSize() - 1});\n\n        const buffer = Buffer.alloc(util.getBarMapOffsetSize());\n        let offsetBuffer = 0;\n\n        readStream.on(\"data\", (chunk) => {\n            chunk.copy(buffer, offsetBuffer);\n            offsetBuffer += chunk.length;\n        });\n\n        readStream.on(\"end\", () => {\n            callback(undefined, buffer.readBigUInt64LE());\n        });\n\n        readStream.on(\"error\", (err) => {\n            return callback(err);\n        });\n    }\n\n    function readBarMap(callback) {\n        readBarMapOffset((err, barMapOffset) => {\n            if (err) {\n                if (err.code === \"ENOENT\") {\n                    return callback(undefined, new BarMap());\n                }\n\n                return callback(err)\n            }\n\n            mapOffset = barMapOffset;\n            const readStream = fs.createReadStream(filePath, {start: Number(barMapOffset)});\n            let barMapData = Buffer.alloc(0);\n\n            readStream.on(\"data\", (chunk) => {\n                barMapData = Buffer.concat([barMapData, chunk]);\n            });\n\n            readStream.on(\"error\", (err) => {\n                return callback(err);\n            });\n\n            readStream.on(\"end\", () => {\n                const mapBrick = new Brick();\n                mapBrick.setTransformedData(barMapData);\n                callback(undefined, new BarMap(mapBrick));\n            });\n        });\n    }\n\n    function readBrick(brickOffsetStart, brickOffsetEnd, callback) {\n        const readStream = fs.createReadStream(filePath, {start: brickOffsetStart, end: brickOffsetEnd - 1});\n        let brickData = Buffer.alloc(0);\n\n        readStream.on(\"data\", (chunk) => {\n            brickData = Buffer.concat([brickData, chunk]);\n        });\n\n        readStream.on(\"error\", (err) => {\n            return callback(err);\n        });\n\n        readStream.on(\"end\", () => {\n            const brick = new Brick();\n            brick.setTransformedData(brickData);\n            callback(undefined, brick);\n        });\n    }\n}\n\nmodule.exports = {\n    createFileBrickStorage(filePath) {\n        return new FileBrickStorage(filePath);\n    }\n};","const Brick = require(\"./Brick\");\nconst pathModule = \"path\";\nlet path;\ntry {\n    path = require(pathModule);\n} catch (err) {\n} finally {\n    if (typeof path === \"undefined\") {\n        path = {sep: \"/\"};\n    }\n}\n\nfunction FolderBarMap(header) {\n    header = header || {};\n    const pskPath = require(\"swarmutils\").path;\n    let archiveConfig;\n    let encryptionKey;\n\n    this.add = (filePath, brick) => {\n        filePath = pskPath.normalize(filePath);\n        if (filePath === \"\") {\n            throw Error(\"Invalid path\");\n        }\n        this.load();\n        const pathSegments = filePath.split(\"/\");\n        __addFileRecursively(header, pathSegments, brick);\n\n        function __addFileRecursively(barMapObj, splitPath, brick) {\n            let fileName = splitPath.shift();\n            if (fileName === \"\") {\n                fileName = splitPath.shift();\n            }\n            if (splitPath.length === 0) {\n                const brickObj = {\n                    checkSum: brick.getAdler32(),\n                    hash: brick.getHash()\n                };\n\n                const encKey = brick.getTransformParameters() ? brick.getTransformParameters().key : undefined;\n                if (encKey) {\n                    brickObj.key = encKey;\n                }\n\n\n                if (!barMapObj[fileName]) {\n                    barMapObj[fileName] = [];\n                }\n\n\n                barMapObj[fileName].push(brickObj);\n            } else {\n                if (!barMapObj[fileName]) {\n                    barMapObj[fileName] = {};\n                }\n                __addFileRecursively(barMapObj[fileName], splitPath, brick);\n            }\n        }\n    };\n\n    this.isInHeader = (filePath) => {\n        return header[filePath] !== undefined;\n    };\n\n    this.removeBrick = (filePath, brickHash) => {\n        let indexToRemove = header[filePath].findIndex(brickObj => brickObj.hash === brickHash);\n        header[filePath].splice(indexToRemove, 1);\n    };\n\n    this.delete = (barPath) => {\n        barPath = pskPath.normalize(barPath);\n\n        if (barPath === \"/\") {\n            header = {};\n        } else {\n            const pathSegments = barPath.split(\"/\");\n            if (pathSegments[0] === \"\") {\n                pathSegments.shift();\n            }\n            __removeRecursively(header, pathSegments);\n        }\n\n        function __removeRecursively(folderObj, splitPath) {\n            const folderName = splitPath.shift();\n            if (folderObj[folderName]) {\n                if (splitPath.length === 0) {\n                    folderObj[folderName] = undefined;\n                } else {\n                    __removeRecursively(folderObj[folderName], splitPath);\n                }\n            }\n        }\n    };\n\n    this.getHashList = (filePath) => {\n        filePath = pskPath.normalize(filePath);\n        if (filePath === \"\") {\n            throw Error(\"Invalid path.\");\n        }\n        this.load();\n        const pathSegments = filePath.split(\"/\");\n\n        return __getHashListRecursively(header, pathSegments);\n\n        function __getHashListRecursively(barMapObj, pathSegments) {\n            let folderName = pathSegments.shift();\n            if (folderName === \"\") {\n                folderName = pathSegments.shift();\n            }\n            if (barMapObj[folderName]) {\n                if (pathSegments.length === 0) {\n                    return barMapObj[folderName].map(brickObj => brickObj.hash);\n                } else {\n                    return __getHashListRecursively(barMapObj[folderName], pathSegments);\n                }\n            } else {\n                throw Error(`Invalid path ${filePath}`);\n            }\n        }\n    };\n\n    this.getCheckSumList = (filePath) => {\n        this.load();\n        return header[filePath].map(brickObj => brickObj.checkSum);\n    };\n\n    this.isEmpty = (filePath) => {\n        filePath = pskPath.normalize(filePath);\n        this.load();\n\n        if (filePath === \"/\") {\n            return Object.keys(header).length === 0;\n        } else {\n            const pathSegments = filePath.split(\"/\");\n            return __checkIsEmptyRecursively(header, pathSegments);\n        }\n\n        function __checkIsEmptyRecursively(folderObj, pathSegments) {\n            if (Object.keys(folderObj).length === 0) {\n                return true;\n            }\n\n            let folderName = pathSegments.shift();\n            if (folderName === \"\") {\n                folderName = pathSegments.shift();\n            }\n\n            if (folderObj[folderName]) {\n                if (pathSegments.length === 0) {\n                    if (Array.isArray(folderObj[folderName])) {\n                        return folderObj[folderName].length === 0;\n                    } else {\n                        return Object.keys(folderObj[folderName]).length === 0;\n                    }\n                } else {\n                    return __checkIsEmptyRecursively(folderObj[folderName], pathSegments);\n                }\n            } else {\n                return true;\n            }\n        }\n    };\n\n    this.emptyList = (filePath) => {\n        filePath = pskPath.normalize(filePath);\n        this.load();\n\n        const pathSegments = filePath.split(\"/\");\n        __emptyListRecursively(header, pathSegments);\n\n        function __emptyListRecursively(folderObj, pathSegments) {\n            let folderName = pathSegments.shift();\n            if (folderName === \"\") {\n                folderName = pathSegments.shift();\n            }\n\n            if (folderObj[folderName]) {\n                if (pathSegments.length === 0) {\n                    if (Array.isArray(folderObj[folderName])) {\n                        folderObj[folderName] = []\n                    } else {\n                        throw Error(\"Invalid path\");\n                    }\n                } else {\n                    __emptyListRecursively(folderObj[folderName], pathSegments);\n                }\n            }\n        }\n    };\n\n\n    this.toBrick = () => {\n        this.load();\n        archiveConfig.setIsEncrypted(true);\n        const brick = new Brick(archiveConfig);\n        if (encryptionKey) {\n            brick.setTransformParameters({key: encryptionKey});\n        }\n        brick.setRawData(Buffer.from(JSON.stringify(header)));\n        return brick;\n    };\n\n\n    this.getFileList = (folderBarPath, recursive) => {\n        if (typeof recursive === \"undefined\") {\n            recursive = true;\n        }\n        folderBarPath = pskPath.normalize(folderBarPath);\n        this.load();\n        return getFilesFromPath(header, folderBarPath, recursive);\n\n\n        function getFilesFromPath(folderObj, barPath, recursive){\n            let files = [];\n            if (barPath === \"/\") {\n                __getAllFiles(header, barPath);\n\n                return files;\n            } else {\n                const pathSegments = barPath.split(\"/\");\n                __getFilesFromPath(header, pathSegments);\n\n                return files;\n            }\n\n            function __getFilesFromPath(folderObj, pathSegments) {\n                let folderName = pathSegments.shift();\n                if (folderName === \"\") {\n                    folderName = pathSegments.shift();\n                }\n                if (folderObj[folderName]) {\n                    if (pathSegments.length === 0) {\n                        Object.keys(folderObj[folderName]).forEach(file => {\n                            if (Array.isArray(folderObj[folderName][file])) {\n                                files.push(file);\n                            }\n                        });\n                    } else {\n                        if (recursive === true) {\n                            __getFilesFromPath(folderObj[folderName], pathSegments);\n                        }\n                    }\n                } else {\n                    throw Error(`Invalid path ${folderBarPath}`);\n                }\n            }\n\n            function __getAllFiles(folderObj, relativePath) {\n                Object.keys(folderObj).forEach(folderName => {\n                    if (folderObj[folderName]) {\n                        let newPath = pskPath.join(relativePath, folderName);\n\n                        if (Array.isArray(folderObj[folderName])) {\n                            files.push(newPath);\n                        } else {\n                            if (recursive === true) {\n                                __getAllFiles(folderObj[folderName], newPath);\n                            }\n                        }\n                    }\n                });\n            }\n        }\n    };\n\n    this.getFolderList = (barPath, recursive) => {\n        barPath = pskPath.normalize(barPath);\n        let folders = [];\n        if (barPath === \"/\") {\n            __getAllFolders(header, barPath, recursive);\n            return folders;\n        } else {\n            const pathSegments = barPath.split(\"/\");\n            __getFoldersFromPath(header, pathSegments, \"/\", recursive);\n            return folders;\n        }\n\n        function __getAllFolders(folderObj, relativePath, recursive) {\n            Object.keys(folderObj).forEach(folderName => {\n                if (typeof folderObj[folderName] === \"object\" && !Array.isArray(folderObj[folderName])) {\n                    const newPath = pskPath.join(relativePath, folderName);\n                    folders.push(newPath);\n                    if (recursive === true) {\n                        __getAllFolders(folderObj[folderName], newPath);\n                    }\n                }\n            });\n        }\n\n        function __getFoldersFromPath(folderObj, pathSegments, relativePath, recursive) {\n            let folderName = pathSegments.shift();\n            if (folderName === \"\") {\n                folderName = pathSegments.shift();\n            }\n            if (folderObj[folderName]) {\n                const newFolderPath = pskPath.join(relativePath, folderName);\n                if (pathSegments.length === 0) {\n                    folders.push(newFolderPath);\n                    Object.keys(folderObj[folderName]).forEach(fileName => {\n                        if (typeof folderObj[folderName][fileName] === \"object\" && !Array.isArray(folderObj[folderName][fileName])) {\n                            const newFilePath = pskPath.join(relativePath, fileName);\n                            folders.push(newFilePath);\n                            if (recursive === true) {\n                                __getFoldersFromPath(folderObj[folderName][fileName], pathSegments, newFilePath, recursive);\n                            }\n                        }\n                    });\n                } else {\n                    __getFoldersFromPath(folderObj[folderName], pathSegments, newFolderPath, recursive);\n                }\n            }\n        }\n    };\n\n    this.getTransformParameters = (brickId) => {\n        this.load();\n        if (!brickId) {\n            return encryptionKey ? {key: encryptionKey} : undefined;\n        }\n        let bricks = [];\n        const files = this.getFileList(\"/\", true);\n        files.forEach(file => {\n            bricks = bricks.concat(getBricksForFile(file));\n        });\n\n        const brickObj = bricks.find(brick => {\n            return brick.hash === brickId;\n        });\n\n        const addTransformData = {};\n        if (brickObj.key) {\n            addTransformData.key = Buffer.from(brickObj.key);\n        }\n\n        return addTransformData;\n    };\n\n    this.load = () => {\n        if (header instanceof Brick) {\n            header.setConfig(archiveConfig);\n            header.setTransformParameters({key: encryptionKey});\n            header = JSON.parse(header.getRawData().toString());\n        } else {\n            if (Buffer.isBuffer(header)) {\n                header = header.toString();\n            }\n\n            if (typeof header === \"string\") {\n                header = JSON.parse(header);\n            }\n        }\n    };\n\n    this.setConfig = (config) => {\n        archiveConfig = config;\n    };\n\n    this.getConfig = () => {\n        return archiveConfig;\n    };\n\n    this.setEncryptionKey = (encKey) => {\n        encryptionKey = encKey;\n    };\n\n    this.removeFile = (filePath) => {\n        this.load();\n        delete header[filePath];\n    };\n\n    function getBricksForFile(filePath) {\n        filePath = pskPath.normalize(filePath);\n        const splitPath = filePath.split(\"/\");\n        return __getBricksForFileRecursively(header, splitPath);\n\n\n        function __getBricksForFileRecursively(folderObj, splitPath) {\n            let folderName = splitPath.shift();\n            if (folderName === \"\") {\n                folderName = splitPath.shift();\n            }\n            if (folderObj[folderName]) {\n                if (splitPath.length === 0) {\n                    if (Array.isArray(folderObj[folderName])) {\n                        return folderObj[folderName];\n                    } else {\n                        throw Error(\"Invalid path\");\n                    }\n                } else {\n                    return __getBricksForFileRecursively(folderObj[folderName], splitPath);\n                }\n            } else {\n                throw Error(\"Invalid path\");\n            }\n        }\n    }\n}\n\nmodule.exports = FolderBarMap;","const fs = require(\"fs\");\nconst path = require(\"path\");\nconst BarMap = require(\"./FolderBarMap\");\nconst Brick = require(\"./Brick\");\n\nfunction FolderBrickStorage(location) {\n    let map;\n\n    this.setBarMap = (barMap) => {\n        map = barMap;\n    };\n\n    this.putBrick = (brick, callback) => {\n        const writeStream = fs.createWriteStream(path.join(location, brick.getHash()));\n        writeStream.write(brick.getTransformedData(), (...args) => {\n            writeStream.end();\n            callback(...args);\n        });\n    };\n\n    this.getBrick = (brickHash, callback) => {\n        fs.readFile(path.join(location, brickHash), (err, brickData) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const brick = new Brick();\n            brick.setTransformedData(brickData);\n            callback(err, brick);\n        });\n    };\n\n    this.deleteFile = (filePath, callback) => {\n        this.getBarMap((err, barMap) => {\n            if (err) {\n                return callback(err);\n            }\n\n            fs.unlink(path.join(location, barMap.toBrick().getHash()), (err) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                barMap.removeFile(filePath);\n                this.putBarMap(barMap, callback);\n            });\n        });\n    };\n\n    this.putBarMap = (barMap, callback) => {\n        map = barMap;\n        const barMapBrick = barMap.toBrick();\n        barMapBrick.setTransformParameters(barMap.getTransformParameters());\n       \n        let brickId = barMapBrick.getKey();\n        if (!brickId) {\n            brickId = barMapBrick.getHash();\n        }\n\n        barMapBrick.setKey(brickId);\n        const writeStream = fs.createWriteStream(path.join(location, brickId));\n        writeStream.write(barMapBrick.getTransformedData(), (err) => {\n            writeStream.end();\n            callback(err, barMapBrick.getSeed());\n        });\n    };\n\n    this.getBarMap = (mapDigest, callback) => {\n        if (typeof mapDigest === \"function\") {\n            callback = mapDigest;\n            mapDigest = undefined;\n        }\n\n        if (map) {\n            return callback(undefined, map);\n        }\n\n        if (typeof mapDigest === \"undefined\") {\n            return callback(undefined, new BarMap());\n        }\n\n        this.getBrick(mapDigest, (err, mapBrick) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const barMap = new BarMap(mapBrick);\n            map = barMap;\n            callback(undefined, barMap);\n        });\n    }\n}\n\nmodule.exports = {\n    createFolderBrickStorage(location) {\n        return new FolderBrickStorage(location);\n    }\n};","const crypto = require(\"pskcrypto\");\nconst base58 = require(\"./base58\");\n\nfunction Seed(compactSeed, endpoint, key) {\n    let seed;\n    const keyLen = 32;\n    init();\n\n    this.getCompactForm = () => {\n        if (!seed) {\n            throw Error(\"Cannot return seed\");\n        }\n\n        return generateCompactForm(seed);\n    };\n\n    this.getEndpoint = () => {\n        if (!seed) {\n            throw Error(\"Cannot retrieve endpoint\");\n        }\n\n        return seed.endpoint;\n    };\n\n    this.getAnchorURL = () => {\n        if (!seed.key) {\n            return;\n        }\n        return seed.endpoint + \"/\" + crypto.pskHash(seed.key, \"hex\");\n    };\n\n    this.getKey = () => {\n        return crypto.pskHash(seed.key, \"hex\");\n    };\n    this.setKey = (key) => {\n        seed.key = key;\n    };\n\n    this.getEncryptionKey = (algorithm) => {\n        return crypto.deriveKey(algorithm, generateCompactForm(seed));\n    };\n\n    //--------------------------------------- internal methods --------------------------------------------\n    function init() {\n        if (!compactSeed) {\n            seed = create();\n        } else {\n            seed = load(compactSeed);\n        }\n    }\n\n    function create() {\n        const localSeed = {};\n        localSeed.key = key;\n        if (!key) {\n            //Bugfix: randomBytes in browser returns an Uint8Array object that has a wrong constructor and prototype\n            //that is why we create a new instance of Buffer/Uint8Array based on the result of randomBytes\n            localSeed.key = Buffer.from(crypto.randomBytes(keyLen));\n            //TODO: why don't we use ID Generator from swarmutils?\n        }\n\n        if (endpoint) {\n            localSeed.endpoint = endpoint;\n        } else {\n            throw Error(\"The SEED could not be created because an endpoint was not provided.\")\n        }\n\n        return localSeed;\n    }\n\n    function generateCompactForm(expandedSeed) {\n        if (typeof expandedSeed === \"string\") {\n            return expandedSeed;\n        }\n\n        if (!expandedSeed.key) {\n            throw Error(\"The seed does not contain an id\");\n        }\n        let compactSeed = expandedSeed.key.toString(\"hex\");\n        if (expandedSeed.endpoint) {\n            compactSeed += '|' + expandedSeed.endpoint.toString();\n        }\n\n        return base58.encode(compactSeed);\n    }\n\n    function load(compactFormSeed) {\n        if (typeof compactFormSeed === \"undefined\") {\n            throw new Error(`Expected type string or Buffer. Received undefined`);\n        }\n\n        if (typeof compactFormSeed !== \"string\") {\n            if (typeof compactFormSeed === \"object\" && !Buffer.isBuffer(compactFormSeed)) {\n                compactFormSeed = Buffer.from(compactFormSeed);\n            }\n\n            compactFormSeed = compactFormSeed.toString();\n        }\n\n        const localSeed = {};\n        const splitCompactSeed = base58.decode(compactFormSeed).toString().split('|');\n        localSeed.key = Buffer.from(splitCompactSeed[0], \"hex\");\n\n        if (splitCompactSeed[1] && splitCompactSeed[1].length > 0) {\n            localSeed.endpoint = splitCompactSeed[1];\n        } else {\n            throw new Error('Cannot find endpoint in compact seed');\n        }\n\n        return localSeed;\n    }\n}\n\nmodule.exports = Seed;\n\n","const ALPHABET = \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\";\nconst BASE = ALPHABET.length;\nconst LEADER = ALPHABET.charAt(0);\nconst FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up\nconst iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up\n\nconst BASE_MAP = Buffer.alloc(256);\nfor (let j = 0; j < BASE_MAP.length; j++) {\n    BASE_MAP[j] = 255\n}\nfor (let i = 0; i < ALPHABET.length; i++) {\n    let x = ALPHABET.charAt(i);\n    let xc = x.charCodeAt(0);\n    if (BASE_MAP[xc] !== 255) {\n        throw new TypeError(x + ' is ambiguous');\n    }\n    BASE_MAP[xc] = i;\n}\n\nfunction encode(source) {\n    if (Array.isArray(source) || source instanceof Uint8Array || typeof source === \"string\") {\n        source = Buffer.from(source);\n    }\n    if (!Buffer.isBuffer(source)) {\n        throw new TypeError('Expected Buffer');\n    }\n    if (source.length === 0) {\n        return '';\n    }\n    // Skip & count leading zeroes.\n    let zeroes = 0;\n    let length = 0;\n    let pbegin = 0;\n    const pend = source.length;\n    while (pbegin !== pend && source[pbegin] === 0) {\n        pbegin++;\n        zeroes++;\n    }\n    // Allocate enough space in big-endian base58 representation.\n    const size = ((pend - pbegin) * iFACTOR + 1) >>> 0;\n    const b58 = Buffer.alloc(size);\n    // Process the bytes.\n    while (pbegin !== pend) {\n        let carry = source[pbegin];\n        // Apply \"b58 = b58 * 256 + ch\".\n        let i = 0;\n        for (let it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {\n            carry += (256 * b58[it1]) >>> 0;\n            b58[it1] = (carry % BASE) >>> 0;\n            carry = (carry / BASE) >>> 0;\n        }\n        if (carry !== 0) {\n            throw new Error('Non-zero carry');\n        }\n        length = i;\n        pbegin++;\n    }\n    // Skip leading zeroes in base58 result.\n    let it2 = size - length;\n    while (it2 !== size && b58[it2] === 0) {\n        it2++;\n    }\n    // Translate the result into a string.\n    let str = LEADER.repeat(zeroes);\n    for (; it2 < size; ++it2) {\n        str += ALPHABET.charAt(b58[it2]);\n    }\n    return str;\n}\n\nfunction decode(source) {\n    if (typeof source !== 'string') {\n        throw new TypeError('Expected String');\n    }\n    if (source.length === 0) {\n        return Buffer.alloc(0);\n    }\n    let psz = 0;\n    // Skip leading spaces.\n    if (source[psz] === ' ') {\n        return;\n    }\n    // Skip and count leading '1's.\n    let zeroes = 0;\n    let length = 0;\n    while (source[psz] === LEADER) {\n        zeroes++;\n        psz++;\n    }\n    // Allocate enough space in big-endian base256 representation.\n    const size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.\n    const b256 = Buffer.alloc(size);\n    // Process the characters.\n    while (source[psz]) {\n        // Decode character\n        let carry = BASE_MAP[source.charCodeAt(psz)];\n        // Invalid character\n        if (carry === 255) {\n            return;\n        }\n        let i = 0;\n        for (let it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {\n            carry += (BASE * b256[it3]) >>> 0;\n            b256[it3] = (carry % 256) >>> 0;\n            carry = (carry / 256) >>> 0;\n        }\n        if (carry !== 0) {\n            throw new Error('Non-zero carry');\n        }\n        length = i;\n        psz++;\n    }\n    // Skip trailing spaces.\n    if (source[psz] === ' ') {\n        return;\n    }\n    // Skip leading zeroes in b256.\n    let it4 = size - length;\n    while (it4 !== size && b256[it4] === 0) {\n        it4++;\n    }\n    const vch = Buffer.alloc(zeroes + (size - it4));\n    vch.fill(0x00, 0, zeroes);\n    let j = zeroes;\n    while (it4 !== size) {\n        vch[j++] = b256[it4++];\n    }\n    return vch;\n}\n\nmodule.exports = {\n    encode,\n    decode\n};","function BrickTransform(transformGenerator) {\n    let directTransform;\n    let inverseTransform;\n\n    this.getTransformParameters = () => {\n        return directTransform ? directTransform.transformParameters : undefined;\n    };\n\n    this.applyDirectTransform = (data, transformParameters) => {\n        if (!directTransform) {\n            directTransform = transformGenerator.createDirectTransform(transformParameters);\n        }\n\n        if (!directTransform) {\n            return undefined;\n        }\n\n        let transformedData = directTransform.transform(data);\n\n        if(directTransform.transformParameters){\n            if (directTransform.transformParameters.iv) {\n                transformedData = Buffer.concat([transformedData, directTransform.transformParameters.iv]);\n            }\n\n            if (directTransform.transformParameters.aad) {\n                transformedData = Buffer.concat([transformedData, directTransform.transformParameters.aad]);\n            }\n\n            if (directTransform.transformParameters.tag) {\n                transformedData = Buffer.concat([transformedData, directTransform.transformParameters.tag]);\n            }\n        }\n\n        return transformedData;\n    };\n\n    this.applyInverseTransform = (data, transformParameters) => {\n        const inverseTransformParams = transformGenerator.getInverseTransformParameters(data);\n        if(inverseTransformParams.params) {\n            Object.keys(inverseTransformParams.params).forEach(param => transformParameters[param] = inverseTransformParams.params[param]);\n        }\n\n        if (!inverseTransform) {\n            inverseTransform = transformGenerator.createInverseTransform(transformParameters);\n        }\n\n        return inverseTransform ? inverseTransform.transform(inverseTransformParams.data) : undefined;\n    };\n}\n\nmodule.exports = BrickTransform;\n\n","const CompressionGenerator = require(\"./CompressionGenerator\");\nconst EncryptionGenerator= require(\"./EncryptionGenerator\");\nconst CompressionEncryptionGenerator = require(\"./CompressionEncryptionGenerator\");\nconst BrickTransform = require(\"./BrickTransform\");\n\nfunction BrickTransformFactory() {\n    this.createBrickTransform = function (config) {\n        if (!config) {\n            return;\n        }\n\n        const encryption = config.getEncryptionAlgorithm();\n        const compression = config.getCompressionAlgorithm();\n\n        let generator;\n        if (!encryption && !compression) {\n            return;\n        }\n\n        if (compression) {\n            if (encryption) {\n                generator = new CompressionEncryptionGenerator(config);\n            } else {\n                generator = new CompressionGenerator(config);\n            }\n        }else{\n            generator = new EncryptionGenerator(config);\n        }\n\n        return new BrickTransform(generator);\n    }\n}\n\nmodule.exports = BrickTransformFactory;\n\n","const CompressionGenerator = require(\"./CompressionGenerator\");\nconst EncryptionGenerator = require(\"./EncryptionGenerator\");\n\nfunction CompressionEncryptionGenerator(config) {\n    let compressionGenerator = new CompressionGenerator(config);\n    let encryptionGenerator = new EncryptionGenerator(config);\n\n    this.getInverseTransformParameters = (transformedData) => {\n        return encryptionGenerator.getInverseTransformParameters(transformedData);\n    };\n\n    this.createDirectTransform = (transformParameters) => {\n        const compression = compressionGenerator.createDirectTransform();\n        const encryption = encryptionGenerator.createDirectTransform(transformParameters);\n        const compressionEncryption = {};\n        Object.keys(encryption).forEach(key => {\n            compressionEncryption[key] = encryption[key]\n        });\n\n        compressionEncryption.transform = (data) => {\n            return encryption.transform(compression.transform(data));\n        };\n\n        return compressionEncryption;\n    };\n\n    this.createInverseTransform = (transformParameters) => {\n        const decompression = compressionGenerator.createInverseTransform();\n        const decryption = encryptionGenerator.createInverseTransform(transformParameters);\n        const compressionEncryption = {};\n        Object.keys(decompression).forEach(key => {\n            compressionEncryption[key] = decompression[key]\n        });\n        compressionEncryption.transform = (data) => {\n            return decompression.transform(decryption.transform(data));\n        };\n\n        return compressionEncryption;\n    };\n}\n\nmodule.exports = CompressionEncryptionGenerator;","const zlib = require(\"zlib\");\n\nfunction CompressionGenerator(config) {\n\n    this.getInverseTransformParameters = (transformedData) => {\n        return {data: transformedData};\n    };\n\n    this.createDirectTransform = () => {\n        return getCompression(true);\n    };\n\n    this.createInverseTransform = () => {\n        return getCompression(false);\n    };\n\n    function getCompression(isCompression) {\n        const algorithm = config.getCompressionAlgorithm();\n        switch (algorithm) {\n            case \"gzip\":\n                return __createCompress(zlib.gzipSync, zlib.gunzipSync, isCompression);\n            case \"br\":\n                return __createCompress(zlib.brotliCompressSync, zlib.brotliDecompressSync, isCompression);\n            case \"deflate\":\n                return __createCompress(zlib.deflateSync, zlib.inflateSync, isCompression);\n            case \"deflateRaw\":\n                return __createCompress(zlib.deflateRawSync, zlib.inflateRawSync, isCompression);\n            default:\n                return;\n        }\n    }\n\n    function __createCompress(compress, decompress, isCompression) {\n        const options = config.getCompressionOptions();\n        if (!isCompression) {\n            return {\n                transform(data) {\n                    return decompress(data, options);\n                }\n            }\n        }\n\n        return {\n            transform(data) {\n                return compress(data, options);\n            }\n        }\n    }\n}\n\nmodule.exports = CompressionGenerator;\n\n","const crypto = require(\"pskcrypto\");\n\nfunction EncryptionGenerator(config) {\n    let key;\n    const pskEncryption = crypto.createPskEncryption(config.getEncryptionAlgorithm());\n    this.setConfig = (newConfig) => {\n        config = newConfig;\n    };\n\n    this.getInverseTransformParameters = (transformedData) => {\n        let decryptionParameters = pskEncryption.getDecryptionParameters(transformedData);\n        const data = decryptionParameters.data;\n        delete decryptionParameters.data;\n        return {\n            data: data,\n            params: decryptionParameters\n        };\n    };\n\n    this.createDirectTransform = (transformParameters) => {\n        return getEncryption(transformParameters);\n    };\n\n    this.createInverseTransform = (transformParameters) => {\n        return getDecryption(transformParameters);\n    };\n\n    //--------------------------------------- internal methods ------------------------------------------------------\n    function getEncryption(transformParameters) {\n        const algorithm = config.getEncryptionAlgorithm();\n        if (!algorithm) {\n            return;\n        }\n\n        if (config.getIsEncrypted() === false) {\n            return;\n        }\n\n        const encOptions = config.getEncryptionOptions();\n        if (transformParameters && transformParameters.key) {\n            key = transformParameters.key;\n        } else {\n            key = pskEncryption.generateEncryptionKey(algorithm);\n        }\n\n\n        const ret = {\n            transform(data) {\n                const encData = pskEncryption.encrypt(data, key, encOptions);\n                ret.transformParameters = pskEncryption.getEncryptionParameters();\n                return encData;\n            }\n        };\n\n        return ret;\n    }\n\n\n    function getDecryption(transformConfig) {\n        const algorithm = config.getEncryptionAlgorithm();\n        if (!algorithm) {\n            return;\n        }\n\n        if (config.getIsEncrypted() === false) {\n            return;\n        }\n\n        const encOptions = config.getEncryptionOptions();\n        let authTagLength = 0;\n        if (!config.getEncryptionOptions() || !config.getAuthTagLength()) {\n            authTagLength = 16;\n        } else {\n            authTagLength = config.getAuthTagLength();\n        }\n\n        return {\n            transform(data) {\n                return pskEncryption.decrypt(data, transformConfig.key, authTagLength, encOptions);\n            }\n        }\n    }\n\n}\n\nmodule.exports = EncryptionGenerator;","\nfunction AsyncDispatcher(finalCallback) {\n\tlet results = [];\n\tlet errors = [];\n\n\tlet started = 0;\n\n\tfunction markOneAsFinished(err, res) {\n\t\tif(err) {\n\t\t\terrors.push(err);\n\t\t}\n\n\t\tif(arguments.length > 2) {\n\t\t\targuments[0] = undefined;\n\t\t\tres = arguments;\n\t\t}\n\n\t\tif(typeof res !== \"undefined\") {\n\t\t\tresults.push(res);\n\t\t}\n\n\t\tif(--started <= 0) {\n            return callCallback();\n\t\t}\n\t}\n\n\tfunction dispatchEmpty(amount = 1) {\n\t\tstarted += amount;\n\t}\n\n\tfunction callCallback() {\n\t    if(errors && errors.length === 0) {\n\t        errors = undefined;\n        }\n\n\t    if(results && results.length === 0) {\n\t        results = undefined;\n        }\n\n        finalCallback(errors, results);\n    }\n\n\treturn {\n\t\tdispatchEmpty,\n\t\tmarkOneAsFinished\n\t};\n}\n\nmodule.exports = AsyncDispatcher;","function isStream(stream){\n    return stream !== null && typeof stream === 'object' && typeof stream.pipe === 'function';\n}\n\nfunction isWritable(stream) {\n    return isStream(stream) &&\n        stream.writable !== false &&\n        typeof stream._write === 'function' &&\n        typeof stream._writableState === 'object';\n\n}\n\nfunction isReadable(stream) {\n    return isStream(stream) &&\n        stream.readable !== false &&\n        typeof stream._read === 'function' &&\n        typeof stream._readableState === 'object';\n}\n\nfunction isDuplex(stream){\n    return isWritable(stream) &&\n        isReadable(stream);\n}\n\nmodule.exports = {\n    isStream,\n    isReadable,\n    isWritable,\n    isDuplex\n};\n","const fs = require('fs');\nconst OFFSET_SIZE = 8;\n\nfunction getBarMapOffsetSize() {\n    return OFFSET_SIZE;\n}\n\nfunction ensureFileDoesNotExist(filePath, callback) {\n    fs.access(filePath, (err) => {\n        if (!err) {\n            fs.unlink(filePath, callback);\n        } else {\n            return callback();\n        }\n    });\n}\n\nmodule.exports = {getBarMapOffsetSize, ensureFileDoesNotExist};","function EDFSBrickStorage(endpoint) {\n\n    const bar = require(\"bar\");\n    const brickTransportStrategy = $$.brickTransportStrategiesRegistry.get(endpoint);\n    let map;\n\n    this.setBarMap = function (barMap) {\n        map = barMap;\n    };\n\n    this.putBrick = function (brick, callback) {\n        brickTransportStrategy.send(brick.getHash(), brick.getTransformedData(), callback);\n    };\n\n    this.getBrick = function (brickHash, callback) {\n\n        brickTransportStrategy.get(brickHash, (err, brickData) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const brick = bar.createBrick();\n            brick.setTransformedData(brickData);\n\n            if (brickHash !== brick.getHash()) {\n                return callback(Error(\"The received data is invalid\"));\n            }\n            callback(undefined, brick);\n        });\n    };\n\n    this.deleteBrick = function (brickHash, callback) {\n        throw new Error(\"Not implemented\");\n    };\n\n    this.putBarMap = function (barMap, callback) {\n        map = barMap;\n        const barMapBrick = barMap.toBrick();\n        barMapBrick.setTransformParameters(barMap.getTransformParameters());\n\n        let brickId = barMapBrick.getKey();\n        if (!brickId) {\n            brickId = barMapBrick.getHash();\n            barMapBrick.setKey(brickId);\n        }\n\n        brickTransportStrategy.getHashForAlias(brickId, (err, hashesList) => {\n            if (err) {\n                return callback(err);\n            }\n\n            if (hashesList.length === 0) {\n                __sendBarMapBrick();\n            } else {\n                const barMapHash = hashesList[hashesList.length - 1];\n                if (barMapHash !== barMapBrick.getHash()) {\n                    __sendBarMapBrick();\n                } else {\n                    callback();\n                }\n            }\n\n            function __sendBarMapBrick() {\n                brickTransportStrategy.attachHashToAlias(brickId, barMapBrick.getHash(), (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n\n                    brickTransportStrategy.send(barMapBrick.getHash(), barMapBrick.getTransformedData(), callback);\n                });\n            }\n        });\n    };\n\n    this.getBarMap = function (mapDigest, callback) {\n        if (typeof mapDigest === \"function\") {\n            callback = mapDigest;\n            mapDigest = undefined;\n        }\n\n        if (map) {\n            return callback(undefined, map);\n        }\n\n        if (typeof mapDigest === \"undefined\") {\n            return callback(undefined, bar.createBarMap());\n        }\n\n        brickTransportStrategy.getHashForAlias(mapDigest, (err, hashesList) => {\n            if (err) {\n                return callback(err);\n            }\n\n            let barMapId;\n            if (hashesList.length === 0) {\n                barMapId = mapDigest;\n            } else {\n                barMapId = hashesList[hashesList.length - 1];\n            }\n            brickTransportStrategy.get(barMapId, (err, barMapData) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                const mapBrick = bar.createBrick();\n                mapBrick.setTransformedData(barMapData);\n                if (barMapId !== mapBrick.getHash()) {\n                    return callback(Error(\"Invalid data received\"));\n                }\n                map = bar.createBarMap(mapBrick);\n                callback(undefined, map);\n            });\n        });\n    };\n}\n\nmodule.exports = EDFSBrickStorage;\n\n","\nfunction FetchBrickTransportStrategy(initialConfig) {\n    const url = initialConfig;\n    this.send = (name, data, callback) => {\n\n        fetch(url + \"/EDFS/\"+name, {\n            method: 'POST',\n            mode: 'cors',\n            headers: {\n                'Content-Type': 'application/octet-stream'\n            },\n            body: data\n        }).then(function(response) {\n            if(response.status>=400){\n                return callback(new Error(`An error occurred ${response.statusText}`))\n            }\n            return response.json().catch((err) => {\n                // This happens when the response is empty\n                return {};\n            });\n        }).then(function(data) {\n            callback(null, data)\n        }).catch(error=>{\n            callback(error);\n        });\n\n    };\n\n    this.get = (name, callback) => {\n        fetch(url + \"/EDFS/\"+name,{\n            method: 'GET',\n            mode: 'cors',\n            headers: {\n                'Content-Type': 'application/octet-stream'\n            },\n        }).then(response=>{\n            if(response.status>=400){\n                return callback(new Error(`An error occurred ${response.statusText}`))\n            }\n            return response.arrayBuffer();\n        }).then(arrayBuffer=>{\n                let buffer = new Buffer(arrayBuffer.byteLength);\n                let view = new Uint8Array(arrayBuffer);\n                for (let i = 0; i < buffer.length; ++i) {\n                    buffer[i] = view[i];\n                }\n\n            callback(null, buffer);\n        }).catch(error=>{\n            callback(error);\n        });\n    };\n\n    this.getHashForAlias = (alias, callback) => {\n        fetch(url + \"/EDFS/getVersions/\" + alias, {\n            method: 'GET',\n            mode: 'cors',\n            headers: {\n                'Content-Type': 'application/octet-stream'\n            },\n        }).then(response => {\n            if(response.status>=400){\n                return callback(new Error(`An error occurred ${response.statusText}`))\n            }\n            return response.json().then(data => {\n                callback(null, data);\n            }).catch(error => {\n                callback(error);\n            })\n        });\n    };\n\n    this.attachHashToAlias = (alias, name, callback) => {\n        fetch(url + '/EDFS/attachHashToAlias/' + name, {\n            method: 'POST',\n            mode: 'cors',\n            headers: {\n                'Content-Type': 'application/octet-stream'\n            },\n            body: alias\n        }).then(response => {\n            if(response.status>=400){\n                return callback(new Error(`An error occurred ${response.statusText}`))\n            }\n            return response.json().catch((err) => {\n                // This happens when the response is empty\n                return {};\n            });\n        }).then(data => {\n            callback(null, data);\n        }).catch(error => {\n            callback(error);\n        })\n    }\n\n    this.getLocator = () => {\n        return url;\n    };\n}\n//TODO:why we use this?\nFetchBrickTransportStrategy.prototype.FETCH_BRICK_TRANSPORT_STRATEGY = \"FETCH_BRICK_TRANSPORT_STRATEGY\";\nFetchBrickTransportStrategy.prototype.canHandleEndpoint = (endpoint) => {\n    return endpoint.indexOf(\"http:\") === 0 || endpoint.indexOf(\"https:\") === 0;\n};\n\n\nmodule.exports = FetchBrickTransportStrategy;\n","\nfunction HTTPBrickTransportStrategy(endpoint) {\n    require(\"psk-http-client\");\n\n    this.send = (name, data, callback) => {\n        $$.remote.doHttpPost(endpoint + \"/EDFS/\" + name, data, callback);\n    };\n\n    this.get = (name, callback) => {\n        $$.remote.doHttpGet(endpoint + \"/EDFS/\" + name, callback);\n    };\n\n    this.getHashForAlias = (alias, callback) => {\n        $$.remote.doHttpGet(endpoint + \"/EDFS/getVersions/\" + alias, (err, hashesList) => {\n            if(err) {\n                return callback(err)\n            }\n\n            callback(undefined, JSON.parse(hashesList.toString()))\n        });\n    };\n\n    this.attachHashToAlias = (alias, name, callback) => {\n        $$.remote.doHttpPost(endpoint + \"/EDFS/attachHashToAlias/\" + name, alias, callback);\n    };\n\n    this.getLocator = () => {\n        return endpoint;\n    };\n}\n\nHTTPBrickTransportStrategy.prototype.canHandleEndpoint = (endpoint) => {\n    return endpoint.indexOf(\"http:\") === 0 || endpoint.indexOf(\"https:\") === 0;\n};\n\nmodule.exports = HTTPBrickTransportStrategy;","function BrickTransportStrategiesRegistry() {\n    const strategies = {};\n\n    this.remove = (transportStrategyName) => {\n        strategies[transportStrategyName] = undefined;\n    };\n\n    this.add = (transportStrategyName, strategy) => {\n        if (typeof strategy.prototype.canHandleEndpoint === \"function\") {\n            strategies[transportStrategyName] = strategy;\n        } else {\n            throw Error(\"Missing function from strategy prototype\");\n        }\n    };\n\n    this.get = (endpoint) => {\n        if (typeof endpoint !== \"string\" || endpoint.length === 0) {\n            throw Error(`Invalid endpoint ${endpoint}, ${typeof endpoint} ${Buffer.isBuffer(endpoint)}`);\n        }\n\n        const strategyName = getStrategyNameFromEndpoint(endpoint);\n        if (!strategyName) {\n            throw Error(`No strategy available to handle endpoint ${endpoint}`);\n        }\n\n        return new strategies[strategyName](endpoint);\n    };\n\n    this.has = (transportStrategyName) => {\n        return strategies.hasOwnProperty(transportStrategyName);\n    };\n\n    function getStrategyNameFromEndpoint(endpoint) {\n        for(let key in strategies){\n            if (strategies[key] && strategies[key].prototype.canHandleEndpoint(endpoint)) {\n                return key;\n            }\n        }\n    }\n}\n\nif (!$$.brickTransportStrategiesRegistry) {\n    $$.brickTransportStrategiesRegistry = new BrickTransportStrategiesRegistry();\n}","function EDFS(endpoint, options) {\n    options = options || {};\n\n    const RawDossier = require(\"./RawDossier\");\n    const barModule = require(\"bar\");\n    const fsAdapter = require(\"bar-fs-adapter\");\n    const constants = require('../moduleConstants');\n    const cache = options.cache;\n\n    this.createRawDossier = () => {\n        return new RawDossier(endpoint, undefined, cache);\n    };\n\n    this.createBar = () => {\n        return barModule.createArchive(createArchiveConfig());\n    };\n\n    this.bootRawDossier = (seed, callback) => {\n        const rawDossier = new RawDossier(endpoint, seed, cache);\n        rawDossier.start(err => callback(err, rawDossier));\n    };\n\n    this.loadRawDossier = (seed) => {\n        return new RawDossier(endpoint, seed, cache);\n    };\n\n    this.loadBar = (seed) => {\n        return barModule.createArchive(createArchiveConfig(seed));\n    };\n\n    this.clone = (seed, callback) => {\n        const edfsBrickStorage = require(\"edfs-brick-storage\").create(endpoint);\n        const bar = this.loadBar(seed);\n        bar.clone(edfsBrickStorage, true, callback);\n    };\n\n    this.createWallet = (templateSeed, password, overwrite, callback) => {\n        if (typeof overwrite === \"function\") {\n            callback = overwrite;\n            overwrite = false;\n        }\n        const wallet = this.createRawDossier();\n        wallet.mount(\"/\" + constants.CSB.CODE_FOLDER, constants.CSB.CONSTITUTION_FOLDER, templateSeed, (err => {\n            if (err) {\n                return callback(err);\n            }\n\n            const seed = wallet.getSeed();\n            if (typeof password !== \"undefined\") {\n                require(\"../seedCage\").putSeed(seed, password, overwrite, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    callback(undefined, seed.toString());\n                });\n            } else {\n                callback(undefined, seed.toString());\n            }\n        }));\n    };\n\n    this.loadWallet = function (walletSeed, password, overwrite, callback) {\n        if (typeof overwrite === \"function\") {\n            callback = overwrite;\n            overwrite = password;\n            password = walletSeed;\n            walletSeed = undefined;\n        }\n        if (typeof walletSeed === \"undefined\") {\n            require(\"../seedCage\").getSeed(password, (err, seed) => {\n                if (err) {\n                    return callback(err);\n                }\n                let rawDossier = this.loadRawDossier(seed);\n\n                if (!rawDossier) {\n                    return callback(new Error(\"RawDossier is not available\"));\n                }\n                return callback(undefined, rawDossier);\n\n            });\n        } else {\n\n            let rawDossier = this.loadRawDossier(walletSeed);\n\n            if (!rawDossier) {\n                return callback(new Error(\"RawDossier is not available\"));\n            }\n\n\n            if (typeof password !== \"undefined\" && password !== null) {\n                require(\"../seedCage\").putSeed(walletSeed, password, overwrite, (err) => {\n                    if (err) {\n                        return callback(err);\n                    }\n                    callback(undefined, rawDossier);\n                });\n            } else {\n                return callback(undefined, rawDossier);\n            }\n        }\n    };\n\n//------------------------------------------------ internal methods -------------------------------------------------\n    function createArchiveConfig(seed) {\n        const ArchiveConfigurator = barModule.ArchiveConfigurator;\n        ArchiveConfigurator.prototype.registerFsAdapter(\"FsAdapter\", fsAdapter.createFsAdapter);\n        ArchiveConfigurator.prototype.registerStorageProvider(\"EDFSBrickStorage\", require(\"edfs-brick-storage\").create);\n        const archiveConfigurator = new ArchiveConfigurator();\n        archiveConfigurator.setFsAdapter(\"FsAdapter\");\n        archiveConfigurator.setStorageProvider(\"EDFSBrickStorage\", endpoint);\n        archiveConfigurator.setBufferSize(65535);\n        archiveConfigurator.setEncryptionAlgorithm(\"aes-256-gcm\");\n        archiveConfigurator.setCache(cache);\n\n        if (seed) {\n            archiveConfigurator.setSeed(seed);\n        } else {\n            archiveConfigurator.setSeedEndpoint(endpoint);\n        }\n\n        return archiveConfigurator;\n    }\n}\n\nmodule.exports = EDFS;\n","function RawDossier(endpoint, seed, cache) {\n    const barModule = require(\"bar\");\n    const constants = require(\"../moduleConstants\").CSB;\n    const swarmutils = require(\"swarmutils\");\n    const TaskCounter = swarmutils.TaskCounter;\n    let bar = createBar(seed);\n    this.getSeed = () => {\n        return bar.getSeed();\n    };\n\n    this.start = (callback) => {\n        createBlockchain(bar).start(callback);\n    };\n\n    this.addFolder = (fsFolderPath, barPath, options, callback) => {\n        const defaultOpts = {encrypt: true, ignoreMounts: true};\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {};\n        }\n\n        Object.assign(defaultOpts, options);\n        options = defaultOpts;\n\n        if (options.ignoreMounts === true) {\n            bar.addFolder(fsFolderPath, barPath, options, callback);\n        } else {\n            const splitPath = barPath.split(\"/\");\n            const folderName = splitPath.pop();\n            barPath = splitPath.join(\"/\");\n            loadBarForPath(barPath, (err, dossierContext) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                dossierContext.archive.addFolder(fsFolderPath, dossierContext.relativePath + \"/\" + folderName, options, callback);\n            });\n        }\n    };\n\n    this.addFile = (fsFilePath, barPath, options, callback) => {\n        const defaultOpts = {encrypt: true, ignoreMounts: true};\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {};\n        }\n\n        Object.assign(defaultOpts, options);\n        options = defaultOpts;\n\n        if (options.ignoreMounts === true) {\n            bar.addFile(fsFilePath, barPath, options, (err, barMapDigest) => callback(err, barMapDigest));\n        } else {\n            const splitPath = barPath.split(\"/\");\n            const fileName = splitPath.pop();\n            barPath = splitPath.join(\"/\");\n            loadBarForPath(barPath, (err, dossierContext) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                dossierContext.archive.addFile(fsFilePath, dossierContext.relativePath + \"/\" + fileName, options, callback);\n            });\n        }\n    };\n\n    this.readFile = (fileBarPath, callback) => {\n        loadBarForPath(fileBarPath, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            dossierContext.archive.readFile(dossierContext.relativePath, callback);\n        });\n    };\n\n    this.createReadStream = (fileBarPath, callback) => {\n        loadBarForPath(fileBarPath, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            dossierContext.archive.createReadStream(dossierContext.relativePath, callback);\n        });\n    };\n\n    this.extractFolder = (fsFolderPath, barPath, callback) => {\n        loadBarForPath(barPath, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            dossierContext.archive.extractFolder(fsFolderPath, dossierContext.relativePath, callback);\n        });\n    };\n\n    this.extractFile = (fsFilePath, barPath, callback) => {\n        loadBarForPath(barPath, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            dossierContext.archive.extractFile(fsFilePath, dossierContext.relativePath, callback);\n        });\n    };\n\n    this.writeFile = (path, data, options, callback) => {\n        const defaultOpts = {encrypt: true, ignoreMounts: true};\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {};\n        }\n\n        Object.assign(defaultOpts, options);\n        options = defaultOpts;\n        if (path.split(\"/\").includes(constants.MANIFEST_FILE)) {\n            return callback(Error(\"Trying to overwrite the manifest file. This is not allowed\"));\n        }\n        if (options.ignoreMounts === true) {\n            bar.writeFile(path, data, options, callback);\n        } else {\n            const splitPath = path.split(\"/\");\n            const fileName = splitPath.pop();\n            path = splitPath.join(\"/\");\n            loadBarForPath(path, (err, dossierContext) => {\n                if (err) {\n                    return callback(err);\n                }\n                if (dossierContext.readonly === true) {\n                    return callback(Error(\"Tried to write in a readonly mounted RawDossier\"));\n                }\n\n                dossierContext.archive.writeFile(dossierContext.relativePath + \"/\" + fileName, data, options, callback);\n            });\n        }\n    };\n\n    this.delete = (barPath, callback) => {\n        bar.delete(barPath, callback);\n    };\n\n    this.listFiles = (path, callback) => {\n        loadBarForPath(path, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            dossierContext.archive.listFiles(dossierContext.relativePath, (err, files) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                if (path !== \"/\" && path !== \"\" && typeof path !== \"function\") {\n                    files = files.map(file => {\n                        if (file[0] === \"/\") {\n                            file = file.slice(1);\n                        }\n\n                        return file;\n                    })\n                }\n\n                callback(undefined, files);\n            });\n        });\n    };\n\n    this.listFolders = (path, callback) => {\n        loadBarForPath(path, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            dossierContext.archive.listFolders(dossierContext.relativePath, (err, folders) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                callback(undefined, folders);\n            });\n        });\n    };\n\n    this.readDir = (folderPath, options, callback) => {\n        if (typeof options === \"function\") {\n            callback = options;\n            options = {\n                withFileTypes: false\n            };\n        }\n        loadBarForPath(folderPath, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            const taskCounter = new TaskCounter((errors, results) => {\n                let entries;\n                if (options.withFileTypes === true) {\n                    entries = {};\n                    results.forEach(res=> {\n                        let entryType = Object.keys(res)[0];\n                        entries[entryType] = res[entryType];\n                    })\n                }else{\n                    entries = [];\n                    results.forEach(res => {\n                        entries = entries.concat(Object.values(res)[0])\n                    });\n                }\n\n\n                callback(undefined, entries);\n            });\n\n            taskCounter.increment(3);\n            dossierContext.archive.listFolders(dossierContext.relativePath, false, (err, folders) => {\n                if (err) {\n                    taskCounter.decrement(undefined, {});\n                    return;\n                }\n\n                folders = folders.map(folder => {\n                    if (folder[0] === \"/\") {\n                        return folder.slice(1);\n                    }\n                });\n                taskCounter.decrement(undefined, {folders: folders});\n            });\n\n            dossierContext.archive.listFiles(dossierContext.relativePath, false, (err, files) => {\n                if (err) {\n                    taskCounter.decrement(undefined, {});\n                    return;\n                }\n\n                files= files.map(folder => {\n                    if (folder[0] === \"/\") {\n                        return folder.slice(1);\n                    }\n                });\n                taskCounter.decrement(undefined, {files: files});\n            });\n\n            this.listMountedDossiers(\"/\", (err, mountedDossiers) => {\n                if (err) {\n                    taskCounter.decrement(undefined, {});\n                    return;\n                }\n\n                const mountPaths = mountedDossiers.map(dossier => {\n                    const pathSegments = dossier.path.split(\"/\");\n                    if (pathSegments[0] === \"\") {\n                        pathSegments.shift();\n                    }\n                    if (pathSegments.length > 0) {\n                        return pathSegments[0];\n                    }\n                });\n\n                taskCounter.decrement(undefined, {mounts: mountPaths});\n            });\n        });\n    };\n\n    this.mount = (path, name, archiveIdentifier, readonly, callback) => {\n        if (typeof readonly === \"function\") {\n            callback = readonly;\n            readonly = false;\n        }\n        if (/\\W-_/.test(name) === true) {\n            return callback(Error(\"Invalid mount name\"));\n        }\n\n        bar.listFiles(path, (err, files) => {\n            if (!err && files.length > 0) {\n                return callback(Error(\"Tried to mount in a non-empty folder\"));\n            }\n\n            bar.readFile(constants.MANIFEST_FILE, (err, data) => {\n                let manifest;\n                if (err) {\n                    manifest = {};\n                    manifest.mounts = [];\n                }\n\n                if (data) {\n                    manifest = JSON.parse(data.toString());\n                    const existingMount = manifest.mounts.find(el => el.localPath === path && el.mountName === name);\n                    if (existingMount) {\n                        return callback(Error(`A mount point at path ${path} with the name ${name} already exists.`));\n                    }\n                }\n\n                const mount = {};\n                mount.localPath = path;\n                mount.mountName = name;\n                mount.archiveIdentifier = archiveIdentifier;\n                mount.readonly = readonly;\n                manifest.mounts.push(mount);\n\n                bar.writeFile(constants.MANIFEST_FILE, JSON.stringify(manifest), {encrypt: true}, callback);\n            });\n        });\n    };\n\n    this.unmount = (path, name, callback) => {\n        bar.readFile(constants.MANIFEST_FILE, (err, data) => {\n            if (err) {\n                return callback(err);\n            }\n\n            if (data.length === 0) {\n                return callback(Error(\"Nothing to unmount\"));\n            }\n\n            const manifest = JSON.parse(data.toString());\n            const index = manifest.mounts.findIndex(el => el.localPath === path);\n            if (index >= 0) {\n                manifest.mounts.splice(index, 1);\n            } else {\n                return callback(Error(`No mount point exists at path ${path}`));\n            }\n\n            bar.writeFile(constants.MANIFEST_FILE, JSON.stringify(manifest), callback);\n        });\n    };\n\n    this.listMountedDossiers = (path, callback) => {\n        loadBarForPath(path, (err, dossierContext) => {\n            if (err) {\n                return callback(err);\n            }\n\n            dossierContext.archive.readFile(constants.MANIFEST_FILE, (err, manifestContent) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                let manifest;\n                try {\n                    manifest = JSON.parse(manifestContent.toString());\n                } catch (e) {\n                    return callback(e);\n                }\n\n                const matchingMounts = [];\n                manifest.mounts.forEach(mount => {\n                    let sep = mount.localPath === \"/\" ? \"\" : \"/\";\n                    let pth = mount.localPath + sep + mount.mountName;\n\n                    if (pth.startsWith(dossierContext.relativePath)) {\n                        if (path !== \"/\" && path !== \"\" && typeof path !== \"function\" && pth[0] === \"/\") {\n                            pth = pth.slice(1);\n                        }\n\n                        matchingMounts.push({path: pth, dossierReference: mount.archiveIdentifier});\n                    }\n                });\n                callback(undefined, matchingMounts);\n            });\n        });\n    };\n\n    //------------------------------------------------- internal functions ---------------------------------------------\n    function createBlockchain(bar) {\n        const blockchainModule = require(\"blockchain\");\n        const worldStateCache = blockchainModule.createWorldStateCache(\"bar\", bar);\n        const historyStorage = blockchainModule.createHistoryStorage(\"bar\", bar);\n        const consensusAlgorithm = blockchainModule.createConsensusAlgorithm(\"direct\");\n        const signatureProvider = blockchainModule.createSignatureProvider(\"permissive\");\n        return blockchainModule.createBlockchain(worldStateCache, historyStorage, consensusAlgorithm, signatureProvider, true);\n    }\n\n    function createBar(localSeed) {\n        const createEDFSBrickStorage = require(\"edfs-brick-storage\").create;\n        const createFsAdapter = require(\"bar-fs-adapter\").createFsAdapter;\n\n        const ArchiveConfigurator = barModule.ArchiveConfigurator;\n        ArchiveConfigurator.prototype.registerStorageProvider(\"EDFSBrickStorage\", createEDFSBrickStorage);\n        ArchiveConfigurator.prototype.registerFsAdapter(\"FsAdapter\", createFsAdapter);\n\n        const archiveConfigurator = new ArchiveConfigurator();\n        archiveConfigurator.setFsAdapter(\"FsAdapter\");\n\n        archiveConfigurator.setEncryptionAlgorithm(\"aes-256-gcm\");\n        archiveConfigurator.setBufferSize(65535);\n        if (!localSeed) {\n            archiveConfigurator.setStorageProvider(\"EDFSBrickStorage\", endpoint);\n            archiveConfigurator.setSeedEndpoint(endpoint);\n        } else {\n            archiveConfigurator.setSeed(localSeed);\n        }\n        archiveConfigurator.setCache(cache);\n\n        return barModule.createArchive(archiveConfigurator);\n    }\n\n    function loadBarForPath(path, callback) {\n        if (typeof path === \"function\") {\n            callback = path;\n            path = \"/\";\n        }\n\n        __loadBarForPathRecursively(bar, \"\", path, false, callback);\n\n        function __loadBarForPathRecursively(archive, prefixPath, relativePath, readonly, callback) {\n            if (relativePath === \"\" || relativePath === \"/\") {\n                return callback(undefined, {archive, prefixPath, readonly, relativePath});\n            }\n\n            archive.listFiles((err, files) => {\n                if (err) {\n                    return callback(err);\n                }\n\n                if (files.length === 0) {\n                    __searchInManifest();\n                } else {\n                    let barPath = files.find(file => {\n                        return file.includes(relativePath) || relativePath.includes(file);\n                    });\n\n                    if (barPath) {\n                        return callback(undefined, {archive, prefixPath, readonly, relativePath});\n                    } else {\n                        __searchInManifest();\n                    }\n\n                }\n\n                function __searchInManifest() {\n                    let pathRest = [];\n                    let splitPath = relativePath.split(\"/\");\n                    if (splitPath[0] === \"\") {\n                        splitPath[0] = \"/\";\n                    }\n\n                    archive.readFile(\"/\" + constants.MANIFEST_FILE, (err, manifestContent) => {\n                        if (err) {\n                            return callback(err);\n                        }\n\n                        const manifest = JSON.parse(manifestContent.toString());\n                        pathRest.unshift(splitPath.pop());\n                        if (splitPath.length === 0) {\n                            return callback(undefined, {archive, prefixPath, readonly, relativePath});\n                        }\n\n                        while (splitPath.length > 0) {\n                            let localPath;\n                            if (splitPath[0] === \"/\") {\n                                while (splitPath[0] === \"/\") {\n                                    splitPath.shift();\n                                }\n                                localPath = \"/\" + splitPath.join(\"/\");\n                                splitPath.unshift(\"/\");\n                            } else {\n                                localPath = splitPath.join(\"/\");\n                            }\n\n                            for (let mount of manifest.mounts) {\n                                const name = pathRest[0];\n                                if (mount.localPath === localPath && mount.mountName === name) {\n                                    pathRest.shift();\n\n                                    let newPath;\n                                    if (prefixPath.endsWith(\"/\") || prefixPath === \"\") {\n                                        newPath = prefixPath + localPath + \"/\" + name;\n                                    } else {\n                                        newPath = prefixPath + \"/\" + localPath + \"/\" + name;\n                                    }\n                                    const internalArchive = createBar(mount.archiveIdentifier);\n                                    let remainingPath = pathRest.join(\"/\");\n                                    if (remainingPath[0] !== \"/\") {\n                                        //when navigate into an archive we need to ensure that the remainingPath starts with /\n                                        remainingPath = \"/\" + remainingPath;\n                                    }\n                                    return __loadBarForPathRecursively(internalArchive, newPath, remainingPath, mount.readonly, callback);\n                                }\n                            }\n\n                            pathRest.unshift(splitPath.pop());\n                            if (splitPath.length === 0) {\n                                return callback(Error(`Path ${path} could not be found.`));\n                            }\n                        }\n                    });\n                }\n            });\n        }\n    }\n}\n\nmodule.exports = RawDossier;\n","const HTTPBrickTransportStrategy = require(\"./brickTransportStrategies/HTTPBrickTransportStrategy\");\nHTTPBrickTransportStrategy.prototype.HTTP_BRICK_TRANSPORT_STRATEGY = \"HTTP_BRICK_TRANSPORT_STRATEGY\";\n\nmodule.exports = {\n    CSB: {\n        CODE_FOLDER: \"code\",\n        CONSTITUTION_FOLDER: 'constitution',\n        BLOCKCHAIN_FOLDER: 'blockchain',\n        APP_FOLDER: 'app',\n        DOMAIN_IDENTITY_FILE: 'domain_identity',\n        ASSETS_FOLDER: \"assets\",\n        TRANSACTIONS_FOLDER: \"transactions\",\n        APPS_FOLDER: \"apps\",\n        DATA_FOLDER: \"data\",\n        MANIFEST_FILE: \"manifest\"\n    }\n};\n","const pskcrypto = \"pskcrypto\";\nconst crypto = require(pskcrypto);\nconst storageLocation = \"seedCage\";\nconst algorithm = \"aes-256-cfb\";\n\n/**\n * local storage can't handle properly binary data\n *  https://stackoverflow.com/questions/52419694/how-to-store-uint8array-in-the-browser-with-localstorage-using-javascript\n * @param pin\n * @param callback\n * @returns {*}\n */\nfunction getSeed(pin, callback) {\n    let encryptedSeed;\n    let seed;\n    try {\n        encryptedSeed = localStorage.getItem(storageLocation);\n        if (encryptedSeed === null || typeof encryptedSeed !== \"string\" || encryptedSeed.length === 0) {\n            return callback(new Error(\"SeedCage is empty or data was altered\"));\n        }\n\n        const retrievedEncryptedArr = JSON.parse(encryptedSeed);\n        encryptedSeed = new Uint8Array(retrievedEncryptedArr);\n        const pskEncryption = crypto.createPskEncryption(algorithm);\n        const encKey = crypto.deriveKey(algorithm, pin);\n        seed = pskEncryption.decrypt(encryptedSeed, encKey).toString();\n    } catch (e) {\n        return callback(e);\n    }\n    callback(undefined, seed);\n}\n\nfunction putSeed(seed, pin, overwrite = false, callback) {\n    let encSeed;\n\n    if (typeof overwrite === \"function\") {\n        callback(Error(\"TODO: api signature updated!\"));\n    }\n    try {\n        if (typeof seed === \"string\") {\n            seed = Buffer.from(seed);\n        }\n        if (typeof seed === \"object\" && !Buffer.isBuffer(seed)) {\n            seed = Buffer.from(seed);\n        }\n\n        const pskEncryption = crypto.createPskEncryption(algorithm);\n        const encKey = crypto.deriveKey(algorithm, pin);\n        encSeed = pskEncryption.encrypt(seed, encKey);\n        const encParameters = pskEncryption.getEncryptionParameters();\n        encSeed = Buffer.concat([encSeed, encParameters.iv]);\n        if (encParameters.aad) {\n            encSeed = Buffer.concat([encSeed, encParameters.aad]);\n        }\n\n        if (encParameters.tag) {\n            encSeed = Buffer.concat([encSeed, encParameters.tag]);\n        }\n\n        const encryptedArray =  Array.from(encSeed);\n        const encryptedSeed = JSON.stringify(encryptedArray);\n\n        localStorage.setItem(storageLocation, encryptedSeed);\n    } catch (e) {\n        return callback(e);\n    }\n    callback(undefined);\n}\n\nfunction check(callback) {\n    let item;\n    try {\n        item = localStorage.getItem(storageLocation);\n    } catch (e) {\n        return callback(e);\n    }\n    if (item) {\n        return callback();\n    }\n    callback(new Error(\"SeedCage does not exists\"));\n}\n\nmodule.exports = {\n    check,\n    putSeed,\n    getSeed\n};\n","const pth = \"path\";\nconst path = require(pth);\nconst os = \"os\";\nconst fileSystem = \"fs\";\nconst fs = require(fileSystem);\nconst pskcrypto = \"pskcrypto\";\nconst crypto = require(pskcrypto);\n\n\nconst storageLocation = process.env.SEED_CAGE_LOCATION || require(os).homedir();\nconst storageFileName = \".seedCage\";\nconst seedCagePath = path.join(storageLocation, storageFileName);\nconst algorithm = \"aes-256-cfb\";\n\nfunction getSeed(password, callback) {\n    fs.readFile(seedCagePath, (err, encryptedSeed) => {\n        if (err) {\n            return callback(err);\n        }\n\n        let seed;\n        try {\n            const pskEncryption = crypto.createPskEncryption(algorithm);\n            const encKey = crypto.deriveKey(algorithm, password);\n            seed = pskEncryption.decrypt(encryptedSeed, encKey).toString();\n        } catch (e) {\n            return callback(e);\n        }\n\n        callback(undefined, seed);\n    });\n}\n\nfunction putSeed(seed, password, overwrite = false, callback) {\n    fs.mkdir(storageLocation, {recursive: true}, (err) => {\n        if (err) {\n            return callback(err);\n        }\n\n        fs.stat(seedCagePath, (err, stats) => {\n            if (!err && stats.size > 0) {\n                if (overwrite) {\n                    __encryptSeed();\n                } else {\n                    return callback(Error(\"Attempted to overwrite existing SEED.\"));\n                }\n            } else {\n                __encryptSeed();\n            }\n\n            function __encryptSeed() {\n                let encSeed;\n                try {\n                    if (typeof seed === \"string\") {\n                        seed = Buffer.from(seed);\n                    }\n\n                    if (typeof seed === \"object\" && !Buffer.isBuffer(seed)) {\n                        seed = Buffer.from(seed);\n                    }\n\n\n                    const pskEncryption = crypto.createPskEncryption(algorithm);\n                    const encKey = crypto.deriveKey(algorithm, password);\n                    encSeed = pskEncryption.encrypt(seed, encKey);\n                    const encParameters = pskEncryption.getEncryptionParameters();\n                    encSeed = Buffer.concat([encSeed, encParameters.iv]);\n                    if (encParameters.aad) {\n                        encSeed = Buffer.concat([encSeed, encParameters.aad]);\n                    }\n\n                    if (encParameters.tag) {\n                        encSeed = Buffer.concat([encSeed, encParameters.tag]);\n                    }\n                } catch (e) {\n                    return callback(e);\n                }\n\n                console.log(\"To be removed later\", seed.toString());\n                fs.writeFile(seedCagePath, encSeed, callback);\n            }\n        });\n    });\n}\n\nfunction check(callback) {\n    fs.access(seedCagePath, callback);\n}\n\nmodule.exports = {\n    check,\n    putSeed,\n    getSeed\n};\n","const or = require(\"overwrite-require\");\nswitch ($$.environmentType) {\n    case or.constants.THREAD_ENVIRONMENT_TYPE:\n    case or.constants.NODEJS_ENVIRONMENT_TYPE:\n        module.exports = require(\"./NodeSeedCage\");\n        break;\n    case or.constants.BROWSER_ENVIRONMENT_TYPE:\n        module.exports = require(\"./BrowserSeedCage\");\n        break;\n    case or.constants.SERVICE_WORKER_ENVIRONMENT_TYPE:\n    case or.constants.ISOLATE_ENVIRONMENT_TYPE:\n    default:\n        throw new Error(\"No implementation of SeedCage for this env type.\");\n}","module.exports = {\n  BROWSER_ENVIRONMENT_TYPE: 'browser',\n  SERVICE_WORKER_ENVIRONMENT_TYPE: 'service-worker',\n  ISOLATE_ENVIRONMENT_TYPE: 'isolate',\n  THREAD_ENVIRONMENT_TYPE: 'thread',\n  NODEJS_ENVIRONMENT_TYPE: 'nodejs'\n};\n","let logger = console;\n\nif (!global.process || process.env.NO_LOGS !== 'true') {\n    try {\n        const zmqName = \"zeromq\";\n        require(zmqName);\n        const PSKLoggerModule = require('psklogger');\n        const PSKLogger = PSKLoggerModule.PSKLogger;\n\n        logger = PSKLogger.getLogger();\n\n        console.log('Logger init successful', process.pid);\n    } catch (e) {\n        if(e.message.indexOf(\"psklogger\")!==-1 || e.message.indexOf(\"zeromq\")!==-1){\n            console.log('Logger not available, using console');\n            logger = console;\n        }else{\n            console.log(e);\n        }\n    }\n} else {\n    console.log('Environment flag NO_LOGS is set, logging to console');\n}\n\n$$.registerGlobalSymbol = function (newSymbol, value) {\n    if (typeof $$[newSymbol] == \"undefined\") {\n        Object.defineProperty($$, newSymbol, {\n            value: value,\n            writable: false\n        });\n    } else {\n        logger.error(\"Refusing to overwrite $$.\" + newSymbol);\n    }\n};\n\nconsole.warn = (...args)=>{\n    console.log(...args);\n};\n\n/**\n * @method\n * @name $$#autoThrow\n * @param {Error} err\n * @throws {Error}\n */\n\n$$.registerGlobalSymbol(\"autoThrow\", function (err) {\n    if (!err) {\n        throw err;\n    }\n});\n\n/**\n * @method\n * @name $$#propagateError\n * @param {Error} err\n * @param {function} callback\n */\n$$.registerGlobalSymbol(\"propagateError\", function (err, callback) {\n    if (err) {\n        callback(err);\n        throw err; //stop execution\n    }\n});\n\n/**\n * @method\n * @name $$#logError\n * @param {Error} err\n */\n$$.registerGlobalSymbol(\"logError\", function (err) {\n    if (err) {\n        console.log(err);\n        $$.err(err);\n    }\n});\n\n/**\n * @method\n * @name $$#fixMe\n * @param {...*} args\n */\nconsole.log(\"Fix the fixMe to not display on console but put in logs\");\n$$.registerGlobalSymbol(\"fixMe\", function (...args) {\n    //$$.log(...args);\n});\n\n/**\n * @method - Throws an error\n * @name $$#exception\n * @param {string} message\n * @param {*} type\n */\n$$.registerGlobalSymbol(\"exception\", function (message, type) {\n    throw new Error(message);\n});\n\n/**\n * @method - Throws an error\n * @name $$#throw\n * @param {string} message\n * @param {*} type\n */\n$$.registerGlobalSymbol(\"throw\", function (message, type) {\n    throw new Error(message);\n});\n\n\n/**\n * @method - Warns that method is not implemented\n * @name $$#incomplete\n * @param {...*} args\n */\n/* signal a  planned feature but not implemented yet (during development) but\nalso it could remain in production and should be flagged asap*/\n$$.incomplete = function (...args) {\n    args.unshift(\"Incomplete feature touched:\");\n    logger.warn(...args);\n};\n\n/**\n * @method - Warns that method is not implemented\n * @name $$#notImplemented\n * @param {...*} args\n */\n$$.notImplemented = $$.incomplete;\n\n\n/**\n * @method Throws if value is false\n * @name $$#assert\n * @param {boolean} value - Value to assert against\n * @param {string} explainWhy - Reason why assert failed (why value is false)\n */\n/* used during development and when trying to discover elusive errors*/\n$$.registerGlobalSymbol(\"assert\", function (value, explainWhy) {\n    if (!value) {\n        throw new Error(\"Assert false \" + explainWhy);\n    }\n});\n\n/**\n * @method\n * @name $$#flags\n * @param {string} flagName\n * @param {*} value\n */\n/* enable/disabale flags that control psk behaviour*/\n$$.registerGlobalSymbol(\"flags\", function (flagName, value) {\n    $$.incomplete(\"flags handling not implemented\");\n});\n\n/**\n * @method - Warns that a method is obsolete\n * @name $$#obsolete\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"obsolete\", function (...args) {\n    args.unshift(\"Obsolete feature:\");\n    logger.log(...args);\n    console.log(...args);\n});\n\n/**\n * @method - Uses the logger to log a message of level \"log\"\n * @name $$#log\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"log\", function (...args) {\n    args.unshift(\"Log:\");\n    logger.log(...args);\n});\n\n/**\n * @method - Uses the logger to log a message of level \"info\"\n * @name $$#info\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"info\", function (...args) {\n    args.unshift(\"Info:\");\n    logger.log(...args);\n    console.log(...args);\n});\n\n/**\n * @method - Uses the logger to log a message of level \"error\"\n * @name $$#err\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"err\", function (...args) {\n    args.unshift(\"Error:\");\n    logger.error(...args);\n    console.error(...args);\n});\n\n/**\n * @method - Uses the logger to log a message of level \"error\"\n * @name $$#err\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"error\", function (...args) {\n    args.unshift(\"Error:\");\n    logger.error(...args);\n    console.error(...args);\n});\n\n/**\n * @method - Uses the logger to log a message of level \"warning\"\n * @name $$#warn\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"warn\", function (...args) {\n    args.unshift(\"Warn:\");\n    logger.warn(...args);\n    console.log(...args);\n});\n\n/**\n * @method - Uses the logger to log a message of level \"syntexError\"\n * @name $$#syntexError\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"syntaxError\", function (...args) {\n    args.unshift(\"Syntax error:\");\n    logger.error(...args);\n    try{\n        throw new Error(\"Syntax error or misspelled symbol!\");\n    }catch(err){\n        console.error(...args);\n        console.error(err.stack);\n    }\n\n});\n\n/**\n * @method - Logs an invalid member name for a swarm\n * @name $$#invalidMemberName\n * @param {string} name\n * @param {Object} swarm\n */\n$$.invalidMemberName = function (name, swarm) {\n    let swarmName = \"unknown\";\n    if (swarm && swarm.meta) {\n        swarmName = swarm.meta.swarmTypeName;\n    }\n    const text = \"Invalid member name \" + name + \"in swarm \" + swarmName;\n    console.error(text);\n    logger.err(text);\n};\n\n/**\n * @method - Logs an invalid swarm name\n * @name $$#invalidSwarmName\n * @param {string} name\n * @param {Object} swarm\n */\n$$.registerGlobalSymbol(\"invalidSwarmName\", function (swarmName) {\n    const text = \"Invalid swarm name \" + swarmName;\n    console.error(text);\n    logger.err(text);\n});\n\n/**\n * @method - Logs unknown exceptions\n * @name $$#unknownException\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"unknownException\", function (...args) {\n    args.unshift(\"unknownException:\");\n    logger.err(...args);\n    console.error(...args);\n});\n\n/**\n * @method - PrivateSky event, used by monitoring and statistics\n * @name $$#event\n * @param {string} event\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"event\", function (event, ...args) {\n    if (logger.hasOwnProperty('event')) {\n        logger.event(event, ...args);\n    } else {\n        if(event === \"status.domains.boot\"){\n            console.log(\"Failing to console...\", event, ...args);\n        }\n    }\n});\n\n/**\n * @method -\n * @name $$#redirectLog\n * @param {string} event\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"redirectLog\", function (logType, logObject) {\n    if(logger.hasOwnProperty('redirect')) {\n        logger.redirect(logType, logObject);\n    }\n});\n\n/**\n * @method - log throttling event // it is just an event?\n * @name $$#throttlingEvent\n * @param {...*} args\n */\n$$.registerGlobalSymbol(\"throttlingEvent\", function (...args) {\n    logger.log(...args);\n});\n","const DEFAULT_ITEMS_LIMIT = 1000;\nconst DEFAULT_STORAGE_LEVELS = 3;\n\n/**\n * @param {object} options\n * @param {Number} options.maxLevels Number of storage levels. Defaults to 3\n * @param {Number} options.limit Number of max items the cache can store per level.\n *                               Defaults to 1000\n */\nfunction Cache(options) {\n    options = options || {};\n    this.limit = parseInt(options.limit, 10) || DEFAULT_ITEMS_LIMIT;\n    this.maxLevels = parseInt(options.maxLevels, 10) || DEFAULT_STORAGE_LEVELS;\n    this.storage = null;\n\n    if (this.limit < 0) {\n        throw new Error('Limit must be a positive number');\n    }\n    if (this.maxLevels < 1) {\n        throw new Error('Cache needs at least one storage level');\n    }\n\n\n    /**\n     * Create an array of Map objects for storing items\n     *\n     * @param {Number} maxLevels\n     * @return {Array.<Map>}\n     */\n    this.createStorage = function (maxLevels) {\n        const storage = [];\n        for (let i = 0; i < maxLevels; i++) {\n            storage.push(new Map());\n        }\n\n        return storage;\n    }\n\n    this.storage = this.createStorage(this.maxLevels);\n\n    /**\n     * @param {*} key\n     * @param {*} value\n     */\n    this.set = function (key, value) {\n        if (this.cacheIsFull()) {\n            this.makeRoom();\n        }\n\n        this.storage[0].set(key, value);\n    }\n\n    /**\n     * @param {*} key\n     * @return {Boolean}\n     */\n    this.has = function (key) {\n        for (let i = 0; i < this.storage.length; i++) {\n            if (this.storage[i].has(key)) {\n                return true;\n            }\n        }\n\n        return false;\n    }\n\n    /**\n     * @param {*} key\n     * @return {*}\n     */\n    this.get = function (key) {\n        if (this.storage[0].has(key)) {\n            return this.storage[0].get(key);\n        }\n\n        return this.getFromLowerLevels(key);\n    }\n\n    /**\n     * Get an item from the lower levels.\n     * If one is found added it to the first level as well\n     *\n     * @param {*} key\n     * @return {*}\n     */\n    this.getFromLowerLevels = function (key) {\n        for (let i = 1; i < this.storage.length; i++) {\n            const storageLevel = this.storage[i];\n            if (!storageLevel.has(key)) {\n                continue;\n            }\n            const value = storageLevel.get(key);\n            this.set(key, value);\n            return value;\n        }\n    }\n\n    /**\n     * @return {Boolean}\n     */\n    this.cacheIsFull = function () {\n        return this.storage[0].size >= this.limit;\n    }\n\n    /**\n     * Move all the items down by one level\n     * and clear the first one to make room for new items\n     */\n    this.makeRoom = function () {\n        for (let i = this.storage.length - 1; i > 0; i--) {\n            this.storage[i] = this.storage[i - 1];\n        }\n        this.storage[0] = new Map();\n    }\n}\n\nmodule.exports = Cache;\n","/**********************  utility class **********************************/\nfunction RequestManager(pollingTimeOut) {\n    if (!pollingTimeOut) {\n        pollingTimeOut = 1000; //1 second by default\n    }\n\n    const self = this;\n\n    function Request(endPoint, initialSwarm, delayedStart) {\n        let onReturnCallbacks = [];\n        let onErrorCallbacks = [];\n        let onCallbacks = [];\n        const requestId = initialSwarm ? initialSwarm.meta.requestId : \"weneedarequestid\";\n        initialSwarm = null;\n\n        this.getRequestId = function () {\n            return requestId;\n        };\n\n        this.on = function (phaseName, callback) {\n            if (typeof phaseName != \"string\" && typeof callback != \"function\") {\n                throw new Error(\"The first parameter should be a string and the second parameter should be a function\");\n            }\n\n            onCallbacks.push({\n                callback: callback,\n                phase: phaseName\n            });\n\n            if (typeof delayedStart === \"undefined\") {\n                self.poll(endPoint, this);\n            }\n\n            return this;\n        };\n\n        this.onReturn = function (callback) {\n            onReturnCallbacks.push(callback);\n            if (typeof delayedStart === \"undefined\") {\n                self.poll(endPoint, this);\n            }\n            return this;\n        };\n\n        this.onError = function (callback) {\n            if (onErrorCallbacks.indexOf(callback) !== -1) {\n                onErrorCallbacks.push(callback);\n            } else {\n                console.log(\"Error callback already registered!\");\n            }\n        };\n\n        this.start = function () {\n            if (typeof delayedStart !== \"undefined\") {\n                self.poll(endPoint, this);\n            }\n        };\n\n        this.dispatch = function (err, result) {\n            if (result instanceof ArrayBuffer) {\n                result = SwarmPacker.unpack(result);\n            }\n\n            result = typeof result === \"string\" ? JSON.parse(result) : result;\n\n            result = OwM.prototype.convert(result);\n            const resultReqId = result.getMeta(\"requestId\");\n            const phaseName = result.getMeta(\"phaseName\");\n            let onReturn = false;\n\n            if (resultReqId === requestId) {\n                onReturnCallbacks.forEach(function (c) {\n                    c(null, result);\n                    onReturn = true;\n                });\n                if (onReturn) {\n                    onReturnCallbacks = [];\n                    onErrorCallbacks = [];\n                }\n\n                onCallbacks.forEach(function (i) {\n                    //console.log(\"XXXXXXXX:\", phaseName , i);\n                    if (phaseName === i.phase || i.phase === '*') {\n                        i.callback(err, result);\n                    }\n                });\n            }\n\n            if (onReturnCallbacks.length === 0 && onCallbacks.length === 0) {\n                self.unpoll(endPoint, this);\n            }\n        };\n\n        this.dispatchError = function (err) {\n            for (let i = 0; i < onErrorCallbacks.length; i++) {\n                const errCb = onErrorCallbacks[i];\n                errCb(err);\n            }\n        };\n\n        this.off = function () {\n            self.unpoll(endPoint, this);\n        };\n    }\n\n    this.createRequest = function (remoteEndPoint, swarm, delayedStart) {\n        return new Request(remoteEndPoint, swarm, delayedStart);\n    };\n\n    /* *************************** polling zone ****************************/\n\n    const pollSet = {};\n\n    const activeConnections = {};\n\n    this.poll = function (remoteEndPoint, request) {\n        let requests = pollSet[remoteEndPoint];\n        if (!requests) {\n            requests = {};\n            pollSet[remoteEndPoint] = requests;\n        }\n        requests[request.getRequestId()] = request;\n        pollingHandler();\n    };\n\n    this.unpoll = function (remoteEndPoint, request) {\n        const requests = pollSet[remoteEndPoint];\n        if (requests) {\n            delete requests[request.getRequestId()];\n            if (Object.keys(requests).length === 0) {\n                delete pollSet[remoteEndPoint];\n            }\n        } else {\n            console.log(\"Unpolling wrong request:\", remoteEndPoint, request);\n        }\n    };\n\n    function createPollThread(remoteEndPoint) {\n        function reArm() {\n            $$.remote.doHttpGet(remoteEndPoint, function (err, res) {\n                let requests = pollSet[remoteEndPoint];\n                if (err) {\n                    for (const req_id in requests) {\n                        if (!requests.hasOwnProperty(req_id)) {\n                            return;\n                        }\n\n                        let err_handler = requests[req_id].dispatchError;\n                        if (err_handler) {\n                            err_handler(err);\n                        }\n                    }\n                    activeConnections[remoteEndPoint] = false;\n                } else {\n\n                    for (const k in requests) {\n                        if (!requests.hasOwnProperty(k)) {\n                            return;\n                        }\n\n                        requests[k].dispatch(null, res);\n                    }\n\n                    if (Object.keys(requests).length !== 0) {\n                        reArm();\n                    } else {\n                        delete activeConnections[remoteEndPoint];\n                        console.log(\"Ending polling for \", remoteEndPoint);\n                    }\n                }\n            });\n        }\n\n        reArm();\n    }\n\n    function pollingHandler() {\n        let setTimer = false;\n        for (const remoteEndPoint in pollSet) {\n            if (!pollSet.hasOwnProperty(remoteEndPoint)) {\n                return;\n            }\n\n            if (!activeConnections[remoteEndPoint]) {\n                createPollThread(remoteEndPoint);\n                activeConnections[remoteEndPoint] = true;\n            }\n            setTimer = true;\n        }\n        if (setTimer) {\n            setTimeout(pollingHandler, pollingTimeOut);\n        }\n    }\n\n    setTimeout(pollingHandler, pollingTimeOut);\n}\n\nfunction urlEndWithSlash(url) {\n    if (url[url.length - 1] !== \"/\") {\n        url += \"/\";\n    }\n    return url;\n}\n\n/********************** main APIs on working with virtualMQ channels **********************************/\nfunction HttpChannelClient(remoteEndPoint, channelName, options) {\n\n    let clientType;\n    const opts = {\n        autoCreate: true,\n        publicSignature: \"no_signature_provided\"\n    };\n\n    Object.keys(options).forEach((optName) => {\n        opts[optName] = options[optName];\n    });\n\n    let channelCreated = false;\n    function readyToBeUsed(){\n        let res = false;\n\n        if(clientType === HttpChannelClient.prototype.PRODUCER_CLIENT_TYPE){\n            res = true;\n        }\n        if(clientType === HttpChannelClient.prototype.CONSUMER_CLIENT_TYPE){\n            if(!options.autoCreate){\n                res = true;\n            }else{\n                res = channelCreated;\n            }\n        }\n\n        return res;\n    }\n\n    function encryptChannelName(channelName) {\n        return $$.remote.base64Encode(channelName);\n    }\n\n    function CatchAll(swarmName, phaseName, callback) { //same interface as Request\n        const requestId = requestsCounter++;\n        this.getRequestId = function () {\n            return \"swarmName\" + \"phaseName\" + requestId;\n        };\n\n        this.dispatch = function (err, result) {\n            /*result = OwM.prototype.convert(result);\n            const currentPhaseName = result.getMeta(\"phaseName\");\n            const currentSwarmName = result.getMeta(\"swarmTypeName\");\n            if ((currentSwarmName === swarmName || swarmName === '*') && (currentPhaseName === phaseName || phaseName === '*')) {\n                return callback(err, result);\n            }*/\n            return callback(err, result);\n        };\n    }\n\n    this.setSenderMode = function () {\n        if (typeof clientType !== \"undefined\") {\n            throw new Error(`HttpChannelClient is set as ${clientType}`);\n        }\n        clientType = HttpChannelClient.prototype.PRODUCER_CLIENT_TYPE;\n\n        this.sendSwarm = function (swarmSerialization) {\n            $$.remote.doHttpPost(getRemoteToSendMessage(remoteEndPoint, channelName), swarmSerialization, (err, res)=>{\n                if(err){\n                    console.log(\"Sending swarm failed\", err);\n                }else{\n                    console.log(\"Swarm sent\");\n                }\n            });\n        };\n    };\n\n    this.setReceiverMode = function () {\n        if (typeof clientType !== \"undefined\") {\n            throw new Error(`HttpChannelClient is set as ${clientType}`);\n        }\n        clientType = HttpChannelClient.prototype.CONSUMER_CLIENT_TYPE;\n\n        function createChannel(callback){\n            if (!readyToBeUsed()) {\n                $$.remote.doHttpPut(getRemoteToCreateChannel(), opts.publicSignature, (err) => {\n                    if (err) {\n                        if (err.statusCode !== 409) {\n                            return callback(err);\n                        }\n                    }\n                    channelCreated = true;\n                    if(opts.enableForward){\n                        console.log(\"Enabling forward\");\n                        $$.remote.doHttpPost(getUrlToEnableForward(), opts.publicSignature, (err, res)=>{\n                            if(err){\n                                console.log(\"Request to enable forward to zeromq failed\", err);\n                            }\n                        });\n                    }\n                    return callback();\n                });\n            }\n        }\n\n        this.getReceiveAddress = function(){\n            return getRemoteToSendMessage();\n        };\n\n        this.on = function (swarmId, swarmName, phaseName, callback) {\n            const c = new CatchAll(swarmName, phaseName, callback);\n            allCatchAlls.push({\n                s: swarmName,\n                p: phaseName,\n                c: c\n            });\n\n           /* if (!readyToBeUsed()) {\n                createChannel((err)=>{\n                    $$.remote.requestManager.poll(getRemoteToReceiveMessage(), c);\n                });\n            } else {*/\n                $$.remote.requestManager.poll(getRemoteToReceiveMessage(), c);\n            /*}*/\n        };\n\n        this.off = function (swarmName, phaseName) {\n            allCatchAlls.forEach(function (ca) {\n                if ((ca.s === swarmName || swarmName === '*') && (phaseName === ca.p || phaseName === '*')) {\n                    $$.remote.requestManager.unpoll(getRemoteToReceiveMessage(remoteEndPoint, domainInfo.domain), ca.c);\n                }\n            });\n        };\n\n        createChannel((err) => {\n            if(err){\n                console.log(err);\n            }\n        });\n\n        $$.remote.createRequestManager();\n    };\n\n    const allCatchAlls = [];\n    let requestsCounter = 0;\n\n    this.uploadCSB = function (cryptoUid, binaryData, callback) {\n        $$.remote.doHttpPost(baseOfRemoteEndPoint + \"/CSB/\" + cryptoUid, binaryData, callback);\n    };\n\n    this.downloadCSB = function (cryptoUid, callback) {\n        $$.remote.doHttpGet(baseOfRemoteEndPoint + \"/CSB/\" + cryptoUid, callback);\n    };\n\n    function getRemoteToReceiveMessage() {\n        return [urlEndWithSlash(remoteEndPoint), urlEndWithSlash(HttpChannelClient.prototype.RECEIVE_API_NAME), urlEndWithSlash(encryptChannelName(channelName))].join(\"\");\n    }\n\n    function getRemoteToSendMessage() {\n        return [urlEndWithSlash(remoteEndPoint), urlEndWithSlash(HttpChannelClient.prototype.SEND_API_NAME), urlEndWithSlash(encryptChannelName(channelName))].join(\"\");\n    }\n\n    function getRemoteToCreateChannel() {\n        return [urlEndWithSlash(remoteEndPoint), urlEndWithSlash(HttpChannelClient.prototype.CREATE_CHANNEL_API_NAME), urlEndWithSlash(encryptChannelName(channelName))].join(\"\");\n    }\n\n    function getUrlToEnableForward() {\n        return [urlEndWithSlash(remoteEndPoint), urlEndWithSlash(HttpChannelClient.prototype.FORWARD_CHANNEL_API_NAME), urlEndWithSlash(encryptChannelName(channelName))].join(\"\");\n    }\n}\n\n/********************** constants **********************************/\nHttpChannelClient.prototype.RECEIVE_API_NAME = \"receive-message\";\nHttpChannelClient.prototype.SEND_API_NAME = \"send-message\";\nHttpChannelClient.prototype.CREATE_CHANNEL_API_NAME = \"create-channel\";\nHttpChannelClient.prototype.FORWARD_CHANNEL_API_NAME = \"forward-zeromq\";\nHttpChannelClient.prototype.PRODUCER_CLIENT_TYPE = \"producer\";\nHttpChannelClient.prototype.CONSUMER_CLIENT_TYPE = \"consumer\";\n\n/********************** initialisation stuff **********************************/\nif (typeof $$ === \"undefined\") {\n    $$ = {};\n}\n\nif (typeof $$.remote === \"undefined\") {\n    $$.remote = {};\n\n    function createRequestManager(timeOut) {\n        const newRequestManager = new RequestManager(timeOut);\n        Object.defineProperty($$.remote, \"requestManager\", {value: newRequestManager});\n    }\n\n    function registerHttpChannelClient(alias, remoteEndPoint, channelName, options) {\n        $$.remote[alias] = new HttpChannelClient(remoteEndPoint, channelName, options);\n    }\n\n    Object.defineProperty($$.remote, \"createRequestManager\", {value: createRequestManager});\n    Object.defineProperty($$.remote, \"registerHttpChannelClient\", {value: registerHttpChannelClient});\n\n    $$.remote.doHttpPost = function (url, data, callback) {\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.doHttpPut = function (url, data, callback) {\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.doHttpGet = function doHttpGet(url, callback) {\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.base64Encode = function base64Encode(stringToEncode) {\n        throw new Error(\"Overwrite this!\");\n    };\n\n    $$.remote.base64Decode = function base64Decode(encodedString) {\n        throw new Error(\"Overwrite this!\");\n    };\n}\n","function generateMethodForRequestWithData(httpMethod) {\n    return function (url, data, callback) {\n        const xhr = new XMLHttpRequest();\n\n        xhr.onload = function () {\n            if (xhr.readyState === 4 && (xhr.status >= 200 && xhr.status < 300)) {\n                const data = xhr.response;\n                callback(undefined, data);\n            } else {\n                if(xhr.status>=400){\n                    const error = new Error(\"An error occured. StatusCode: \" + xhr.status);\n                    callback({error: error, statusCode: xhr.status});\n                } else {\n                    console.log(`Status code ${xhr.status} received, response is ignored.`);\n                }\n            }\n        };\n\n        xhr.onerror = function (e) {\n            callback(new Error(\"A network error occurred\"));\n        };\n\n        xhr.open(httpMethod, url, true);\n        //xhr.setRequestHeader(\"Content-Type\", \"application/json;charset=UTF-8\");\n\n        if(data && data.pipe && typeof data.pipe === \"function\"){\n            const buffers = [];\n            data.on(\"data\", function(data) {\n                buffers.push(data);\n            });\n            data.on(\"end\", function() {\n                const actualContents = Buffer.concat(buffers);\n                xhr.send(actualContents);\n            });\n        }\n        else {\n            if(ArrayBuffer.isView(data) || data instanceof ArrayBuffer) {\n                xhr.setRequestHeader('Content-Type', 'application/octet-stream');\n\n                /**\n                 * Content-Length is an unsafe header and we cannot set it.\n                 * When browser is making a request that is intercepted by a service worker,\n                 * the Content-Length header is not set implicitly.\n                 */\n                xhr.setRequestHeader('X-Content-Length', data.byteLength);\n            }\n            xhr.send(data);\n        }\n    };\n}\n\n\n$$.remote.doHttpPost = generateMethodForRequestWithData('POST');\n\n$$.remote.doHttpPut = generateMethodForRequestWithData('PUT');\n\n\n$$.remote.doHttpGet = function doHttpGet(url, callback) {\n\n    var xhr = new XMLHttpRequest();\n\n    xhr.onreadystatechange = function () {\n        //check if headers were received and if any action should be performed before receiving data\n        if (xhr.readyState === 2) {\n            var contentType = xhr.getResponseHeader(\"Content-Type\");\n            if (contentType === \"application/octet-stream\") {\n                xhr.responseType = 'arraybuffer';\n            }\n        }\n    };\n\n    xhr.onload = function () {\n        if (xhr.readyState === 4 && xhr.status == \"200\") {\n            var contentType = xhr.getResponseHeader(\"Content-Type\");\n            if (contentType === \"application/octet-stream\") {\n                let responseBuffer = this.response;\n\n                let buffer = new Buffer(responseBuffer.byteLength);\n                let view = new Uint8Array(responseBuffer);\n                for (let i = 0; i < buffer.length; ++i) {\n                    buffer[i] = view[i];\n                }\n                callback(undefined, buffer);\n            }\n            else{\n                callback(undefined, xhr.response);\n            }\n        } else {\n            const error = new Error(\"An error occurred. StatusCode: \" + xhr.status);\n\n            callback({error: error, statusCode: xhr.status});\n        }\n    };\n    xhr.onerror = function (e) {\n        callback(new Error(\"A network error occurred\"));\n    };\n\n    xhr.open(\"GET\", url);\n    xhr.send();\n};\n\n\nfunction CryptoProvider(){\n\n    this.generateSafeUid = function(){\n        let uid = \"\";\n        var array = new Uint32Array(10);\n        window.crypto.getRandomValues(array);\n\n\n        for (var i = 0; i < array.length; i++) {\n            uid += array[i].toString(16);\n        }\n\n        return uid;\n    };\n\n    this.signSwarm = function(swarm, agent){\n        swarm.meta.signature = agent;\n    };\n}\n\n\n\n$$.remote.cryptoProvider = new CryptoProvider();\n\n$$.remote.base64Encode = function base64Encode(stringToEncode){\n    return window.btoa(stringToEncode);\n};\n\n$$.remote.base64Decode = function base64Decode(encodedString){\n    return window.atob(encodedString);\n};\n","require(\"./psk-abstract-client\");\n\nconst http = require(\"http\");\nconst https = require(\"https\");\nconst URL = require(\"url\");\nconst userAgent = 'PSK NodeAgent/0.0.1';\nconst signatureHeaderName = process.env.vmq_signature_header_name || \"x-signature\";\n\n\nconsole.log(\"PSK node client loading\");\n\nfunction getNetworkForOptions(options) {\n\tif(options.protocol === 'http:') {\n\t\treturn http;\n\t} else if(options.protocol === 'https:') {\n\t\treturn https;\n\t} else {\n\t\tthrow new Error(`Can't handle protocol ${options.protocol}`);\n\t}\n\n}\n\nfunction generateMethodForRequestWithData(httpMethod) {\n\treturn function (url, data, callback) {\n\t\tconst innerUrl = URL.parse(url);\n\n\t\tconst options = {\n\t\t\thostname: innerUrl.hostname,\n\t\t\tpath: innerUrl.pathname,\n\t\t\tport: parseInt(innerUrl.port),\n\t\t\theaders: {\n\t\t\t\t'User-Agent': userAgent,\n\t\t\t\t[signatureHeaderName]: 'replaceThisPlaceholderSignature'\n\t\t\t},\n\t\t\tmethod: httpMethod\n\t\t};\n\n\t\tconst network = getNetworkForOptions(innerUrl);\n\n\t\tif (ArrayBuffer.isView(data) || Buffer.isBuffer(data) || data instanceof ArrayBuffer) {\n\t\t\tif (!Buffer.isBuffer(data)) {\n\t\t\t\tdata = Buffer.from(data);\n\t\t\t}\n\n\t\t\toptions.headers['Content-Type'] = 'application/octet-stream';\n\t\t\toptions.headers['Content-Length'] = data.length;\n\t\t}\n\n\t\tconst req = network.request(options, (res) => {\n\t\t\tconst {statusCode} = res;\n\n\t\t\tlet error;\n\t\t\tif (statusCode >= 400) {\n\t\t\t\terror = new Error('Request Failed.\\n' +\n\t\t\t\t\t`Status Code: ${statusCode}\\n` +\n\t\t\t\t\t`URL: ${options.hostname}:${options.port}${options.path}`);\n\t\t\t}\n\n\t\t\tif (error) {\n\t\t\t\tcallback({error: error, statusCode: statusCode});\n\t\t\t\t// free up memory\n\t\t\t\tres.resume();\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tlet rawData = '';\n\t\t\tres.on('data', (chunk) => {\n\t\t\t\trawData += chunk;\n\t\t\t});\n\t\t\tres.on('end', () => {\n\t\t\t\ttry {\n\t\t\t\t\tcallback(undefined, rawData, res.headers);\n\t\t\t\t} catch (err) {\n\t\t\t\t\treturn callback(err);\n\t\t\t\t}finally {\n\t\t\t\t\t//trying to prevent getting ECONNRESET error after getting our response\n\t\t\t\t\treq.abort();\n\t\t\t\t}\n\t\t\t});\n\t\t}).on(\"error\", (error) => {\n\t\t\tconsole.log(`[POST] ${url}`, error);\n\t\t\tcallback(error);\n\t\t});\n\n\t\tif (data && data.pipe && typeof data.pipe === \"function\") {\n\t\t\tdata.pipe(req);\n\t\t\treturn;\n\t\t}\n\n\t\tif (typeof data !== 'string' && !Buffer.isBuffer(data) && !ArrayBuffer.isView(data)) {\n\t\t\tdata = JSON.stringify(data);\n\t\t}\n\n\t\treq.write(data);\n\t\treq.end();\n\t};\n}\n\n$$.remote.doHttpPost = generateMethodForRequestWithData('POST');\n\n$$.remote.doHttpPut = generateMethodForRequestWithData('PUT');\n\n$$.remote.doHttpGet = function doHttpGet(url, callback){\n    const innerUrl = URL.parse(url);\n\n\tconst options = {\n\t\thostname: innerUrl.hostname,\n\t\tpath: innerUrl.pathname + (innerUrl.search || ''),\n\t\tport: parseInt(innerUrl.port),\n\t\theaders: {\n\t\t\t'User-Agent': userAgent,\n            [signatureHeaderName]: 'someSignature'\n\t\t},\n\t\tmethod: 'GET'\n\t};\n\n\tconst network = getNetworkForOptions(innerUrl);\n\tconst req = network.request(options, (res) => {\n\t\tconst { statusCode } = res;\n\n\t\tlet error;\n\t\tif (statusCode !== 200) {\n\t\t\terror = new Error('Request Failed.\\n' +\n\t\t\t\t`Status Code: ${statusCode}`);\n\t\t\terror.code = statusCode;\n\t\t}\n\n\t\tif (error) {\n\t\t\tcallback({error:error, statusCode:statusCode});\n\t\t\t// free up memory\n\t\t\tres.resume();\n\t\t\treturn\n\t\t}\n\n\t\tlet rawData;\n\t\tconst contentType = res.headers['content-type'];\n\n\t\tif(contentType === \"application/octet-stream\"){\n\t\t\trawData = [];\n\t\t}else{\n\t\t\trawData = '';\n\t\t}\n\n\t\tres.on('data', (chunk) => {\n\t\t\tif(Array.isArray(rawData)){\n\t\t\t\trawData.push(...chunk);\n\t\t\t}else{\n\t\t\t\trawData += chunk;\n\t\t\t}\n\t\t});\n\t\tres.on('end', () => {\n\t\t\ttry {\n\t\t\t\tif(Array.isArray(rawData)){\n\t\t\t\t\trawData = Buffer.from(rawData);\n\t\t\t\t}\n\t\t\t\tcallback(null, rawData, res.headers);\n\t\t\t} catch (err) {\n\t\t\t\tconsole.log(\"Client error:\", err);\n\t\t\t}finally {\n\t\t\t\t//trying to prevent getting ECONNRESET error after getting our response\n\t\t\t\treq.abort();\n\t\t\t}\n\t\t});\n\t});\n\n\treq.on(\"error\", (error) => {\n\t\tif(error && error.code !== 'ECONNRESET'){\n        \tconsole.log(`[GET] ${url}`, error);\n\t\t}\n\n\t\tcallback(error);\n\t});\n\n\treq.end();\n};\n\n$$.remote.base64Encode = function base64Encode(stringToEncode){\n    return Buffer.from(stringToEncode).toString('base64');\n};\n\n$$.remote.base64Decode = function base64Decode(encodedString){\n    return Buffer.from(encodedString, 'base64').toString('ascii');\n};\n","function PskCrypto() {\n    const crypto = require('crypto');\n    const utils = require(\"./utils/cryptoUtils\");\n    const PskEncryption = require(\"./PskEncryption\");\n    const or = require('overwrite-require');\n\n    this.createPskEncryption = (algorithm) => {\n        return new PskEncryption(algorithm);\n    };\n\n    this.sign = function (privateKey, digest) {\n        if (typeof digest === \"string\") {\n            digest = Buffer.from(digest, \"hex\");\n        }\n\n        return crypto.createSign(\"sha256\").update(digest).sign(privateKey);\n    };\n\n    this.verify = function (publicKey, signature, digest) {\n        if (typeof digest === \"string\") {\n            digest = Buffer.from(digest, \"hex\");\n        }\n\n        if (typeof signature === \"string\") {\n            signature = Buffer.from(signature, \"hex\");\n        }\n        return crypto.createVerify(\"sha256\").update(digest).verify(publicKey, signature);\n    };\n\n    this.generateKeyPair = (callback) => {\n        crypto.generateKeyPair('rsa', {\n            modulusLength: 4096,\n            publicKeyEncoding: {\n                type: 'spki',\n                format: 'pem'\n            },\n            privateKeyEncoding: {\n                type: 'pkcs8',\n                format: 'pem',\n            }\n        }, callback);\n    };\n\n    this.privateEncrypt = (privateKey, data) => {\n        if (typeof data === \"string\") {\n            data = Buffer.from(data);\n        }\n\n        return crypto.privateEncrypt(privateKey, data);\n    };\n\n    this.privateDecrypt = (privateKey, encryptedData) => {\n        if (typeof encryptedData === \"string\") {\n            encryptedData = Buffer.from(encryptedData);\n        }\n\n        return crypto.privateDecrypt(privateKey, encryptedData);\n    };\n\n    this.publicEncrypt = (publicKey, data) => {\n        if (typeof data === \"string\") {\n            data = Buffer.from(data);\n        }\n\n        return crypto.publicEncrypt(publicKey, data);\n    };\n\n    this.publicDecrypt = (publicKey, encryptedData) => {\n        if (typeof encryptedData === \"string\") {\n            encryptedData = Buffer.from(encryptedData);\n        }\n\n        return crypto.publicDecrypt(publicKey, encryptedData);\n    };\n\n    this.pskHash = function (data, encoding) {\n        if (Buffer.isBuffer(data)) {\n            return utils.createPskHash(data, encoding);\n        }\n        if (data instanceof Object) {\n            return utils.createPskHash(JSON.stringify(data), encoding);\n        }\n        return utils.createPskHash(data, encoding);\n    };\n\n    this.pskHashStream = function (readStream, callback) {\n        const pskHash = new utils.PskHash();\n\n        readStream.on('data', (chunk) => {\n            pskHash.update(chunk);\n        });\n\n\n        readStream.on('end', () => {\n            callback(null, pskHash.digest());\n        })\n    };\n\n    this.generateSafeUid = function (password, additionalData) {\n        password = password || Buffer.alloc(0);\n        if (!additionalData) {\n            additionalData = Buffer.alloc(0);\n        }\n\n        if (!Buffer.isBuffer(additionalData)) {\n            additionalData = Buffer.from(additionalData);\n        }\n\n        return utils.encode(this.pskHash(Buffer.concat([password, additionalData])));\n    };\n\n    this.deriveKey = function deriveKey(algorithm, password) {\n        const keylen = utils.getKeyLength(algorithm);\n        const salt = utils.generateSalt(password, 32);\n        return crypto.pbkdf2Sync(password, salt, 1000, keylen, 'sha256');\n    };\n\n\n    this.randomBytes = (len) => {\n        if ($$.environmentType === or.constants.BROWSER_ENVIRONMENT_TYPE) {\n            let randomArray = new Uint8Array(len);\n\n            return window.crypto.getRandomValues(randomArray);\n        } else {\n            return crypto.randomBytes(len);\n        }\n    };\n\n    this.xorBuffers = (...args) => {\n        if (args.length < 2) {\n            throw Error(`The function should receive at least two arguments. Received ${args.length}`);\n        }\n\n        if (args.length === 2) {\n            __xorTwoBuffers(args[0], args[1]);\n            return args[1];\n        }\n\n        for (let i = 0; i < args.length - 1; i++) {\n            __xorTwoBuffers(args[i], args[i + 1]);\n        }\n\n        function __xorTwoBuffers(a, b) {\n            if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n                throw Error(\"The argument type should be Buffer.\");\n            }\n\n            const length = Math.min(a.length, b.length);\n            for (let i = 0; i < length; i++) {\n                b[i] ^= a[i];\n            }\n\n            return b;\n        }\n\n        return args[args.length - 1];\n    };\n\n    this.PskHash = utils.PskHash;\n}\n\nmodule.exports = new PskCrypto();\n\n\n","const crypto = require(\"crypto\");\nconst utils = require(\"./utils/cryptoUtils\");\n\nfunction PskEncryption(algorithm) {\n    if (!algorithm) {\n        throw Error(\"No encryption algorithm was provided\");\n    }\n\n    let iv;\n    let aad;\n    let tag;\n    let data;\n    let key;\n\n    let keylen = utils.getKeyLength(algorithm);\n    let encryptionIsAuthenticated = utils.encryptionIsAuthenticated(algorithm);\n\n    this.encrypt = (plainData, encryptionKey, options) => {\n        iv = iv || crypto.randomBytes(16);\n        const cipher = crypto.createCipheriv(algorithm, encryptionKey, iv, options);\n        if (encryptionIsAuthenticated) {\n            aad = crypto.randomBytes(encryptionKey.length);\n            cipher.setAAD(aad);\n        }\n\n        const encData = Buffer.concat([cipher.update(plainData), cipher.final()]);\n        if (encryptionIsAuthenticated) {\n            tag = cipher.getAuthTag();\n        }\n\n        key = encryptionKey;\n        return encData;\n    };\n\n    this.decrypt = (encryptedData, decryptionKey, authTagLength = 0, options) => {\n        if (!iv) {\n            this.getDecryptionParameters(encryptedData, authTagLength);\n        }\n        const decipher = crypto.createDecipheriv(algorithm, decryptionKey, iv, options);\n        if (encryptionIsAuthenticated) {\n            decipher.setAAD(aad);\n            decipher.setAuthTag(tag);\n        }\n\n        return Buffer.concat([decipher.update(data), decipher.final()]);\n    };\n\n    this.getEncryptionParameters = () => {\n        if (!iv) {\n            return;\n        }\n\n        return {iv, aad, key, tag};\n    };\n\n    this.getDecryptionParameters = (encryptedData, authTagLength = 0) => {\n        let aadLen = 0;\n        if (encryptionIsAuthenticated) {\n            authTagLength = 16;\n            aadLen = keylen;\n        }\n\n        const tagOffset = encryptedData.length - authTagLength;\n        tag = encryptedData.slice(tagOffset, encryptedData.length);\n\n        const aadOffset = tagOffset - aadLen;\n        aad = encryptedData.slice(aadOffset, tagOffset);\n\n        iv = encryptedData.slice(aadOffset - 16, aadOffset);\n        data = encryptedData.slice(0, aadOffset - 16);\n\n        return {iv, aad, tag, data};\n    };\n\n    this.generateEncryptionKey = () => {\n        keylen = utils.getKeyLength(algorithm);\n        return crypto.randomBytes(keylen);\n    };\n}\n\nmodule.exports = PskEncryption;","const stream = require('stream');\nconst util = require('util');\n\nconst Duplex = stream.Duplex;\n\nfunction DuplexStream(options) {\n\tif (!(this instanceof DuplexStream)) {\n\t\treturn new DuplexStream(options);\n\t}\n\tDuplex.call(this, options);\n}\nutil.inherits(DuplexStream, Duplex);\n\nDuplexStream.prototype._write = function (chunk, enc, cb) {\n\tthis.push(chunk);\n\tcb();\n};\n\n\nDuplexStream.prototype._read = function (n) {\n\n};\n\nmodule.exports = DuplexStream;","const crypto = require('crypto');\n\nconst keySizes = [128, 192, 256];\nconst authenticationModes = [\"ocb\", \"ccm\", \"gcm\"];\n\nfunction encode(buffer) {\n\treturn buffer.toString('base64')\n\t\t.replace(/\\+/g, '')\n\t\t.replace(/\\//g, '')\n\t\t.replace(/=+$/, '');\n}\n\nfunction createPskHash(data, encoding) {\n\tconst pskHash = new PskHash();\n\tpskHash.update(data);\n\treturn pskHash.digest(encoding);\n}\n\nfunction PskHash() {\n\tconst sha512 = crypto.createHash('sha512');\n\tconst sha256 = crypto.createHash('sha256');\n\n\tfunction update(data) {\n\t\tsha512.update(data);\n\t}\n\n\tfunction digest(encoding) {\n\t\tsha256.update(sha512.digest());\n\t\treturn sha256.digest(encoding);\n\t}\n\n\treturn {\n\t\tupdate,\n\t\tdigest\n\t}\n}\n\n\nfunction generateSalt(inputData, saltLen) {\n\tconst hash = crypto.createHash('sha512');\n\thash.update(inputData);\n\tconst digest = Buffer.from(hash.digest('hex'), 'binary');\n\n\treturn digest.slice(0, saltLen);\n}\n\nfunction encryptionIsAuthenticated(algorithm) {\n\tfor (const mode of authenticationModes) {\n\t\tif (algorithm.includes(mode)) {\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nfunction getKeyLength(algorithm) {\n\tfor (const len of keySizes) {\n\t\tif (algorithm.includes(len.toString())) {\n\t\t\treturn len / 8;\n\t\t}\n\t}\n\n\tthrow new Error(\"Invalid encryption algorithm.\");\n}\n\nmodule.exports = {\n\tcreatePskHash,\n\tencode,\n\tgenerateSalt,\n\tPskHash,\n\tgetKeyLength,\n\tencryptionIsAuthenticated\n};\n\n","const stream = require('stream');\n\n\nfunction isStream (obj) {\n\treturn obj instanceof stream.Stream || obj instanceof stream.Duplex;\n}\n\n\nfunction isReadable (obj) {\n\treturn isStream(obj) && typeof obj._read === 'function' && typeof obj._readableState === 'object'\n}\n\n\nfunction isWritable (obj) {\n\treturn isStream(obj) && typeof obj._write === 'function' && typeof obj._writableState === 'object'\n}\n\n\nfunction isDuplex (obj) {\n\treturn isReadable(obj) && isWritable(obj)\n}\n\n\nmodule.exports            = isStream;\nmodule.exports.isReadable = isReadable;\nmodule.exports.isWritable = isWritable;\nmodule.exports.isDuplex   = isDuplex;","/*\n SignSens helper functions\n */\nconst crypto = require('crypto');\n\nexports.wipeOutsidePayload = function wipeOutsidePayload(hashStringHexa, pos, size){\n    var result;\n    var sz = hashStringHexa.length;\n\n    var end = (pos + size) % sz;\n\n    if(pos < end){\n        result = '0'.repeat(pos) +  hashStringHexa.substring(pos, end) + '0'.repeat(sz - end);\n    }\n    else {\n        result = hashStringHexa.substring(0, end) + '0'.repeat(pos - end) + hashStringHexa.substring(pos, sz);\n    }\n    return result;\n}\n\n\n\nexports.extractPayload = function extractPayload(hashStringHexa, pos, size){\n    var result;\n\n    var sz = hashStringHexa.length;\n    var end = (pos + size) % sz;\n\n    if( pos < end){\n        result = hashStringHexa.substring(pos, pos + size);\n    } else{\n\n        if(0 != end){\n            result = hashStringHexa.substring(0, end)\n        }  else {\n            result = \"\";\n        }\n        result += hashStringHexa.substring(pos, sz);\n    }\n    return result;\n}\n\n\n\nexports.fillPayload = function fillPayload(payload, pos, size){\n    var sz = 64;\n    var result = \"\";\n\n    var end = (pos + size) % sz;\n\n    if( pos < end){\n        result = '0'.repeat(pos) + payload + '0'.repeat(sz - end);\n    } else{\n        result = payload.substring(0,end);\n        result += '0'.repeat(pos - end);\n        result += payload.substring(end);\n    }\n    return result;\n}\n\n\n\nexports.generatePosHashXTimes = function generatePosHashXTimes(buffer, pos, size, count){ //generate positional hash\n    var result  = buffer.toString(\"hex\");\n\n    /*if(pos != -1 )\n        result[pos] = 0; */\n\n    for(var i = 0; i < count; i++){\n        var hash = crypto.createHash('sha256');\n        result = exports.wipeOutsidePayload(result, pos, size);\n        hash.update(result);\n        result = hash.digest('hex');\n    }\n    return exports.wipeOutsidePayload(result, pos, size);\n}\n\nexports.hashStringArray = function (counter, arr, payloadSize){\n\n    const hash = crypto.createHash('sha256');\n    var result = counter.toString(16);\n\n    for(var i = 0 ; i < 64; i++){\n        result += exports.extractPayload(arr[i],i, payloadSize);\n    }\n\n    hash.update(result);\n    var result = hash.digest('hex');\n    return result;\n}\n\n\n\n\n\n\nfunction dumpMember(obj){\n    var type = Array.isArray(obj) ? \"array\" : typeof obj;\n    if(obj === null){\n        return \"null\";\n    }\n    if(obj === undefined){\n        return \"undefined\";\n    }\n\n    switch(type){\n        case \"number\":\n        case \"string\":return obj.toString(); break;\n        case \"object\": return exports.dumpObjectForHashing(obj); break;\n        case \"boolean\": return  obj? \"true\": \"false\"; break;\n        case \"array\":\n            var result = \"\";\n            for(var i=0; i < obj.length; i++){\n                result += exports.dumpObjectForHashing(obj[i]);\n            }\n            return result;\n            break;\n        default:\n            throw new Error(\"Type \" +  type + \" cannot be cryptographically digested\");\n    }\n\n}\n\n\nexports.dumpObjectForHashing = function(obj){\n    var result = \"\";\n\n    if(obj === null){\n        return \"null\";\n    }\n    if(obj === undefined){\n        return \"undefined\";\n    }\n\n    var basicTypes = {\n        \"array\"     : true,\n        \"number\"    : true,\n        \"boolean\"   : true,\n        \"string\"    : true,\n        \"object\"    : false\n    }\n\n    var type = Array.isArray(obj) ? \"array\" : typeof obj;\n    if( basicTypes[type]){\n        return dumpMember(obj);\n    }\n\n    var keys = Object.keys(obj);\n    keys.sort();\n\n\n    for(var i=0; i < keys.length; i++){\n        result += dumpMember(keys[i]);\n        result += dumpMember(obj[keys[i]]);\n    }\n\n    return result;\n}\n\n\nexports.hashValues  = function (values){\n    const hash = crypto.createHash('sha256');\n    var result = exports.dumpObjectForHashing(values);\n    hash.update(result);\n    return hash.digest('hex');\n};\n\nexports.getJSONFromSignature = function getJSONFromSignature(signature, size){\n    var result = {\n        proof:[]\n    };\n    var a = signature.split(\":\");\n    result.agent        = a[0];\n    result.counter      =  parseInt(a[1], \"hex\");\n    result.nextPublic   =  a[2];\n\n    var proof = a[3]\n\n\n    if(proof.length/size != 64) {\n        throw new Error(\"Invalid signature \" + proof);\n    }\n\n    for(var i = 0; i < 64; i++){\n        result.proof.push(exports.fillPayload(proof.substring(i * size,(i+1) * size ), i, size))\n    }\n\n    return result;\n}\n\nexports.createSignature = function (agent,counter, nextPublic, arr, size){\n    var result = \"\";\n\n    for(var i = 0; i < arr.length; i++){\n        result += exports.extractPayload(arr[i], i , size);\n    }\n\n    return agent + \":\" + counter + \":\" + nextPublic + \":\" + result;\n}","function BootEngine(getSeed, getEDFS, initializeSwarmEngine, runtimeBundles, constitutionBundles) {\n\n\tif (typeof getSeed !== \"function\") {\n\t\tthrow new Error(\"getSeed missing or not a function\");\n\t}\n\tgetSeed = promisify(getSeed);\n\n\tif (typeof getEDFS !== \"function\") {\n\t\tthrow new Error(\"getEDFS missing or not a function\");\n\t}\n\tgetEDFS = promisify(getEDFS);\n\n\tif (typeof initializeSwarmEngine !== \"function\") {\n\t\tthrow new Error(\"initializeSwarmEngine missing or not a function\");\n\t}\n\tinitializeSwarmEngine = promisify(initializeSwarmEngine);\n\n\tif (typeof runtimeBundles !== \"undefined\" && !Array.isArray(runtimeBundles)) {\n\t\tthrow new Error(\"runtimeBundles is not array\");\n\t}\n\n\tif (typeof constitutionBundles !== \"undefined\" && !Array.isArray(constitutionBundles)) {\n\t\tthrow new Error(\"constitutionBundles is not array\");\n\t}\n\n\tconst EDFS = require('edfs');\n\tlet edfs;\n\tconst pskPath = require(\"swarmutils\").path;\n\n\tconst evalBundles = async (bundles, ignore) => {\n\t\tconst listFiles = promisify(this.rawDossier.listFiles);\n\t\tconst readFile = promisify(this.rawDossier.readFile);\n\n\t\tlet fileList = await listFiles(pskPath.join(EDFS.constants.CSB.CODE_FOLDER, EDFS.constants.CSB.CONSTITUTION_FOLDER));\n\n\t\tfileList = bundles.filter(bundle => fileList.includes(bundle))\n\t\t\t.map(bundle => pskPath.join(EDFS.constants.CSB.CODE_FOLDER, EDFS.constants.CSB.CONSTITUTION_FOLDER, bundle));\n\n\t\tif (fileList.length !== bundles.length) {\n\t\t\tconst message = `Some bundles missing. Expected to have ${JSON.stringify(bundles)} but got only ${JSON.stringify(fileList)}`;\n\t\t\tif (!ignore) {\n\t\t\t\tthrow new Error(message);\n\t\t\t} else {\n\t\t\t\tconsole.log(message);\n\t\t\t}\n\t\t}\n\n\n\t\tfor (let i = 0; i < fileList.length; i++) {\n\t\t\tvar fileContent = await readFile(fileList[i]);\n\t\t\teval(fileContent.toString());\n\t\t}\n\t};\n\n\tthis.boot = function (callback) {\n\t\tconst __boot = async () => {\n\t\t\tconst seed = await getSeed();\n\t\t\tedfs = await getEDFS();\n\t\t\tthis.rawDossier = edfs.loadRawDossier(seed);\n\t\t\ttry{\n                await evalBundles(runtimeBundles);\n            }catch(err)\n            {\n                console.log(err);\n            }\n\t\t\tawait initializeSwarmEngine();\n\t\t\tif (typeof constitutionBundles !== \"undefined\") {\n\t\t\t\ttry{\n\t\t\t\t\tawait evalBundles(constitutionBundles, true);\n\t\t\t\t}catch(err)\n\t\t\t\t{\n\t\t\t\t\tconsole.log(err);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\t__boot()\n\t\t\t.then(() => callback(undefined, this.rawDossier))\n\t\t\t.catch(callback);\n\t};\n}\n\nfunction promisify(fn) {\n\treturn function (...args) {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tfn(...args, (err, ...res) => {\n\t\t\t\tif (err) {\n\t\t\t\t\treject(err);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(...res);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n}\n\nmodule.exports = BootEngine;\n","function product(args) {\n    if(!args.length){\n        return [ [] ];\n    }\n    var prod = product(args.slice(1)), r = [];\n    args[0].forEach(function(x) {\n        prod.forEach(function(p) {\n            r.push([ x ].concat(p));\n        });\n    });\n    return r;\n}\n\nfunction objectProduct(obj) {\n    var keys = Object.keys(obj),\n        values = keys.map(function(x) { return obj[x]; });\n\n    return product(values).map(function(p) {\n        var e = {};\n        keys.forEach(function(k, n) { e[k] = p[n]; });\n        return e;\n    });\n}\n\nmodule.exports = objectProduct;","var meta = \"meta\";\n\nfunction OwM(serialized){\n\n    if(serialized){\n        return OwM.prototype.convert(serialized);\n    }\n\n    Object.defineProperty(this, meta, {\n        writable: false,\n        enumerable: true,\n        value: {}\n    });\n\n    Object.defineProperty(this, \"setMeta\", {\n        writable: false,\n        enumerable: false,\n        configurable:false,\n        value: function(prop, value){\n            if(typeof prop == \"object\" && typeof value == \"undefined\"){\n                for(var p in prop){\n                    this[meta][p] = prop[p];\n                }\n                return prop;\n            }\n            this[meta][prop] = value;\n            return value;\n        }\n    });\n\n    Object.defineProperty(this, \"getMeta\", {\n        writable: false,\n        value: function(prop){\n            return this[meta][prop];\n        }\n    });\n}\n\nfunction testOwMSerialization(obj){\n    let res = false;\n\n    if(obj){\n        res = typeof obj[meta] != \"undefined\" && !(obj instanceof OwM);\n    }\n\n    return res;\n}\n\nOwM.prototype.convert = function(serialized){\n    const owm = new OwM();\n\n    for(var metaProp in serialized.meta){\n        if(!testOwMSerialization(serialized[metaProp])) {\n            owm.setMeta(metaProp, serialized.meta[metaProp]);\n        }else{\n            owm.setMeta(metaProp, OwM.prototype.convert(serialized.meta[metaProp]));\n        }\n    }\n\n    for(var simpleProp in serialized){\n        if(simpleProp === meta) {\n            continue;\n        }\n\n        if(!testOwMSerialization(serialized[simpleProp])){\n            owm[simpleProp] = serialized[simpleProp];\n        }else{\n            owm[simpleProp] = OwM.prototype.convert(serialized[simpleProp]);\n        }\n    }\n\n    return owm;\n};\n\nOwM.prototype.getMetaFrom = function(obj, name){\n    var res;\n    if(!name){\n        res = obj[meta];\n    }else{\n        res = obj[meta][name];\n    }\n    return res;\n};\n\nOwM.prototype.setMetaFor = function(obj, name, value){\n    obj[meta][name] = value;\n    return obj[meta][name];\n};\n\nmodule.exports = OwM;","function QueueElement(content) {\n\tthis.content = content;\n\tthis.next = null;\n}\n\nfunction Queue() {\n\tthis.head = null;\n\tthis.tail = null;\n\tthis.length = 0;\n\tthis.push = function (value) {\n\t\tconst newElement = new QueueElement(value);\n\t\tif (!this.head) {\n\t\t\tthis.head = newElement;\n\t\t\tthis.tail = newElement;\n\t\t} else {\n\t\t\tthis.tail.next = newElement;\n\t\t\tthis.tail = newElement;\n\t\t}\n\t\tthis.length++;\n\t};\n\n\tthis.pop = function () {\n\t\tif (!this.head) {\n\t\t\treturn null;\n\t\t}\n\t\tconst headCopy = this.head;\n\t\tthis.head = this.head.next;\n\t\tthis.length--;\n\n\t\t//fix???????\n\t\tif(this.length === 0){\n            this.tail = null;\n\t\t}\n\n\t\treturn headCopy.content;\n\t};\n\n\tthis.front = function () {\n\t\treturn this.head ? this.head.content : undefined;\n\t};\n\n\tthis.isEmpty = function () {\n\t\treturn this.head === null;\n\t};\n\n\tthis[Symbol.iterator] = function* () {\n\t\tlet head = this.head;\n\t\twhile(head !== null) {\n\t\t\tyield head.content;\n\t\t\thead = head.next;\n\t\t}\n\t}.bind(this);\n}\n\nQueue.prototype.toString = function () {\n\tlet stringifiedQueue = '';\n\tlet iterator = this.head;\n\twhile (iterator) {\n\t\tstringifiedQueue += `${JSON.stringify(iterator.content)} `;\n\t\titerator = iterator.next;\n\t}\n\treturn stringifiedQueue;\n};\n\nQueue.prototype.inspect = Queue.prototype.toString;\n\nmodule.exports = Queue;","const HEADER_SIZE_RESEARVED = 4;\n\nfunction SwarmPacker(){\n}\n\nfunction copyStringtoArrayBuffer(str, buffer){\n    if(typeof str !== \"string\"){\n        throw new Error(\"Wrong param type received\");\n    }\n    for(var i = 0; i < str.length; i++) {\n        buffer[i] = str.charCodeAt(i);\n    }\n    return buffer;\n}\n\nfunction copyFromBuffer(target, source){\n    for(let i=0; i<source.length; i++){\n        target[i] = source[i];\n    }\n    return target;\n}\n\nlet serializers = {};\n\nSwarmPacker.registerSerializer = function(name, implementation){\n    if(serializers[name]){\n        throw new Error(\"Serializer name already exists\");\n    }\n    serializers[name] = implementation;\n};\n\nfunction getSerializer(name){\n    return serializers[name];\n}\n\nSwarmPacker.getSerializer = getSerializer;\n\nObject.defineProperty(SwarmPacker.prototype, \"JSON\", {value: \"json\"});\nObject.defineProperty(SwarmPacker.prototype, \"MSGPACK\", {value: \"msgpack\"});\n\nSwarmPacker.registerSerializer(SwarmPacker.prototype.JSON, {\n    serialize: JSON.stringify,\n    deserialize: (serialization)=>{\n        if(typeof serialization !== \"string\"){\n            serialization = String.fromCharCode.apply(null, serialization);\n        }\n        return JSON.parse(serialization);\n    },\n    getType: ()=>{\n        return SwarmPacker.prototype.JSON;\n    }\n});\n\nfunction registerMsgPackSerializer(){\n    const mp = '@msgpack/msgpack';\n    let msgpack;\n\n    try{\n        msgpack = require(mp);\n        if (typeof msgpack === \"undefined\") {\n            throw new Error(\"msgpack is unavailable.\")\n        }\n    }catch(err){\n        console.log(\"msgpack not available. If you need msgpack serialization include msgpack in one of your bundles\");\n        //preventing msgPack serializer being register if msgPack dep is not found.\n        return;\n    }\n\n    SwarmPacker.registerSerializer(SwarmPacker.prototype.MSGPACK, {\n        serialize: msgpack.encode,\n        deserialize: msgpack.decode,\n        getType: ()=>{\n            return SwarmPacker.prototype.MSGPACK;\n        }\n    });\n}\n\nregisterMsgPackSerializer();\n\nSwarmPacker.pack = function(swarm, serializer){\n\n    let jsonSerializer = getSerializer(SwarmPacker.prototype.JSON);\n    if(typeof serializer === \"undefined\"){\n        serializer = jsonSerializer;\n    }\n\n    let swarmSerialization = serializer.serialize(swarm);\n\n    let header = {\n        command: swarm.getMeta(\"command\"),\n        swarmId : swarm.getMeta(\"swarmId\"),\n        swarmTypeName: swarm.getMeta(\"swarmTypeName\"),\n        swarmTarget: swarm.getMeta(\"target\"),\n        serializationType: serializer.getType()\n    };\n\n    header = serializer.serialize(header);\n\n    if(header.length >= Math.pow(2, 32)){\n        throw new Error(\"Swarm serialization too big.\");\n    }\n\n    //arraybuffer construction\n    let size = HEADER_SIZE_RESEARVED + header.length + swarmSerialization.length;\n    let pack = new ArrayBuffer(size);\n\n    let sizeHeaderView = new DataView(pack, 0);\n    sizeHeaderView.setUint32(0, header.length);\n\n    let headerView = new Uint8Array(pack, HEADER_SIZE_RESEARVED);\n    copyStringtoArrayBuffer(header, headerView);\n\n    let serializationView = new Uint8Array(pack, HEADER_SIZE_RESEARVED+header.length);\n    if(typeof swarmSerialization === \"string\"){\n        copyStringtoArrayBuffer(swarmSerialization, serializationView);\n    }else{\n        copyFromBuffer(serializationView, swarmSerialization);\n    }\n\n    return pack;\n};\n\nSwarmPacker.unpack = function(pack){\n    let jsonSerialiser = SwarmPacker.getSerializer(SwarmPacker.prototype.JSON);\n    let headerSerialization = getHeaderSerializationFromPack(pack);\n    let header = jsonSerialiser.deserialize(headerSerialization);\n\n    let serializer = SwarmPacker.getSerializer(header.serializationType);\n    let messageView = new Uint8Array(pack, HEADER_SIZE_RESEARVED+headerSerialization.length);\n\n    let swarm = serializer.deserialize(messageView);\n    return swarm;\n};\n\nfunction getHeaderSerializationFromPack(pack){\n    let headerSize = new DataView(pack).getUint32(0);\n\n    let headerView = new Uint8Array(pack, HEADER_SIZE_RESEARVED, headerSize);\n    return headerView;\n}\n\nSwarmPacker.getHeader = function(pack){\n    let jsonSerialiser = SwarmPacker.getSerializer(SwarmPacker.prototype.JSON);\n    let header = jsonSerialiser.deserialize(getHeaderSerializationFromPack(pack));\n\n    return header;\n};\nmodule.exports = SwarmPacker;","\nfunction TaskCounter(finalCallback) {\n\tlet results = [];\n\tlet errors = [];\n\n\tlet started = 0;\n\n\tfunction decrement(err, res) {\n\t\tif(err) {\n\t\t\terrors.push(err);\n\t\t}\n\n\t\tif(arguments.length > 2) {\n\t\t\targuments[0] = undefined;\n\t\t\tres = arguments;\n\t\t}\n\n\t\tif(typeof res !== \"undefined\") {\n\t\t\tresults.push(res);\n\t\t}\n\n\t\tif(--started <= 0) {\n            return callCallback();\n\t\t}\n\t}\n\n\tfunction increment(amount = 1) {\n\t\tstarted += amount;\n\t}\n\n\tfunction callCallback() {\n\t    if(errors && errors.length === 0) {\n\t        errors = undefined;\n        }\n\n\t    if(results && results.length === 0) {\n\t        results = undefined;\n        }\n\n        finalCallback(errors, results);\n    }\n\n\treturn {\n\t\tincrement,\n\t\tdecrement\n\t};\n}\n\nmodule.exports = TaskCounter;","const OwM = require(\"./OwM\");\n\n/*\n    Prepare the state of a swarm to be serialised\n*/\n\nexports.asJSON = function(valueObj, phaseName, args, callback){\n\n        let valueObject = valueObj.valueOf();\n        let res = new OwM();\n        res.publicVars          = valueObject.publicVars;\n        res.privateVars         = valueObject.privateVars;\n\n        res.setMeta(\"COMMAND_ARGS\",        OwM.prototype.getMetaFrom(valueObject, \"COMMAND_ARGS\"));\n        res.setMeta(\"SecurityParadigm\",        OwM.prototype.getMetaFrom(valueObject, \"SecurityParadigm\"));\n        res.setMeta(\"swarmTypeName\", OwM.prototype.getMetaFrom(valueObject, \"swarmTypeName\"));\n        res.setMeta(\"swarmId\",       OwM.prototype.getMetaFrom(valueObject, \"swarmId\"));\n        res.setMeta(\"target\",        OwM.prototype.getMetaFrom(valueObject, \"target\"));\n        res.setMeta(\"homeSecurityContext\",        OwM.prototype.getMetaFrom(valueObject, \"homeSecurityContext\"));\n        res.setMeta(\"requestId\",        OwM.prototype.getMetaFrom(valueObject, \"requestId\"));\n\n\n        if(!phaseName){\n            res.setMeta(\"command\", \"stored\");\n        } else {\n            res.setMeta(\"phaseName\", phaseName);\n            res.setMeta(\"phaseId\", $$.uidGenerator.safe_uuid());\n            res.setMeta(\"args\", args);\n            res.setMeta(\"command\", OwM.prototype.getMetaFrom(valueObject, \"command\") || \"executeSwarmPhase\");\n        }\n\n        res.setMeta(\"waitStack\", valueObject.meta.waitStack); //TODO: think if is not better to be deep cloned and not referenced!!!\n\n        if(callback){\n            return callback(null, res);\n        }\n        //console.log(\"asJSON:\", res, valueObject);\n        return res;\n};\n\nexports.jsonToNative = function(serialisedValues, result){\n\n    for(let v in serialisedValues.publicVars){\n        result.publicVars[v] = serialisedValues.publicVars[v];\n\n    };\n    for(let l in serialisedValues.privateVars){\n        result.privateVars[l] = serialisedValues.privateVars[l];\n    };\n\n    for(let i in OwM.prototype.getMetaFrom(serialisedValues)){\n        OwM.prototype.setMetaFor(result, i, OwM.prototype.getMetaFrom(serialisedValues, i));\n    };\n\n};","function replaceAll(str, search, replacement) {\n    return str.split(search).join(replacement);\n}\n\nfunction resolve(pth) {\n    let pathSegments = pth.split(\"/\");\n    let makeAbsolute = pathSegments[0] === \"\" ? true : false;\n    for (let i = 0; i < pathSegments.length; i++) {\n        let segment = pathSegments[i];\n        if (segment === \"..\") {\n            let j = 1;\n            if (i > 0) {\n                j = j + 1;\n            } else {\n                makeAbsolute = true;\n            }\n            pathSegments.splice(i + 1 - j, j);\n            i = i - j;\n        }\n    }\n    let res = pathSegments.join(\"/\");\n    if (makeAbsolute && res !== \"\") {\n        res = __ensureIsAbsolute(res);\n    }\n    return res;\n}\n\nfunction normalize(pth) {\n    if (typeof pth !== \"string\") {\n        throw new TypeError();\n    }\n    pth = replaceAll(pth, \"\\\\\", \"/\");\n    pth = replaceAll(pth, /[/]+/, \"/\");\n\n    return resolve(pth);\n}\n\nfunction join(...args) {\n    let pth = \"\";\n    for (let i = 0; i < args.length; i++) {\n        pth += \"/\" + args[i];\n    }\n    return normalize(pth);\n}\n\nfunction __ensureIsAbsolute(pth) {\n    if (pth[0] !== \"/\") {\n        pth = \"/\" + pth;\n    }\n    return pth;\n}\n\nfunction isAbsolute(pth) {\n    pth = normalize(pth);\n    if (pth[0] !== \"/\") {\n        return false;\n    }\n\n    return true;\n}\n\nfunction ensureIsAbsolute(pth) {\n    pth = normalize(pth);\n    return __ensureIsAbsolute(pth);\n}\n\nmodule.exports = {\n    normalize,\n    join,\n    isAbsolute,\n    ensureIsAbsolute\n};\n","const PING = \"PING\";\nconst PONG = \"PONG\";\n\nmodule.exports.fork = function pingPongFork(modulePath, args, options){\n    const child_process = require(\"child_process\");\n    const defaultStdio = [\"inherit\", \"inherit\", \"inherit\", \"ipc\"];\n\n    if(!options){\n        options = {stdio: defaultStdio};\n    }else{\n        if(typeof options.stdio === \"undefined\"){\n            options.stdio = defaultStdio;\n        }\n\n        let stdio = options.stdio;\n        if(stdio.length<3){\n            for(let i=stdio.length; i<4; i++){\n                stdio.push(\"inherit\");\n            }\n            stdio.push(\"ipc\");\n        }\n    }\n\n    let child = child_process.fork(modulePath, args, options);\n\n    child.on(\"message\", (message)=>{\n        if(message === PING){\n            child.send(PONG);\n        }\n    });\n\n    return child;\n};\n\nmodule.exports.enableLifeLine = function(timeout){\n\n    if(typeof process.send === \"undefined\"){\n        console.log(\"\\\"process.send\\\" not found. LifeLine mechanism disabled!\");\n        return;\n    }\n\n    let lastConfirmationTime;\n    const interval = timeout || 2000;\n\n    // this is needed because new Date().getTime() has reduced precision to mitigate timer based attacks\n    // for more information see: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/getTime\n    const roundingError = 101;\n\n    function sendPing(){\n        try {\n            process.send(PING);\n        } catch (e) {\n            console.log('Parent is not available, shutting down');\n            exit(1)\n        }\n    }\n\n    process.on(\"message\", function (message){\n        if(message === PONG){\n            lastConfirmationTime = new Date().getTime();\n        }\n    });\n\n    function exit(code){\n        setTimeout(()=>{\n            process.exit(code);\n        }, 0);\n    }\n\n    const exceptionEvents = [\"SIGINT\", \"SIGUSR1\", \"SIGUSR2\", \"uncaughtException\", \"SIGTERM\", \"SIGHUP\"];\n    let killingSignal = false;\n    for(let i=0; i<exceptionEvents.length; i++){\n        process.on(exceptionEvents[i], (event, code)=>{\n            killingSignal = true;\n            clearInterval(timeoutInterval);\n            console.log(`Caught event type [${exceptionEvents[i]}]. Shutting down...`, code, event);\n            exit(code);\n        });\n    }\n\n    const timeoutInterval = setInterval(function(){\n        const currentTime = new Date().getTime();\n\n        if(typeof lastConfirmationTime === \"undefined\" || currentTime - lastConfirmationTime < interval + roundingError && !killingSignal){\n            sendPing();\n        }else{\n            console.log(\"Parent process did not answer. Shutting down...\", process.argv, killingSignal);\n            exit(1);\n        }\n    }, interval);\n};","var commands = {};\nvar commands_help = {};\n\n//global function addCommand\naddCommand = function addCommand(verb, adverbe, funct, helpLine){\n    var cmdId;\n    if(!helpLine){\n        helpLine = \" \";\n    } else {\n        helpLine = \" \" + helpLine;\n    }\n    if(adverbe){\n        cmdId = verb + \" \" +  adverbe;\n        helpLine = verb + \" \" +  adverbe + helpLine;\n    } else {\n        cmdId = verb;\n        helpLine = verb + helpLine;\n    }\n    commands[cmdId] = funct;\n        commands_help[cmdId] = helpLine;\n};\n\nfunction doHelp(){\n    console.log(\"List of commands:\");\n    for(var l in commands_help){\n        console.log(\"\\t\", commands_help[l]);\n    }\n}\n\naddCommand(\"-h\", null, doHelp, \"\\t\\t\\t\\t\\t\\t |just print the help\");\naddCommand(\"/?\", null, doHelp, \"\\t\\t\\t\\t\\t\\t |just print the help\");\naddCommand(\"help\", null, doHelp, \"\\t\\t\\t\\t\\t\\t |just print the help\");\n\n\nfunction runCommand(){\n  var argv = Object.assign([], process.argv);\n  var cmdId = null;\n  var cmd = null;\n  argv.shift();\n  argv.shift();\n\n  if(argv.length >=1){\n      cmdId = argv[0];\n      cmd = commands[cmdId];\n      argv.shift();\n  }\n\n\n  if(!cmd && argv.length >=1){\n      cmdId = cmdId + \" \" + argv[0];\n      cmd = commands[cmdId];\n      argv.shift();\n  }\n\n  if(!cmd){\n    if(cmdId){\n        console.log(\"Unknown command: \", cmdId);\n    }\n    cmd = doHelp;\n  }\n\n  cmd.apply(null,argv);\n\n}\n\nmodule.exports = {\n    runCommand\n};\n\n","\nfunction encode(buffer) {\n    return buffer.toString('base64')\n        .replace(/\\+/g, '')\n        .replace(/\\//g, '')\n        .replace(/=+$/, '');\n};\n\nfunction stampWithTime(buf, salt, msalt){\n    if(!salt){\n        salt = 1;\n    }\n    if(!msalt){\n        msalt = 1;\n    }\n    var date = new Date;\n    var ct = Math.floor(date.getTime() / salt);\n    var counter = 0;\n    while(ct > 0 ){\n        //console.log(\"Counter\", counter, ct);\n        buf[counter*msalt] = Math.floor(ct % 256);\n        ct = Math.floor(ct / 256);\n        counter++;\n    }\n}\n\n/*\n    The uid contains around 256 bits of randomness and are unique at the level of seconds. This UUID should by cryptographically safe (can not be guessed)\n\n    We generate a safe UID that is guaranteed unique (by usage of a PRNG to geneate 256 bits) and time stamping with the number of seconds at the moment when is generated\n    This method should be safe to use at the level of very large distributed systems.\n    The UUID is stamped with time (seconds): does it open a way to guess the UUID? It depends how safe is \"crypto\" PRNG, but it should be no problem...\n\n */\n\nvar generateUid = null;\n\n\nexports.init = function(externalGenerator){\n    generateUid = externalGenerator.generateUid;\n    return module.exports;\n};\n\nexports.safe_uuid = function() {\n    var buf = generateUid(32);\n    stampWithTime(buf, 1000, 3);\n    return encode(buf);\n};\n\n\n\n/*\n    Try to generate a small UID that is unique against chance in the same millisecond second and in a specific context (eg in the same choreography execution)\n    The id contains around 6*8 = 48  bits of randomness and are unique at the level of milliseconds\n    This method is safe on a single computer but should be used with care otherwise\n    This UUID is not cryptographically safe (can be guessed)\n */\nexports.short_uuid = function(callback) {\n    require('crypto').randomBytes(12, function (err, buf) {\n        if (err) {\n            callback(err);\n            return;\n        }\n        stampWithTime(buf,1,2);\n        callback(null, encode(buf));\n    });\n};","const crypto = require('crypto');\nconst Queue = require(\"./Queue\");\nvar PSKBuffer = typeof $$ !== \"undefined\" && $$.PSKBuffer ? $$.PSKBuffer : Buffer;\n\nfunction UidGenerator(minBuffers, buffersSize) {\n    var buffers = new Queue();\n    var lowLimit = .2;\n\n    function fillBuffers(size) {\n        //notifyObserver();\n        const sz = size || minBuffers;\n        if (buffers.length < Math.floor(minBuffers * lowLimit)) {\n            for (var i = buffers.length; i < sz; i++) {\n                generateOneBuffer(null);\n            }\n        }\n    }\n\n    fillBuffers();\n\n    function generateOneBuffer(b) {\n        if (!b) {\n            b = PSKBuffer.alloc(0);\n        }\n        const sz = buffersSize - b.length;\n        /*crypto.randomBytes(sz, function (err, res) {\n            buffers.push(Buffer.concat([res, b]));\n            notifyObserver();\n        });*/\n        buffers.push(PSKBuffer.concat([crypto.randomBytes(sz), b]));\n        notifyObserver();\n    }\n\n    function extractN(n) {\n        var sz = Math.floor(n / buffersSize);\n        var ret = [];\n\n        for (var i = 0; i < sz; i++) {\n            ret.push(buffers.pop());\n            setTimeout(generateOneBuffer, 1);\n        }\n\n\n        var remainder = n % buffersSize;\n        if (remainder > 0) {\n            var front = buffers.pop();\n            ret.push(front.slice(0, remainder));\n            //generateOneBuffer(front.slice(remainder));\n            setTimeout(function () {\n                generateOneBuffer(front.slice(remainder));\n            }, 1);\n        }\n\n        //setTimeout(fillBuffers, 1);\n\n        return Buffer.concat(ret);\n    }\n\n    var fillInProgress = false;\n\n    this.generateUid = function (n) {\n        var totalSize = buffers.length * buffersSize;\n        if (n <= totalSize) {\n            return extractN(n);\n        } else {\n            if (!fillInProgress) {\n                fillInProgress = true;\n                setTimeout(function () {\n                    fillBuffers(Math.floor(minBuffers * 2.5));\n                    fillInProgress = false;\n                }, 1);\n            }\n            return crypto.randomBytes(n);\n        }\n    };\n\n    var observer;\n    this.registerObserver = function (obs) {\n        if (observer) {\n            console.error(new Error(\"One observer allowed!\"));\n        } else {\n            if (typeof obs == \"function\") {\n                observer = obs;\n                //notifyObserver();\n            }\n        }\n    };\n\n    function notifyObserver() {\n        if (observer) {\n            var valueToReport = buffers.length * buffersSize;\n            setTimeout(function () {\n                observer(null, {\"size\": valueToReport});\n            }, 10);\n        }\n    }\n}\n\nmodule.exports.createUidGenerator = function (minBuffers, bufferSize) {\n    return new UidGenerator(minBuffers, bufferSize);\n};\n","/*!\n * Determine if an object is a Buffer\n *\n * @author   Feross Aboukhadijeh <https://feross.org>\n * @license  MIT\n */\n\n// The _isBuffer check is for Safari 5-7 support, because it's missing\n// Object.prototype.constructor. Remove this eventually\nmodule.exports = function (obj) {\n  return obj != null && (isBuffer(obj) || isSlowBuffer(obj) || !!obj._isBuffer)\n}\n\nfunction isBuffer (obj) {\n  return !!obj.constructor && typeof obj.constructor.isBuffer === 'function' && obj.constructor.isBuffer(obj)\n}\n\n// For Node v0.10 support. Remove this eventually.\nfunction isSlowBuffer (obj) {\n  return typeof obj.readFloatLE === 'function' && typeof obj.slice === 'function' && isBuffer(obj.slice(0, 0))\n}\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar has = Object.prototype.hasOwnProperty;\nvar hasNativeMap = typeof Map !== \"undefined\";\n\n/**\n * A data structure which is a combination of an array and a set. Adding a new\n * member is O(1), testing for membership is O(1), and finding the index of an\n * element is O(1). Removing elements from the set is not supported. Only\n * strings are supported for membership.\n */\nfunction ArraySet() {\n  this._array = [];\n  this._set = hasNativeMap ? new Map() : Object.create(null);\n}\n\n/**\n * Static method for creating ArraySet instances from an existing array.\n */\nArraySet.fromArray = function ArraySet_fromArray(aArray, aAllowDuplicates) {\n  var set = new ArraySet();\n  for (var i = 0, len = aArray.length; i < len; i++) {\n    set.add(aArray[i], aAllowDuplicates);\n  }\n  return set;\n};\n\n/**\n * Return how many unique items are in this ArraySet. If duplicates have been\n * added, than those do not count towards the size.\n *\n * @returns Number\n */\nArraySet.prototype.size = function ArraySet_size() {\n  return hasNativeMap ? this._set.size : Object.getOwnPropertyNames(this._set).length;\n};\n\n/**\n * Add the given string to this set.\n *\n * @param String aStr\n */\nArraySet.prototype.add = function ArraySet_add(aStr, aAllowDuplicates) {\n  var sStr = hasNativeMap ? aStr : util.toSetString(aStr);\n  var isDuplicate = hasNativeMap ? this.has(aStr) : has.call(this._set, sStr);\n  var idx = this._array.length;\n  if (!isDuplicate || aAllowDuplicates) {\n    this._array.push(aStr);\n  }\n  if (!isDuplicate) {\n    if (hasNativeMap) {\n      this._set.set(aStr, idx);\n    } else {\n      this._set[sStr] = idx;\n    }\n  }\n};\n\n/**\n * Is the given string a member of this set?\n *\n * @param String aStr\n */\nArraySet.prototype.has = function ArraySet_has(aStr) {\n  if (hasNativeMap) {\n    return this._set.has(aStr);\n  } else {\n    var sStr = util.toSetString(aStr);\n    return has.call(this._set, sStr);\n  }\n};\n\n/**\n * What is the index of the given string in the array?\n *\n * @param String aStr\n */\nArraySet.prototype.indexOf = function ArraySet_indexOf(aStr) {\n  if (hasNativeMap) {\n    var idx = this._set.get(aStr);\n    if (idx >= 0) {\n        return idx;\n    }\n  } else {\n    var sStr = util.toSetString(aStr);\n    if (has.call(this._set, sStr)) {\n      return this._set[sStr];\n    }\n  }\n\n  throw new Error('\"' + aStr + '\" is not in the set.');\n};\n\n/**\n * What is the element at the given index?\n *\n * @param Number aIdx\n */\nArraySet.prototype.at = function ArraySet_at(aIdx) {\n  if (aIdx >= 0 && aIdx < this._array.length) {\n    return this._array[aIdx];\n  }\n  throw new Error('No element indexed by ' + aIdx);\n};\n\n/**\n * Returns the array representation of this set (which has the proper indices\n * indicated by indexOf). Note that this is a copy of the internal array used\n * for storing the members so that no one can mess with internal state.\n */\nArraySet.prototype.toArray = function ArraySet_toArray() {\n  return this._array.slice();\n};\n\nexports.ArraySet = ArraySet;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n *\n * Based on the Base 64 VLQ implementation in Closure Compiler:\n * https://code.google.com/p/closure-compiler/source/browse/trunk/src/com/google/debugging/sourcemap/Base64VLQ.java\n *\n * Copyright 2011 The Closure Compiler Authors. All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above\n *    copyright notice, this list of conditions and the following\n *    disclaimer in the documentation and/or other materials provided\n *    with the distribution.\n *  * Neither the name of Google Inc. nor the names of its\n *    contributors may be used to endorse or promote products derived\n *    from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\nvar base64 = require('./base64');\n\n// A single base 64 digit can contain 6 bits of data. For the base 64 variable\n// length quantities we use in the source map spec, the first bit is the sign,\n// the next four bits are the actual value, and the 6th bit is the\n// continuation bit. The continuation bit tells us whether there are more\n// digits in this value following this digit.\n//\n//   Continuation\n//   |    Sign\n//   |    |\n//   V    V\n//   101011\n\nvar VLQ_BASE_SHIFT = 5;\n\n// binary: 100000\nvar VLQ_BASE = 1 << VLQ_BASE_SHIFT;\n\n// binary: 011111\nvar VLQ_BASE_MASK = VLQ_BASE - 1;\n\n// binary: 100000\nvar VLQ_CONTINUATION_BIT = VLQ_BASE;\n\n/**\n * Converts from a two-complement value to a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   1 becomes 2 (10 binary), -1 becomes 3 (11 binary)\n *   2 becomes 4 (100 binary), -2 becomes 5 (101 binary)\n */\nfunction toVLQSigned(aValue) {\n  return aValue < 0\n    ? ((-aValue) << 1) + 1\n    : (aValue << 1) + 0;\n}\n\n/**\n * Converts to a two-complement value from a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   2 (10 binary) becomes 1, 3 (11 binary) becomes -1\n *   4 (100 binary) becomes 2, 5 (101 binary) becomes -2\n */\nfunction fromVLQSigned(aValue) {\n  var isNegative = (aValue & 1) === 1;\n  var shifted = aValue >> 1;\n  return isNegative\n    ? -shifted\n    : shifted;\n}\n\n/**\n * Returns the base 64 VLQ encoded value.\n */\nexports.encode = function base64VLQ_encode(aValue) {\n  var encoded = \"\";\n  var digit;\n\n  var vlq = toVLQSigned(aValue);\n\n  do {\n    digit = vlq & VLQ_BASE_MASK;\n    vlq >>>= VLQ_BASE_SHIFT;\n    if (vlq > 0) {\n      // There are still more digits in this value, so we must make sure the\n      // continuation bit is marked.\n      digit |= VLQ_CONTINUATION_BIT;\n    }\n    encoded += base64.encode(digit);\n  } while (vlq > 0);\n\n  return encoded;\n};\n\n/**\n * Decodes the next base 64 VLQ value from the given string and returns the\n * value and the rest of the string via the out parameter.\n */\nexports.decode = function base64VLQ_decode(aStr, aIndex, aOutParam) {\n  var strLen = aStr.length;\n  var result = 0;\n  var shift = 0;\n  var continuation, digit;\n\n  do {\n    if (aIndex >= strLen) {\n      throw new Error(\"Expected more digits in base 64 VLQ value.\");\n    }\n\n    digit = base64.decode(aStr.charCodeAt(aIndex++));\n    if (digit === -1) {\n      throw new Error(\"Invalid base64 digit: \" + aStr.charAt(aIndex - 1));\n    }\n\n    continuation = !!(digit & VLQ_CONTINUATION_BIT);\n    digit &= VLQ_BASE_MASK;\n    result = result + (digit << shift);\n    shift += VLQ_BASE_SHIFT;\n  } while (continuation);\n\n  aOutParam.value = fromVLQSigned(result);\n  aOutParam.rest = aIndex;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar intToCharMap = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');\n\n/**\n * Encode an integer in the range of 0 to 63 to a single base 64 digit.\n */\nexports.encode = function (number) {\n  if (0 <= number && number < intToCharMap.length) {\n    return intToCharMap[number];\n  }\n  throw new TypeError(\"Must be between 0 and 63: \" + number);\n};\n\n/**\n * Decode a single base 64 character code digit to an integer. Returns -1 on\n * failure.\n */\nexports.decode = function (charCode) {\n  var bigA = 65;     // 'A'\n  var bigZ = 90;     // 'Z'\n\n  var littleA = 97;  // 'a'\n  var littleZ = 122; // 'z'\n\n  var zero = 48;     // '0'\n  var nine = 57;     // '9'\n\n  var plus = 43;     // '+'\n  var slash = 47;    // '/'\n\n  var littleOffset = 26;\n  var numberOffset = 52;\n\n  // 0 - 25: ABCDEFGHIJKLMNOPQRSTUVWXYZ\n  if (bigA <= charCode && charCode <= bigZ) {\n    return (charCode - bigA);\n  }\n\n  // 26 - 51: abcdefghijklmnopqrstuvwxyz\n  if (littleA <= charCode && charCode <= littleZ) {\n    return (charCode - littleA + littleOffset);\n  }\n\n  // 52 - 61: 0123456789\n  if (zero <= charCode && charCode <= nine) {\n    return (charCode - zero + numberOffset);\n  }\n\n  // 62: +\n  if (charCode == plus) {\n    return 62;\n  }\n\n  // 63: /\n  if (charCode == slash) {\n    return 63;\n  }\n\n  // Invalid base64 digit.\n  return -1;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nexports.GREATEST_LOWER_BOUND = 1;\nexports.LEAST_UPPER_BOUND = 2;\n\n/**\n * Recursive implementation of binary search.\n *\n * @param aLow Indices here and lower do not contain the needle.\n * @param aHigh Indices here and higher do not contain the needle.\n * @param aNeedle The element being searched for.\n * @param aHaystack The non-empty array being searched.\n * @param aCompare Function which takes two elements and returns -1, 0, or 1.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n */\nfunction recursiveSearch(aLow, aHigh, aNeedle, aHaystack, aCompare, aBias) {\n  // This function terminates when one of the following is true:\n  //\n  //   1. We find the exact element we are looking for.\n  //\n  //   2. We did not find the exact element, but we can return the index of\n  //      the next-closest element.\n  //\n  //   3. We did not find the exact element, and there is no next-closest\n  //      element than the one we are searching for, so we return -1.\n  var mid = Math.floor((aHigh - aLow) / 2) + aLow;\n  var cmp = aCompare(aNeedle, aHaystack[mid], true);\n  if (cmp === 0) {\n    // Found the element we are looking for.\n    return mid;\n  }\n  else if (cmp > 0) {\n    // Our needle is greater than aHaystack[mid].\n    if (aHigh - mid > 1) {\n      // The element is in the upper half.\n      return recursiveSearch(mid, aHigh, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // The exact needle element was not found in this haystack. Determine if\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return aHigh < aHaystack.length ? aHigh : -1;\n    } else {\n      return mid;\n    }\n  }\n  else {\n    // Our needle is less than aHaystack[mid].\n    if (mid - aLow > 1) {\n      // The element is in the lower half.\n      return recursiveSearch(aLow, mid, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return mid;\n    } else {\n      return aLow < 0 ? -1 : aLow;\n    }\n  }\n}\n\n/**\n * This is an implementation of binary search which will always try and return\n * the index of the closest element if there is no exact hit. This is because\n * mappings between original and generated line/col pairs are single points,\n * and there is an implicit region between each of them, so a miss just means\n * that you aren't on the very start of a region.\n *\n * @param aNeedle The element you are looking for.\n * @param aHaystack The array that is being searched.\n * @param aCompare A function which takes the needle and an element in the\n *     array and returns -1, 0, or 1 depending on whether the needle is less\n *     than, equal to, or greater than the element, respectively.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'binarySearch.GREATEST_LOWER_BOUND'.\n */\nexports.search = function search(aNeedle, aHaystack, aCompare, aBias) {\n  if (aHaystack.length === 0) {\n    return -1;\n  }\n\n  var index = recursiveSearch(-1, aHaystack.length, aNeedle, aHaystack,\n                              aCompare, aBias || exports.GREATEST_LOWER_BOUND);\n  if (index < 0) {\n    return -1;\n  }\n\n  // We have found either the exact element, or the next-closest element than\n  // the one we are searching for. However, there may be more than one such\n  // element. Make sure we always return the smallest of these.\n  while (index - 1 >= 0) {\n    if (aCompare(aHaystack[index], aHaystack[index - 1], true) !== 0) {\n      break;\n    }\n    --index;\n  }\n\n  return index;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2014 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\n\n/**\n * Determine whether mappingB is after mappingA with respect to generated\n * position.\n */\nfunction generatedPositionAfter(mappingA, mappingB) {\n  // Optimized for most common case\n  var lineA = mappingA.generatedLine;\n  var lineB = mappingB.generatedLine;\n  var columnA = mappingA.generatedColumn;\n  var columnB = mappingB.generatedColumn;\n  return lineB > lineA || lineB == lineA && columnB >= columnA ||\n         util.compareByGeneratedPositionsInflated(mappingA, mappingB) <= 0;\n}\n\n/**\n * A data structure to provide a sorted view of accumulated mappings in a\n * performance conscious manner. It trades a neglibable overhead in general\n * case for a large speedup in case of mappings being added in order.\n */\nfunction MappingList() {\n  this._array = [];\n  this._sorted = true;\n  // Serves as infimum\n  this._last = {generatedLine: -1, generatedColumn: 0};\n}\n\n/**\n * Iterate through internal items. This method takes the same arguments that\n * `Array.prototype.forEach` takes.\n *\n * NOTE: The order of the mappings is NOT guaranteed.\n */\nMappingList.prototype.unsortedForEach =\n  function MappingList_forEach(aCallback, aThisArg) {\n    this._array.forEach(aCallback, aThisArg);\n  };\n\n/**\n * Add the given source mapping.\n *\n * @param Object aMapping\n */\nMappingList.prototype.add = function MappingList_add(aMapping) {\n  if (generatedPositionAfter(this._last, aMapping)) {\n    this._last = aMapping;\n    this._array.push(aMapping);\n  } else {\n    this._sorted = false;\n    this._array.push(aMapping);\n  }\n};\n\n/**\n * Returns the flat, sorted array of mappings. The mappings are sorted by\n * generated position.\n *\n * WARNING: This method returns internal data without copying, for\n * performance. The return value must NOT be mutated, and should be treated as\n * an immutable borrow. If you want to take ownership, you must make your own\n * copy.\n */\nMappingList.prototype.toArray = function MappingList_toArray() {\n  if (!this._sorted) {\n    this._array.sort(util.compareByGeneratedPositionsInflated);\n    this._sorted = true;\n  }\n  return this._array;\n};\n\nexports.MappingList = MappingList;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n// It turns out that some (most?) JavaScript engines don't self-host\n// `Array.prototype.sort`. This makes sense because C++ will likely remain\n// faster than JS when doing raw CPU-intensive sorting. However, when using a\n// custom comparator function, calling back and forth between the VM's C++ and\n// JIT'd JS is rather slow *and* loses JIT type information, resulting in\n// worse generated code for the comparator function than would be optimal. In\n// fact, when sorting with a comparator, these costs outweigh the benefits of\n// sorting in C++. By using our own JS-implemented Quick Sort (below), we get\n// a ~3500ms mean speed-up in `bench/bench.html`.\n\n/**\n * Swap the elements indexed by `x` and `y` in the array `ary`.\n *\n * @param {Array} ary\n *        The array.\n * @param {Number} x\n *        The index of the first item.\n * @param {Number} y\n *        The index of the second item.\n */\nfunction swap(ary, x, y) {\n  var temp = ary[x];\n  ary[x] = ary[y];\n  ary[y] = temp;\n}\n\n/**\n * Returns a random integer within the range `low .. high` inclusive.\n *\n * @param {Number} low\n *        The lower bound on the range.\n * @param {Number} high\n *        The upper bound on the range.\n */\nfunction randomIntInRange(low, high) {\n  return Math.round(low + (Math.random() * (high - low)));\n}\n\n/**\n * The Quick Sort algorithm.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n * @param {Number} p\n *        Start index of the array\n * @param {Number} r\n *        End index of the array\n */\nfunction doQuickSort(ary, comparator, p, r) {\n  // If our lower bound is less than our upper bound, we (1) partition the\n  // array into two pieces and (2) recurse on each half. If it is not, this is\n  // the empty array and our base case.\n\n  if (p < r) {\n    // (1) Partitioning.\n    //\n    // The partitioning chooses a pivot between `p` and `r` and moves all\n    // elements that are less than or equal to the pivot to the before it, and\n    // all the elements that are greater than it after it. The effect is that\n    // once partition is done, the pivot is in the exact place it will be when\n    // the array is put in sorted order, and it will not need to be moved\n    // again. This runs in O(n) time.\n\n    // Always choose a random pivot so that an input array which is reverse\n    // sorted does not cause O(n^2) running time.\n    var pivotIndex = randomIntInRange(p, r);\n    var i = p - 1;\n\n    swap(ary, pivotIndex, r);\n    var pivot = ary[r];\n\n    // Immediately after `j` is incremented in this loop, the following hold\n    // true:\n    //\n    //   * Every element in `ary[p .. i]` is less than or equal to the pivot.\n    //\n    //   * Every element in `ary[i+1 .. j-1]` is greater than the pivot.\n    for (var j = p; j < r; j++) {\n      if (comparator(ary[j], pivot) <= 0) {\n        i += 1;\n        swap(ary, i, j);\n      }\n    }\n\n    swap(ary, i + 1, j);\n    var q = i + 1;\n\n    // (2) Recurse on each half.\n\n    doQuickSort(ary, comparator, p, q - 1);\n    doQuickSort(ary, comparator, q + 1, r);\n  }\n}\n\n/**\n * Sort the given array in-place with the given comparator function.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n */\nexports.quickSort = function (ary, comparator) {\n  doQuickSort(ary, comparator, 0, ary.length - 1);\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar binarySearch = require('./binary-search');\nvar ArraySet = require('./array-set').ArraySet;\nvar base64VLQ = require('./base64-vlq');\nvar quickSort = require('./quick-sort').quickSort;\n\nfunction SourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  return sourceMap.sections != null\n    ? new IndexedSourceMapConsumer(sourceMap)\n    : new BasicSourceMapConsumer(sourceMap);\n}\n\nSourceMapConsumer.fromSourceMap = function(aSourceMap) {\n  return BasicSourceMapConsumer.fromSourceMap(aSourceMap);\n}\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nSourceMapConsumer.prototype._version = 3;\n\n// `__generatedMappings` and `__originalMappings` are arrays that hold the\n// parsed mapping coordinates from the source map's \"mappings\" attribute. They\n// are lazily instantiated, accessed via the `_generatedMappings` and\n// `_originalMappings` getters respectively, and we only parse the mappings\n// and create these arrays once queried for a source location. We jump through\n// these hoops because there can be many thousands of mappings, and parsing\n// them is expensive, so we only want to do it if we must.\n//\n// Each object in the arrays is of the form:\n//\n//     {\n//       generatedLine: The line number in the generated code,\n//       generatedColumn: The column number in the generated code,\n//       source: The path to the original source file that generated this\n//               chunk of code,\n//       originalLine: The line number in the original source that\n//                     corresponds to this chunk of generated code,\n//       originalColumn: The column number in the original source that\n//                       corresponds to this chunk of generated code,\n//       name: The name of the original symbol which generated this chunk of\n//             code.\n//     }\n//\n// All properties except for `generatedLine` and `generatedColumn` can be\n// `null`.\n//\n// `_generatedMappings` is ordered by the generated positions.\n//\n// `_originalMappings` is ordered by the original positions.\n\nSourceMapConsumer.prototype.__generatedMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_generatedMappings', {\n  get: function () {\n    if (!this.__generatedMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__generatedMappings;\n  }\n});\n\nSourceMapConsumer.prototype.__originalMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_originalMappings', {\n  get: function () {\n    if (!this.__originalMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__originalMappings;\n  }\n});\n\nSourceMapConsumer.prototype._charIsMappingSeparator =\n  function SourceMapConsumer_charIsMappingSeparator(aStr, index) {\n    var c = aStr.charAt(index);\n    return c === \";\" || c === \",\";\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    throw new Error(\"Subclasses must implement _parseMappings\");\n  };\n\nSourceMapConsumer.GENERATED_ORDER = 1;\nSourceMapConsumer.ORIGINAL_ORDER = 2;\n\nSourceMapConsumer.GREATEST_LOWER_BOUND = 1;\nSourceMapConsumer.LEAST_UPPER_BOUND = 2;\n\n/**\n * Iterate over each mapping between an original source/line/column and a\n * generated line/column in this source map.\n *\n * @param Function aCallback\n *        The function that is called with each mapping.\n * @param Object aContext\n *        Optional. If specified, this object will be the value of `this` every\n *        time that `aCallback` is called.\n * @param aOrder\n *        Either `SourceMapConsumer.GENERATED_ORDER` or\n *        `SourceMapConsumer.ORIGINAL_ORDER`. Specifies whether you want to\n *        iterate over the mappings sorted by the generated file's line/column\n *        order or the original's source/line/column order, respectively. Defaults to\n *        `SourceMapConsumer.GENERATED_ORDER`.\n */\nSourceMapConsumer.prototype.eachMapping =\n  function SourceMapConsumer_eachMapping(aCallback, aContext, aOrder) {\n    var context = aContext || null;\n    var order = aOrder || SourceMapConsumer.GENERATED_ORDER;\n\n    var mappings;\n    switch (order) {\n    case SourceMapConsumer.GENERATED_ORDER:\n      mappings = this._generatedMappings;\n      break;\n    case SourceMapConsumer.ORIGINAL_ORDER:\n      mappings = this._originalMappings;\n      break;\n    default:\n      throw new Error(\"Unknown order of iteration.\");\n    }\n\n    var sourceRoot = this.sourceRoot;\n    mappings.map(function (mapping) {\n      var source = mapping.source === null ? null : this._sources.at(mapping.source);\n      if (source != null && sourceRoot != null) {\n        source = util.join(sourceRoot, source);\n      }\n      return {\n        source: source,\n        generatedLine: mapping.generatedLine,\n        generatedColumn: mapping.generatedColumn,\n        originalLine: mapping.originalLine,\n        originalColumn: mapping.originalColumn,\n        name: mapping.name === null ? null : this._names.at(mapping.name)\n      };\n    }, this).forEach(aCallback, context);\n  };\n\n/**\n * Returns all generated line and column information for the original source,\n * line, and column provided. If no column is provided, returns all mappings\n * corresponding to a either the line we are searching for or the next\n * closest line that has any mappings. Otherwise, returns all mappings\n * corresponding to the given line and either the column we are searching for\n * or the next closest column that has any offsets.\n *\n * The only argument is an object with the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: Optional. the column number in the original source.\n *\n * and an array of objects is returned, each with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nSourceMapConsumer.prototype.allGeneratedPositionsFor =\n  function SourceMapConsumer_allGeneratedPositionsFor(aArgs) {\n    var line = util.getArg(aArgs, 'line');\n\n    // When there is no exact match, BasicSourceMapConsumer.prototype._findMapping\n    // returns the index of the closest mapping less than the needle. By\n    // setting needle.originalColumn to 0, we thus find the last mapping for\n    // the given line, provided such a mapping exists.\n    var needle = {\n      source: util.getArg(aArgs, 'source'),\n      originalLine: line,\n      originalColumn: util.getArg(aArgs, 'column', 0)\n    };\n\n    if (this.sourceRoot != null) {\n      needle.source = util.relative(this.sourceRoot, needle.source);\n    }\n    if (!this._sources.has(needle.source)) {\n      return [];\n    }\n    needle.source = this._sources.indexOf(needle.source);\n\n    var mappings = [];\n\n    var index = this._findMapping(needle,\n                                  this._originalMappings,\n                                  \"originalLine\",\n                                  \"originalColumn\",\n                                  util.compareByOriginalPositions,\n                                  binarySearch.LEAST_UPPER_BOUND);\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (aArgs.column === undefined) {\n        var originalLine = mapping.originalLine;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we found. Since\n        // mappings are sorted, this is guaranteed to find all mappings for\n        // the line we found.\n        while (mapping && mapping.originalLine === originalLine) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      } else {\n        var originalColumn = mapping.originalColumn;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we were searching for.\n        // Since mappings are sorted, this is guaranteed to find all mappings for\n        // the line we are searching for.\n        while (mapping &&\n               mapping.originalLine === line &&\n               mapping.originalColumn == originalColumn) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      }\n    }\n\n    return mappings;\n  };\n\nexports.SourceMapConsumer = SourceMapConsumer;\n\n/**\n * A BasicSourceMapConsumer instance represents a parsed source map which we can\n * query for information about the original file positions by giving it a file\n * position in the generated source.\n *\n * The only parameter is the raw source map (either as a JSON string, or\n * already parsed to an object). According to the spec, source maps have the\n * following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - sources: An array of URLs to the original source files.\n *   - names: An array of identifiers which can be referrenced by individual mappings.\n *   - sourceRoot: Optional. The URL root from which all sources are relative.\n *   - sourcesContent: Optional. An array of contents of the original source files.\n *   - mappings: A string of base64 VLQs which contain the actual mappings.\n *   - file: Optional. The generated file this source map is associated with.\n *\n * Here is an example source map, taken from the source map spec[0]:\n *\n *     {\n *       version : 3,\n *       file: \"out.js\",\n *       sourceRoot : \"\",\n *       sources: [\"foo.js\", \"bar.js\"],\n *       names: [\"src\", \"maps\", \"are\", \"fun\"],\n *       mappings: \"AA,AB;;ABCDE;\"\n *     }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?pli=1#\n */\nfunction BasicSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sources = util.getArg(sourceMap, 'sources');\n  // Sass 3.3 leaves out the 'names' array, so we deviate from the spec (which\n  // requires the array) to play nice here.\n  var names = util.getArg(sourceMap, 'names', []);\n  var sourceRoot = util.getArg(sourceMap, 'sourceRoot', null);\n  var sourcesContent = util.getArg(sourceMap, 'sourcesContent', null);\n  var mappings = util.getArg(sourceMap, 'mappings');\n  var file = util.getArg(sourceMap, 'file', null);\n\n  // Once again, Sass deviates from the spec and supplies the version as a\n  // string rather than a number, so we use loose equality checking here.\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  sources = sources\n    .map(String)\n    // Some source maps produce relative source paths like \"./foo.js\" instead of\n    // \"foo.js\".  Normalize these first so that future comparisons will succeed.\n    // See bugzil.la/1090768.\n    .map(util.normalize)\n    // Always ensure that absolute sources are internally stored relative to\n    // the source root, if the source root is absolute. Not doing this would\n    // be particularly problematic when the source root is a prefix of the\n    // source (valid, but why??). See github issue #199 and bugzil.la/1188982.\n    .map(function (source) {\n      return sourceRoot && util.isAbsolute(sourceRoot) && util.isAbsolute(source)\n        ? util.relative(sourceRoot, source)\n        : source;\n    });\n\n  // Pass `true` below to allow duplicate names and sources. While source maps\n  // are intended to be compressed and deduplicated, the TypeScript compiler\n  // sometimes generates source maps with duplicates in them. See Github issue\n  // #72 and bugzil.la/889492.\n  this._names = ArraySet.fromArray(names.map(String), true);\n  this._sources = ArraySet.fromArray(sources, true);\n\n  this.sourceRoot = sourceRoot;\n  this.sourcesContent = sourcesContent;\n  this._mappings = mappings;\n  this.file = file;\n}\n\nBasicSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nBasicSourceMapConsumer.prototype.consumer = SourceMapConsumer;\n\n/**\n * Create a BasicSourceMapConsumer from a SourceMapGenerator.\n *\n * @param SourceMapGenerator aSourceMap\n *        The source map that will be consumed.\n * @returns BasicSourceMapConsumer\n */\nBasicSourceMapConsumer.fromSourceMap =\n  function SourceMapConsumer_fromSourceMap(aSourceMap) {\n    var smc = Object.create(BasicSourceMapConsumer.prototype);\n\n    var names = smc._names = ArraySet.fromArray(aSourceMap._names.toArray(), true);\n    var sources = smc._sources = ArraySet.fromArray(aSourceMap._sources.toArray(), true);\n    smc.sourceRoot = aSourceMap._sourceRoot;\n    smc.sourcesContent = aSourceMap._generateSourcesContent(smc._sources.toArray(),\n                                                            smc.sourceRoot);\n    smc.file = aSourceMap._file;\n\n    // Because we are modifying the entries (by converting string sources and\n    // names to indices into the sources and names ArraySets), we have to make\n    // a copy of the entry or else bad things happen. Shared mutable state\n    // strikes again! See github issue #191.\n\n    var generatedMappings = aSourceMap._mappings.toArray().slice();\n    var destGeneratedMappings = smc.__generatedMappings = [];\n    var destOriginalMappings = smc.__originalMappings = [];\n\n    for (var i = 0, length = generatedMappings.length; i < length; i++) {\n      var srcMapping = generatedMappings[i];\n      var destMapping = new Mapping;\n      destMapping.generatedLine = srcMapping.generatedLine;\n      destMapping.generatedColumn = srcMapping.generatedColumn;\n\n      if (srcMapping.source) {\n        destMapping.source = sources.indexOf(srcMapping.source);\n        destMapping.originalLine = srcMapping.originalLine;\n        destMapping.originalColumn = srcMapping.originalColumn;\n\n        if (srcMapping.name) {\n          destMapping.name = names.indexOf(srcMapping.name);\n        }\n\n        destOriginalMappings.push(destMapping);\n      }\n\n      destGeneratedMappings.push(destMapping);\n    }\n\n    quickSort(smc.__originalMappings, util.compareByOriginalPositions);\n\n    return smc;\n  };\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nBasicSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(BasicSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    return this._sources.toArray().map(function (s) {\n      return this.sourceRoot != null ? util.join(this.sourceRoot, s) : s;\n    }, this);\n  }\n});\n\n/**\n * Provide the JIT with a nice shape / hidden class.\n */\nfunction Mapping() {\n  this.generatedLine = 0;\n  this.generatedColumn = 0;\n  this.source = null;\n  this.originalLine = null;\n  this.originalColumn = null;\n  this.name = null;\n}\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nBasicSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    var generatedLine = 1;\n    var previousGeneratedColumn = 0;\n    var previousOriginalLine = 0;\n    var previousOriginalColumn = 0;\n    var previousSource = 0;\n    var previousName = 0;\n    var length = aStr.length;\n    var index = 0;\n    var cachedSegments = {};\n    var temp = {};\n    var originalMappings = [];\n    var generatedMappings = [];\n    var mapping, str, segment, end, value;\n\n    while (index < length) {\n      if (aStr.charAt(index) === ';') {\n        generatedLine++;\n        index++;\n        previousGeneratedColumn = 0;\n      }\n      else if (aStr.charAt(index) === ',') {\n        index++;\n      }\n      else {\n        mapping = new Mapping();\n        mapping.generatedLine = generatedLine;\n\n        // Because each offset is encoded relative to the previous one,\n        // many segments often have the same encoding. We can exploit this\n        // fact by caching the parsed variable length fields of each segment,\n        // allowing us to avoid a second parse if we encounter the same\n        // segment again.\n        for (end = index; end < length; end++) {\n          if (this._charIsMappingSeparator(aStr, end)) {\n            break;\n          }\n        }\n        str = aStr.slice(index, end);\n\n        segment = cachedSegments[str];\n        if (segment) {\n          index += str.length;\n        } else {\n          segment = [];\n          while (index < end) {\n            base64VLQ.decode(aStr, index, temp);\n            value = temp.value;\n            index = temp.rest;\n            segment.push(value);\n          }\n\n          if (segment.length === 2) {\n            throw new Error('Found a source, but no line and column');\n          }\n\n          if (segment.length === 3) {\n            throw new Error('Found a source and line, but no column');\n          }\n\n          cachedSegments[str] = segment;\n        }\n\n        // Generated column.\n        mapping.generatedColumn = previousGeneratedColumn + segment[0];\n        previousGeneratedColumn = mapping.generatedColumn;\n\n        if (segment.length > 1) {\n          // Original source.\n          mapping.source = previousSource + segment[1];\n          previousSource += segment[1];\n\n          // Original line.\n          mapping.originalLine = previousOriginalLine + segment[2];\n          previousOriginalLine = mapping.originalLine;\n          // Lines are stored 0-based\n          mapping.originalLine += 1;\n\n          // Original column.\n          mapping.originalColumn = previousOriginalColumn + segment[3];\n          previousOriginalColumn = mapping.originalColumn;\n\n          if (segment.length > 4) {\n            // Original name.\n            mapping.name = previousName + segment[4];\n            previousName += segment[4];\n          }\n        }\n\n        generatedMappings.push(mapping);\n        if (typeof mapping.originalLine === 'number') {\n          originalMappings.push(mapping);\n        }\n      }\n    }\n\n    quickSort(generatedMappings, util.compareByGeneratedPositionsDeflated);\n    this.__generatedMappings = generatedMappings;\n\n    quickSort(originalMappings, util.compareByOriginalPositions);\n    this.__originalMappings = originalMappings;\n  };\n\n/**\n * Find the mapping that best matches the hypothetical \"needle\" mapping that\n * we are searching for in the given \"haystack\" of mappings.\n */\nBasicSourceMapConsumer.prototype._findMapping =\n  function SourceMapConsumer_findMapping(aNeedle, aMappings, aLineName,\n                                         aColumnName, aComparator, aBias) {\n    // To return the position we are searching for, we must first find the\n    // mapping for the given position and then return the opposite position it\n    // points to. Because the mappings are sorted, we can use binary search to\n    // find the best mapping.\n\n    if (aNeedle[aLineName] <= 0) {\n      throw new TypeError('Line must be greater than or equal to 1, got '\n                          + aNeedle[aLineName]);\n    }\n    if (aNeedle[aColumnName] < 0) {\n      throw new TypeError('Column must be greater than or equal to 0, got '\n                          + aNeedle[aColumnName]);\n    }\n\n    return binarySearch.search(aNeedle, aMappings, aComparator, aBias);\n  };\n\n/**\n * Compute the last column for each generated mapping. The last column is\n * inclusive.\n */\nBasicSourceMapConsumer.prototype.computeColumnSpans =\n  function SourceMapConsumer_computeColumnSpans() {\n    for (var index = 0; index < this._generatedMappings.length; ++index) {\n      var mapping = this._generatedMappings[index];\n\n      // Mappings do not contain a field for the last generated columnt. We\n      // can come up with an optimistic estimate, however, by assuming that\n      // mappings are contiguous (i.e. given two consecutive mappings, the\n      // first mapping ends where the second one starts).\n      if (index + 1 < this._generatedMappings.length) {\n        var nextMapping = this._generatedMappings[index + 1];\n\n        if (mapping.generatedLine === nextMapping.generatedLine) {\n          mapping.lastGeneratedColumn = nextMapping.generatedColumn - 1;\n          continue;\n        }\n      }\n\n      // The last mapping for each line spans the entire line.\n      mapping.lastGeneratedColumn = Infinity;\n    }\n  };\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nBasicSourceMapConsumer.prototype.originalPositionFor =\n  function SourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._generatedMappings,\n      \"generatedLine\",\n      \"generatedColumn\",\n      util.compareByGeneratedPositionsDeflated,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._generatedMappings[index];\n\n      if (mapping.generatedLine === needle.generatedLine) {\n        var source = util.getArg(mapping, 'source', null);\n        if (source !== null) {\n          source = this._sources.at(source);\n          if (this.sourceRoot != null) {\n            source = util.join(this.sourceRoot, source);\n          }\n        }\n        var name = util.getArg(mapping, 'name', null);\n        if (name !== null) {\n          name = this._names.at(name);\n        }\n        return {\n          source: source,\n          line: util.getArg(mapping, 'originalLine', null),\n          column: util.getArg(mapping, 'originalColumn', null),\n          name: name\n        };\n      }\n    }\n\n    return {\n      source: null,\n      line: null,\n      column: null,\n      name: null\n    };\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nBasicSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function BasicSourceMapConsumer_hasContentsOfAllSources() {\n    if (!this.sourcesContent) {\n      return false;\n    }\n    return this.sourcesContent.length >= this._sources.size() &&\n      !this.sourcesContent.some(function (sc) { return sc == null; });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nBasicSourceMapConsumer.prototype.sourceContentFor =\n  function SourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    if (!this.sourcesContent) {\n      return null;\n    }\n\n    if (this.sourceRoot != null) {\n      aSource = util.relative(this.sourceRoot, aSource);\n    }\n\n    if (this._sources.has(aSource)) {\n      return this.sourcesContent[this._sources.indexOf(aSource)];\n    }\n\n    var url;\n    if (this.sourceRoot != null\n        && (url = util.urlParse(this.sourceRoot))) {\n      // XXX: file:// URIs and absolute paths lead to unexpected behavior for\n      // many users. We can help them out when they expect file:// URIs to\n      // behave like it would if they were running a local HTTP server. See\n      // https://bugzilla.mozilla.org/show_bug.cgi?id=885597.\n      var fileUriAbsPath = aSource.replace(/^file:\\/\\//, \"\");\n      if (url.scheme == \"file\"\n          && this._sources.has(fileUriAbsPath)) {\n        return this.sourcesContent[this._sources.indexOf(fileUriAbsPath)]\n      }\n\n      if ((!url.path || url.path == \"/\")\n          && this._sources.has(\"/\" + aSource)) {\n        return this.sourcesContent[this._sources.indexOf(\"/\" + aSource)];\n      }\n    }\n\n    // This function is used recursively from\n    // IndexedSourceMapConsumer.prototype.sourceContentFor. In that case, we\n    // don't want to throw if we can't find the source - we just want to\n    // return null, so we provide a flag to exit gracefully.\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nBasicSourceMapConsumer.prototype.generatedPositionFor =\n  function SourceMapConsumer_generatedPositionFor(aArgs) {\n    var source = util.getArg(aArgs, 'source');\n    if (this.sourceRoot != null) {\n      source = util.relative(this.sourceRoot, source);\n    }\n    if (!this._sources.has(source)) {\n      return {\n        line: null,\n        column: null,\n        lastColumn: null\n      };\n    }\n    source = this._sources.indexOf(source);\n\n    var needle = {\n      source: source,\n      originalLine: util.getArg(aArgs, 'line'),\n      originalColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._originalMappings,\n      \"originalLine\",\n      \"originalColumn\",\n      util.compareByOriginalPositions,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (mapping.source === needle.source) {\n        return {\n          line: util.getArg(mapping, 'generatedLine', null),\n          column: util.getArg(mapping, 'generatedColumn', null),\n          lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n        };\n      }\n    }\n\n    return {\n      line: null,\n      column: null,\n      lastColumn: null\n    };\n  };\n\nexports.BasicSourceMapConsumer = BasicSourceMapConsumer;\n\n/**\n * An IndexedSourceMapConsumer instance represents a parsed source map which\n * we can query for information. It differs from BasicSourceMapConsumer in\n * that it takes \"indexed\" source maps (i.e. ones with a \"sections\" field) as\n * input.\n *\n * The only parameter is a raw source map (either as a JSON string, or already\n * parsed to an object). According to the spec for indexed source maps, they\n * have the following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - file: Optional. The generated file this source map is associated with.\n *   - sections: A list of section definitions.\n *\n * Each value under the \"sections\" field has two fields:\n *   - offset: The offset into the original specified at which this section\n *       begins to apply, defined as an object with a \"line\" and \"column\"\n *       field.\n *   - map: A source map definition. This source map could also be indexed,\n *       but doesn't have to be.\n *\n * Instead of the \"map\" field, it's also possible to have a \"url\" field\n * specifying a URL to retrieve a source map from, but that's currently\n * unsupported.\n *\n * Here's an example source map, taken from the source map spec[0], but\n * modified to omit a section which uses the \"url\" field.\n *\n *  {\n *    version : 3,\n *    file: \"app.js\",\n *    sections: [{\n *      offset: {line:100, column:10},\n *      map: {\n *        version : 3,\n *        file: \"section.js\",\n *        sources: [\"foo.js\", \"bar.js\"],\n *        names: [\"src\", \"maps\", \"are\", \"fun\"],\n *        mappings: \"AAAA,E;;ABCDE;\"\n *      }\n *    }],\n *  }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.535es3xeprgt\n */\nfunction IndexedSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sections = util.getArg(sourceMap, 'sections');\n\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n\n  var lastOffset = {\n    line: -1,\n    column: 0\n  };\n  this._sections = sections.map(function (s) {\n    if (s.url) {\n      // The url field will require support for asynchronicity.\n      // See https://github.com/mozilla/source-map/issues/16\n      throw new Error('Support for url field in sections not implemented.');\n    }\n    var offset = util.getArg(s, 'offset');\n    var offsetLine = util.getArg(offset, 'line');\n    var offsetColumn = util.getArg(offset, 'column');\n\n    if (offsetLine < lastOffset.line ||\n        (offsetLine === lastOffset.line && offsetColumn < lastOffset.column)) {\n      throw new Error('Section offsets must be ordered and non-overlapping.');\n    }\n    lastOffset = offset;\n\n    return {\n      generatedOffset: {\n        // The offset fields are 0-based, but we use 1-based indices when\n        // encoding/decoding from VLQ.\n        generatedLine: offsetLine + 1,\n        generatedColumn: offsetColumn + 1\n      },\n      consumer: new SourceMapConsumer(util.getArg(s, 'map'))\n    }\n  });\n}\n\nIndexedSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nIndexedSourceMapConsumer.prototype.constructor = SourceMapConsumer;\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nIndexedSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(IndexedSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    var sources = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      for (var j = 0; j < this._sections[i].consumer.sources.length; j++) {\n        sources.push(this._sections[i].consumer.sources[j]);\n      }\n    }\n    return sources;\n  }\n});\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nIndexedSourceMapConsumer.prototype.originalPositionFor =\n  function IndexedSourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    // Find the section containing the generated position we're trying to map\n    // to an original position.\n    var sectionIndex = binarySearch.search(needle, this._sections,\n      function(needle, section) {\n        var cmp = needle.generatedLine - section.generatedOffset.generatedLine;\n        if (cmp) {\n          return cmp;\n        }\n\n        return (needle.generatedColumn -\n                section.generatedOffset.generatedColumn);\n      });\n    var section = this._sections[sectionIndex];\n\n    if (!section) {\n      return {\n        source: null,\n        line: null,\n        column: null,\n        name: null\n      };\n    }\n\n    return section.consumer.originalPositionFor({\n      line: needle.generatedLine -\n        (section.generatedOffset.generatedLine - 1),\n      column: needle.generatedColumn -\n        (section.generatedOffset.generatedLine === needle.generatedLine\n         ? section.generatedOffset.generatedColumn - 1\n         : 0),\n      bias: aArgs.bias\n    });\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nIndexedSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function IndexedSourceMapConsumer_hasContentsOfAllSources() {\n    return this._sections.every(function (s) {\n      return s.consumer.hasContentsOfAllSources();\n    });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nIndexedSourceMapConsumer.prototype.sourceContentFor =\n  function IndexedSourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      var content = section.consumer.sourceContentFor(aSource, true);\n      if (content) {\n        return content;\n      }\n    }\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nIndexedSourceMapConsumer.prototype.generatedPositionFor =\n  function IndexedSourceMapConsumer_generatedPositionFor(aArgs) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      // Only consider this section if the requested source is in the list of\n      // sources of the consumer.\n      if (section.consumer.sources.indexOf(util.getArg(aArgs, 'source')) === -1) {\n        continue;\n      }\n      var generatedPosition = section.consumer.generatedPositionFor(aArgs);\n      if (generatedPosition) {\n        var ret = {\n          line: generatedPosition.line +\n            (section.generatedOffset.generatedLine - 1),\n          column: generatedPosition.column +\n            (section.generatedOffset.generatedLine === generatedPosition.line\n             ? section.generatedOffset.generatedColumn - 1\n             : 0)\n        };\n        return ret;\n      }\n    }\n\n    return {\n      line: null,\n      column: null\n    };\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nIndexedSourceMapConsumer.prototype._parseMappings =\n  function IndexedSourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    this.__generatedMappings = [];\n    this.__originalMappings = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n      var sectionMappings = section.consumer._generatedMappings;\n      for (var j = 0; j < sectionMappings.length; j++) {\n        var mapping = sectionMappings[j];\n\n        var source = section.consumer._sources.at(mapping.source);\n        if (section.consumer.sourceRoot !== null) {\n          source = util.join(section.consumer.sourceRoot, source);\n        }\n        this._sources.add(source);\n        source = this._sources.indexOf(source);\n\n        var name = section.consumer._names.at(mapping.name);\n        this._names.add(name);\n        name = this._names.indexOf(name);\n\n        // The mappings coming from the consumer for the section have\n        // generated positions relative to the start of the section, so we\n        // need to offset them to be relative to the start of the concatenated\n        // generated file.\n        var adjustedMapping = {\n          source: source,\n          generatedLine: mapping.generatedLine +\n            (section.generatedOffset.generatedLine - 1),\n          generatedColumn: mapping.generatedColumn +\n            (section.generatedOffset.generatedLine === mapping.generatedLine\n            ? section.generatedOffset.generatedColumn - 1\n            : 0),\n          originalLine: mapping.originalLine,\n          originalColumn: mapping.originalColumn,\n          name: name\n        };\n\n        this.__generatedMappings.push(adjustedMapping);\n        if (typeof adjustedMapping.originalLine === 'number') {\n          this.__originalMappings.push(adjustedMapping);\n        }\n      }\n    }\n\n    quickSort(this.__generatedMappings, util.compareByGeneratedPositionsDeflated);\n    quickSort(this.__originalMappings, util.compareByOriginalPositions);\n  };\n\nexports.IndexedSourceMapConsumer = IndexedSourceMapConsumer;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar base64VLQ = require('./base64-vlq');\nvar util = require('./util');\nvar ArraySet = require('./array-set').ArraySet;\nvar MappingList = require('./mapping-list').MappingList;\n\n/**\n * An instance of the SourceMapGenerator represents a source map which is\n * being built incrementally. You may pass an object with the following\n * properties:\n *\n *   - file: The filename of the generated source.\n *   - sourceRoot: A root for all relative URLs in this source map.\n */\nfunction SourceMapGenerator(aArgs) {\n  if (!aArgs) {\n    aArgs = {};\n  }\n  this._file = util.getArg(aArgs, 'file', null);\n  this._sourceRoot = util.getArg(aArgs, 'sourceRoot', null);\n  this._skipValidation = util.getArg(aArgs, 'skipValidation', false);\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n  this._mappings = new MappingList();\n  this._sourcesContents = null;\n}\n\nSourceMapGenerator.prototype._version = 3;\n\n/**\n * Creates a new SourceMapGenerator based on a SourceMapConsumer\n *\n * @param aSourceMapConsumer The SourceMap.\n */\nSourceMapGenerator.fromSourceMap =\n  function SourceMapGenerator_fromSourceMap(aSourceMapConsumer) {\n    var sourceRoot = aSourceMapConsumer.sourceRoot;\n    var generator = new SourceMapGenerator({\n      file: aSourceMapConsumer.file,\n      sourceRoot: sourceRoot\n    });\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      var newMapping = {\n        generated: {\n          line: mapping.generatedLine,\n          column: mapping.generatedColumn\n        }\n      };\n\n      if (mapping.source != null) {\n        newMapping.source = mapping.source;\n        if (sourceRoot != null) {\n          newMapping.source = util.relative(sourceRoot, newMapping.source);\n        }\n\n        newMapping.original = {\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        };\n\n        if (mapping.name != null) {\n          newMapping.name = mapping.name;\n        }\n      }\n\n      generator.addMapping(newMapping);\n    });\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        generator.setSourceContent(sourceFile, content);\n      }\n    });\n    return generator;\n  };\n\n/**\n * Add a single mapping from original source line and column to the generated\n * source's line and column for this source map being created. The mapping\n * object should have the following properties:\n *\n *   - generated: An object with the generated line and column positions.\n *   - original: An object with the original line and column positions.\n *   - source: The original source file (relative to the sourceRoot).\n *   - name: An optional original token name for this mapping.\n */\nSourceMapGenerator.prototype.addMapping =\n  function SourceMapGenerator_addMapping(aArgs) {\n    var generated = util.getArg(aArgs, 'generated');\n    var original = util.getArg(aArgs, 'original', null);\n    var source = util.getArg(aArgs, 'source', null);\n    var name = util.getArg(aArgs, 'name', null);\n\n    if (!this._skipValidation) {\n      this._validateMapping(generated, original, source, name);\n    }\n\n    if (source != null) {\n      source = String(source);\n      if (!this._sources.has(source)) {\n        this._sources.add(source);\n      }\n    }\n\n    if (name != null) {\n      name = String(name);\n      if (!this._names.has(name)) {\n        this._names.add(name);\n      }\n    }\n\n    this._mappings.add({\n      generatedLine: generated.line,\n      generatedColumn: generated.column,\n      originalLine: original != null && original.line,\n      originalColumn: original != null && original.column,\n      source: source,\n      name: name\n    });\n  };\n\n/**\n * Set the source content for a source file.\n */\nSourceMapGenerator.prototype.setSourceContent =\n  function SourceMapGenerator_setSourceContent(aSourceFile, aSourceContent) {\n    var source = aSourceFile;\n    if (this._sourceRoot != null) {\n      source = util.relative(this._sourceRoot, source);\n    }\n\n    if (aSourceContent != null) {\n      // Add the source content to the _sourcesContents map.\n      // Create a new _sourcesContents map if the property is null.\n      if (!this._sourcesContents) {\n        this._sourcesContents = Object.create(null);\n      }\n      this._sourcesContents[util.toSetString(source)] = aSourceContent;\n    } else if (this._sourcesContents) {\n      // Remove the source file from the _sourcesContents map.\n      // If the _sourcesContents map is empty, set the property to null.\n      delete this._sourcesContents[util.toSetString(source)];\n      if (Object.keys(this._sourcesContents).length === 0) {\n        this._sourcesContents = null;\n      }\n    }\n  };\n\n/**\n * Applies the mappings of a sub-source-map for a specific source file to the\n * source map being generated. Each mapping to the supplied source file is\n * rewritten using the supplied source map. Note: The resolution for the\n * resulting mappings is the minimium of this map and the supplied map.\n *\n * @param aSourceMapConsumer The source map to be applied.\n * @param aSourceFile Optional. The filename of the source file.\n *        If omitted, SourceMapConsumer's file property will be used.\n * @param aSourceMapPath Optional. The dirname of the path to the source map\n *        to be applied. If relative, it is relative to the SourceMapConsumer.\n *        This parameter is needed when the two source maps aren't in the same\n *        directory, and the source map to be applied contains relative source\n *        paths. If so, those relative source paths need to be rewritten\n *        relative to the SourceMapGenerator.\n */\nSourceMapGenerator.prototype.applySourceMap =\n  function SourceMapGenerator_applySourceMap(aSourceMapConsumer, aSourceFile, aSourceMapPath) {\n    var sourceFile = aSourceFile;\n    // If aSourceFile is omitted, we will use the file property of the SourceMap\n    if (aSourceFile == null) {\n      if (aSourceMapConsumer.file == null) {\n        throw new Error(\n          'SourceMapGenerator.prototype.applySourceMap requires either an explicit source file, ' +\n          'or the source map\\'s \"file\" property. Both were omitted.'\n        );\n      }\n      sourceFile = aSourceMapConsumer.file;\n    }\n    var sourceRoot = this._sourceRoot;\n    // Make \"sourceFile\" relative if an absolute Url is passed.\n    if (sourceRoot != null) {\n      sourceFile = util.relative(sourceRoot, sourceFile);\n    }\n    // Applying the SourceMap can add and remove items from the sources and\n    // the names array.\n    var newSources = new ArraySet();\n    var newNames = new ArraySet();\n\n    // Find mappings for the \"sourceFile\"\n    this._mappings.unsortedForEach(function (mapping) {\n      if (mapping.source === sourceFile && mapping.originalLine != null) {\n        // Check if it can be mapped by the source map, then update the mapping.\n        var original = aSourceMapConsumer.originalPositionFor({\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        });\n        if (original.source != null) {\n          // Copy mapping\n          mapping.source = original.source;\n          if (aSourceMapPath != null) {\n            mapping.source = util.join(aSourceMapPath, mapping.source)\n          }\n          if (sourceRoot != null) {\n            mapping.source = util.relative(sourceRoot, mapping.source);\n          }\n          mapping.originalLine = original.line;\n          mapping.originalColumn = original.column;\n          if (original.name != null) {\n            mapping.name = original.name;\n          }\n        }\n      }\n\n      var source = mapping.source;\n      if (source != null && !newSources.has(source)) {\n        newSources.add(source);\n      }\n\n      var name = mapping.name;\n      if (name != null && !newNames.has(name)) {\n        newNames.add(name);\n      }\n\n    }, this);\n    this._sources = newSources;\n    this._names = newNames;\n\n    // Copy sourcesContents of applied map.\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aSourceMapPath != null) {\n          sourceFile = util.join(aSourceMapPath, sourceFile);\n        }\n        if (sourceRoot != null) {\n          sourceFile = util.relative(sourceRoot, sourceFile);\n        }\n        this.setSourceContent(sourceFile, content);\n      }\n    }, this);\n  };\n\n/**\n * A mapping can have one of the three levels of data:\n *\n *   1. Just the generated position.\n *   2. The Generated position, original position, and original source.\n *   3. Generated and original position, original source, as well as a name\n *      token.\n *\n * To maintain consistency, we validate that any new mapping being added falls\n * in to one of these categories.\n */\nSourceMapGenerator.prototype._validateMapping =\n  function SourceMapGenerator_validateMapping(aGenerated, aOriginal, aSource,\n                                              aName) {\n    // When aOriginal is truthy but has empty values for .line and .column,\n    // it is most likely a programmer error. In this case we throw a very\n    // specific error message to try to guide them the right way.\n    // For example: https://github.com/Polymer/polymer-bundler/pull/519\n    if (aOriginal && typeof aOriginal.line !== 'number' && typeof aOriginal.column !== 'number') {\n        throw new Error(\n            'original.line and original.column are not numbers -- you probably meant to omit ' +\n            'the original mapping entirely and only map the generated position. If so, pass ' +\n            'null for the original mapping instead of an object with empty or null values.'\n        );\n    }\n\n    if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n        && aGenerated.line > 0 && aGenerated.column >= 0\n        && !aOriginal && !aSource && !aName) {\n      // Case 1.\n      return;\n    }\n    else if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n             && aOriginal && 'line' in aOriginal && 'column' in aOriginal\n             && aGenerated.line > 0 && aGenerated.column >= 0\n             && aOriginal.line > 0 && aOriginal.column >= 0\n             && aSource) {\n      // Cases 2 and 3.\n      return;\n    }\n    else {\n      throw new Error('Invalid mapping: ' + JSON.stringify({\n        generated: aGenerated,\n        source: aSource,\n        original: aOriginal,\n        name: aName\n      }));\n    }\n  };\n\n/**\n * Serialize the accumulated mappings in to the stream of base 64 VLQs\n * specified by the source map format.\n */\nSourceMapGenerator.prototype._serializeMappings =\n  function SourceMapGenerator_serializeMappings() {\n    var previousGeneratedColumn = 0;\n    var previousGeneratedLine = 1;\n    var previousOriginalColumn = 0;\n    var previousOriginalLine = 0;\n    var previousName = 0;\n    var previousSource = 0;\n    var result = '';\n    var next;\n    var mapping;\n    var nameIdx;\n    var sourceIdx;\n\n    var mappings = this._mappings.toArray();\n    for (var i = 0, len = mappings.length; i < len; i++) {\n      mapping = mappings[i];\n      next = ''\n\n      if (mapping.generatedLine !== previousGeneratedLine) {\n        previousGeneratedColumn = 0;\n        while (mapping.generatedLine !== previousGeneratedLine) {\n          next += ';';\n          previousGeneratedLine++;\n        }\n      }\n      else {\n        if (i > 0) {\n          if (!util.compareByGeneratedPositionsInflated(mapping, mappings[i - 1])) {\n            continue;\n          }\n          next += ',';\n        }\n      }\n\n      next += base64VLQ.encode(mapping.generatedColumn\n                                 - previousGeneratedColumn);\n      previousGeneratedColumn = mapping.generatedColumn;\n\n      if (mapping.source != null) {\n        sourceIdx = this._sources.indexOf(mapping.source);\n        next += base64VLQ.encode(sourceIdx - previousSource);\n        previousSource = sourceIdx;\n\n        // lines are stored 0-based in SourceMap spec version 3\n        next += base64VLQ.encode(mapping.originalLine - 1\n                                   - previousOriginalLine);\n        previousOriginalLine = mapping.originalLine - 1;\n\n        next += base64VLQ.encode(mapping.originalColumn\n                                   - previousOriginalColumn);\n        previousOriginalColumn = mapping.originalColumn;\n\n        if (mapping.name != null) {\n          nameIdx = this._names.indexOf(mapping.name);\n          next += base64VLQ.encode(nameIdx - previousName);\n          previousName = nameIdx;\n        }\n      }\n\n      result += next;\n    }\n\n    return result;\n  };\n\nSourceMapGenerator.prototype._generateSourcesContent =\n  function SourceMapGenerator_generateSourcesContent(aSources, aSourceRoot) {\n    return aSources.map(function (source) {\n      if (!this._sourcesContents) {\n        return null;\n      }\n      if (aSourceRoot != null) {\n        source = util.relative(aSourceRoot, source);\n      }\n      var key = util.toSetString(source);\n      return Object.prototype.hasOwnProperty.call(this._sourcesContents, key)\n        ? this._sourcesContents[key]\n        : null;\n    }, this);\n  };\n\n/**\n * Externalize the source map.\n */\nSourceMapGenerator.prototype.toJSON =\n  function SourceMapGenerator_toJSON() {\n    var map = {\n      version: this._version,\n      sources: this._sources.toArray(),\n      names: this._names.toArray(),\n      mappings: this._serializeMappings()\n    };\n    if (this._file != null) {\n      map.file = this._file;\n    }\n    if (this._sourceRoot != null) {\n      map.sourceRoot = this._sourceRoot;\n    }\n    if (this._sourcesContents) {\n      map.sourcesContent = this._generateSourcesContent(map.sources, map.sourceRoot);\n    }\n\n    return map;\n  };\n\n/**\n * Render the source map being generated to a string.\n */\nSourceMapGenerator.prototype.toString =\n  function SourceMapGenerator_toString() {\n    return JSON.stringify(this.toJSON());\n  };\n\nexports.SourceMapGenerator = SourceMapGenerator;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar SourceMapGenerator = require('./source-map-generator').SourceMapGenerator;\nvar util = require('./util');\n\n// Matches a Windows-style `\\r\\n` newline or a `\\n` newline used by all other\n// operating systems these days (capturing the result).\nvar REGEX_NEWLINE = /(\\r?\\n)/;\n\n// Newline character code for charCodeAt() comparisons\nvar NEWLINE_CODE = 10;\n\n// Private symbol for identifying `SourceNode`s when multiple versions of\n// the source-map library are loaded. This MUST NOT CHANGE across\n// versions!\nvar isSourceNode = \"$$$isSourceNode$$$\";\n\n/**\n * SourceNodes provide a way to abstract over interpolating/concatenating\n * snippets of generated JavaScript source code while maintaining the line and\n * column information associated with the original source code.\n *\n * @param aLine The original line number.\n * @param aColumn The original column number.\n * @param aSource The original source's filename.\n * @param aChunks Optional. An array of strings which are snippets of\n *        generated JS, or other SourceNodes.\n * @param aName The original identifier.\n */\nfunction SourceNode(aLine, aColumn, aSource, aChunks, aName) {\n  this.children = [];\n  this.sourceContents = {};\n  this.line = aLine == null ? null : aLine;\n  this.column = aColumn == null ? null : aColumn;\n  this.source = aSource == null ? null : aSource;\n  this.name = aName == null ? null : aName;\n  this[isSourceNode] = true;\n  if (aChunks != null) this.add(aChunks);\n}\n\n/**\n * Creates a SourceNode from generated code and a SourceMapConsumer.\n *\n * @param aGeneratedCode The generated code\n * @param aSourceMapConsumer The SourceMap for the generated code\n * @param aRelativePath Optional. The path that relative sources in the\n *        SourceMapConsumer should be relative to.\n */\nSourceNode.fromStringWithSourceMap =\n  function SourceNode_fromStringWithSourceMap(aGeneratedCode, aSourceMapConsumer, aRelativePath) {\n    // The SourceNode we want to fill with the generated code\n    // and the SourceMap\n    var node = new SourceNode();\n\n    // All even indices of this array are one line of the generated code,\n    // while all odd indices are the newlines between two adjacent lines\n    // (since `REGEX_NEWLINE` captures its match).\n    // Processed fragments are accessed by calling `shiftNextLine`.\n    var remainingLines = aGeneratedCode.split(REGEX_NEWLINE);\n    var remainingLinesIndex = 0;\n    var shiftNextLine = function() {\n      var lineContents = getNextLine();\n      // The last line of a file might not have a newline.\n      var newLine = getNextLine() || \"\";\n      return lineContents + newLine;\n\n      function getNextLine() {\n        return remainingLinesIndex < remainingLines.length ?\n            remainingLines[remainingLinesIndex++] : undefined;\n      }\n    };\n\n    // We need to remember the position of \"remainingLines\"\n    var lastGeneratedLine = 1, lastGeneratedColumn = 0;\n\n    // The generate SourceNodes we need a code range.\n    // To extract it current and last mapping is used.\n    // Here we store the last mapping.\n    var lastMapping = null;\n\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      if (lastMapping !== null) {\n        // We add the code from \"lastMapping\" to \"mapping\":\n        // First check if there is a new line in between.\n        if (lastGeneratedLine < mapping.generatedLine) {\n          // Associate first line with \"lastMapping\"\n          addMappingWithCode(lastMapping, shiftNextLine());\n          lastGeneratedLine++;\n          lastGeneratedColumn = 0;\n          // The remaining code is added without mapping\n        } else {\n          // There is no new line in between.\n          // Associate the code between \"lastGeneratedColumn\" and\n          // \"mapping.generatedColumn\" with \"lastMapping\"\n          var nextLine = remainingLines[remainingLinesIndex];\n          var code = nextLine.substr(0, mapping.generatedColumn -\n                                        lastGeneratedColumn);\n          remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn -\n                                              lastGeneratedColumn);\n          lastGeneratedColumn = mapping.generatedColumn;\n          addMappingWithCode(lastMapping, code);\n          // No more remaining code, continue\n          lastMapping = mapping;\n          return;\n        }\n      }\n      // We add the generated code until the first mapping\n      // to the SourceNode without any mapping.\n      // Each line is added as separate string.\n      while (lastGeneratedLine < mapping.generatedLine) {\n        node.add(shiftNextLine());\n        lastGeneratedLine++;\n      }\n      if (lastGeneratedColumn < mapping.generatedColumn) {\n        var nextLine = remainingLines[remainingLinesIndex];\n        node.add(nextLine.substr(0, mapping.generatedColumn));\n        remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn);\n        lastGeneratedColumn = mapping.generatedColumn;\n      }\n      lastMapping = mapping;\n    }, this);\n    // We have processed all mappings.\n    if (remainingLinesIndex < remainingLines.length) {\n      if (lastMapping) {\n        // Associate the remaining code in the current line with \"lastMapping\"\n        addMappingWithCode(lastMapping, shiftNextLine());\n      }\n      // and add the remaining lines without any mapping\n      node.add(remainingLines.splice(remainingLinesIndex).join(\"\"));\n    }\n\n    // Copy sourcesContent into SourceNode\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aRelativePath != null) {\n          sourceFile = util.join(aRelativePath, sourceFile);\n        }\n        node.setSourceContent(sourceFile, content);\n      }\n    });\n\n    return node;\n\n    function addMappingWithCode(mapping, code) {\n      if (mapping === null || mapping.source === undefined) {\n        node.add(code);\n      } else {\n        var source = aRelativePath\n          ? util.join(aRelativePath, mapping.source)\n          : mapping.source;\n        node.add(new SourceNode(mapping.originalLine,\n                                mapping.originalColumn,\n                                source,\n                                code,\n                                mapping.name));\n      }\n    }\n  };\n\n/**\n * Add a chunk of generated JS to this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.add = function SourceNode_add(aChunk) {\n  if (Array.isArray(aChunk)) {\n    aChunk.forEach(function (chunk) {\n      this.add(chunk);\n    }, this);\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    if (aChunk) {\n      this.children.push(aChunk);\n    }\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Add a chunk of generated JS to the beginning of this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.prepend = function SourceNode_prepend(aChunk) {\n  if (Array.isArray(aChunk)) {\n    for (var i = aChunk.length-1; i >= 0; i--) {\n      this.prepend(aChunk[i]);\n    }\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    this.children.unshift(aChunk);\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Walk over the tree of JS snippets in this node and its children. The\n * walking function is called once for each snippet of JS and is passed that\n * snippet and the its original associated source's line/column location.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walk = function SourceNode_walk(aFn) {\n  var chunk;\n  for (var i = 0, len = this.children.length; i < len; i++) {\n    chunk = this.children[i];\n    if (chunk[isSourceNode]) {\n      chunk.walk(aFn);\n    }\n    else {\n      if (chunk !== '') {\n        aFn(chunk, { source: this.source,\n                     line: this.line,\n                     column: this.column,\n                     name: this.name });\n      }\n    }\n  }\n};\n\n/**\n * Like `String.prototype.join` except for SourceNodes. Inserts `aStr` between\n * each of `this.children`.\n *\n * @param aSep The separator.\n */\nSourceNode.prototype.join = function SourceNode_join(aSep) {\n  var newChildren;\n  var i;\n  var len = this.children.length;\n  if (len > 0) {\n    newChildren = [];\n    for (i = 0; i < len-1; i++) {\n      newChildren.push(this.children[i]);\n      newChildren.push(aSep);\n    }\n    newChildren.push(this.children[i]);\n    this.children = newChildren;\n  }\n  return this;\n};\n\n/**\n * Call String.prototype.replace on the very right-most source snippet. Useful\n * for trimming whitespace from the end of a source node, etc.\n *\n * @param aPattern The pattern to replace.\n * @param aReplacement The thing to replace the pattern with.\n */\nSourceNode.prototype.replaceRight = function SourceNode_replaceRight(aPattern, aReplacement) {\n  var lastChild = this.children[this.children.length - 1];\n  if (lastChild[isSourceNode]) {\n    lastChild.replaceRight(aPattern, aReplacement);\n  }\n  else if (typeof lastChild === 'string') {\n    this.children[this.children.length - 1] = lastChild.replace(aPattern, aReplacement);\n  }\n  else {\n    this.children.push(''.replace(aPattern, aReplacement));\n  }\n  return this;\n};\n\n/**\n * Set the source content for a source file. This will be added to the SourceMapGenerator\n * in the sourcesContent field.\n *\n * @param aSourceFile The filename of the source file\n * @param aSourceContent The content of the source file\n */\nSourceNode.prototype.setSourceContent =\n  function SourceNode_setSourceContent(aSourceFile, aSourceContent) {\n    this.sourceContents[util.toSetString(aSourceFile)] = aSourceContent;\n  };\n\n/**\n * Walk over the tree of SourceNodes. The walking function is called for each\n * source file content and is passed the filename and source content.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walkSourceContents =\n  function SourceNode_walkSourceContents(aFn) {\n    for (var i = 0, len = this.children.length; i < len; i++) {\n      if (this.children[i][isSourceNode]) {\n        this.children[i].walkSourceContents(aFn);\n      }\n    }\n\n    var sources = Object.keys(this.sourceContents);\n    for (var i = 0, len = sources.length; i < len; i++) {\n      aFn(util.fromSetString(sources[i]), this.sourceContents[sources[i]]);\n    }\n  };\n\n/**\n * Return the string representation of this source node. Walks over the tree\n * and concatenates all the various snippets together to one string.\n */\nSourceNode.prototype.toString = function SourceNode_toString() {\n  var str = \"\";\n  this.walk(function (chunk) {\n    str += chunk;\n  });\n  return str;\n};\n\n/**\n * Returns the string representation of this source node along with a source\n * map.\n */\nSourceNode.prototype.toStringWithSourceMap = function SourceNode_toStringWithSourceMap(aArgs) {\n  var generated = {\n    code: \"\",\n    line: 1,\n    column: 0\n  };\n  var map = new SourceMapGenerator(aArgs);\n  var sourceMappingActive = false;\n  var lastOriginalSource = null;\n  var lastOriginalLine = null;\n  var lastOriginalColumn = null;\n  var lastOriginalName = null;\n  this.walk(function (chunk, original) {\n    generated.code += chunk;\n    if (original.source !== null\n        && original.line !== null\n        && original.column !== null) {\n      if(lastOriginalSource !== original.source\n         || lastOriginalLine !== original.line\n         || lastOriginalColumn !== original.column\n         || lastOriginalName !== original.name) {\n        map.addMapping({\n          source: original.source,\n          original: {\n            line: original.line,\n            column: original.column\n          },\n          generated: {\n            line: generated.line,\n            column: generated.column\n          },\n          name: original.name\n        });\n      }\n      lastOriginalSource = original.source;\n      lastOriginalLine = original.line;\n      lastOriginalColumn = original.column;\n      lastOriginalName = original.name;\n      sourceMappingActive = true;\n    } else if (sourceMappingActive) {\n      map.addMapping({\n        generated: {\n          line: generated.line,\n          column: generated.column\n        }\n      });\n      lastOriginalSource = null;\n      sourceMappingActive = false;\n    }\n    for (var idx = 0, length = chunk.length; idx < length; idx++) {\n      if (chunk.charCodeAt(idx) === NEWLINE_CODE) {\n        generated.line++;\n        generated.column = 0;\n        // Mappings end at eol\n        if (idx + 1 === length) {\n          lastOriginalSource = null;\n          sourceMappingActive = false;\n        } else if (sourceMappingActive) {\n          map.addMapping({\n            source: original.source,\n            original: {\n              line: original.line,\n              column: original.column\n            },\n            generated: {\n              line: generated.line,\n              column: generated.column\n            },\n            name: original.name\n          });\n        }\n      } else {\n        generated.column++;\n      }\n    }\n  });\n  this.walkSourceContents(function (sourceFile, sourceContent) {\n    map.setSourceContent(sourceFile, sourceContent);\n  });\n\n  return { code: generated.code, map: map };\n};\n\nexports.SourceNode = SourceNode;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/**\n * This is a helper function for getting values from parameter/options\n * objects.\n *\n * @param args The object we are extracting values from\n * @param name The name of the property we are getting.\n * @param defaultValue An optional value to return if the property is missing\n * from the object. If this is not specified and the property is missing, an\n * error will be thrown.\n */\nfunction getArg(aArgs, aName, aDefaultValue) {\n  if (aName in aArgs) {\n    return aArgs[aName];\n  } else if (arguments.length === 3) {\n    return aDefaultValue;\n  } else {\n    throw new Error('\"' + aName + '\" is a required argument.');\n  }\n}\nexports.getArg = getArg;\n\nvar urlRegexp = /^(?:([\\w+\\-.]+):)?\\/\\/(?:(\\w+:\\w+)@)?([\\w.]*)(?::(\\d+))?(\\S*)$/;\nvar dataUrlRegexp = /^data:.+\\,.+$/;\n\nfunction urlParse(aUrl) {\n  var match = aUrl.match(urlRegexp);\n  if (!match) {\n    return null;\n  }\n  return {\n    scheme: match[1],\n    auth: match[2],\n    host: match[3],\n    port: match[4],\n    path: match[5]\n  };\n}\nexports.urlParse = urlParse;\n\nfunction urlGenerate(aParsedUrl) {\n  var url = '';\n  if (aParsedUrl.scheme) {\n    url += aParsedUrl.scheme + ':';\n  }\n  url += '//';\n  if (aParsedUrl.auth) {\n    url += aParsedUrl.auth + '@';\n  }\n  if (aParsedUrl.host) {\n    url += aParsedUrl.host;\n  }\n  if (aParsedUrl.port) {\n    url += \":\" + aParsedUrl.port\n  }\n  if (aParsedUrl.path) {\n    url += aParsedUrl.path;\n  }\n  return url;\n}\nexports.urlGenerate = urlGenerate;\n\n/**\n * Normalizes a path, or the path portion of a URL:\n *\n * - Replaces consecutive slashes with one slash.\n * - Removes unnecessary '.' parts.\n * - Removes unnecessary '<dir>/..' parts.\n *\n * Based on code in the Node.js 'path' core module.\n *\n * @param aPath The path or url to normalize.\n */\nfunction normalize(aPath) {\n  var path = aPath;\n  var url = urlParse(aPath);\n  if (url) {\n    if (!url.path) {\n      return aPath;\n    }\n    path = url.path;\n  }\n  var isAbsolute = exports.isAbsolute(path);\n\n  var parts = path.split(/\\/+/);\n  for (var part, up = 0, i = parts.length - 1; i >= 0; i--) {\n    part = parts[i];\n    if (part === '.') {\n      parts.splice(i, 1);\n    } else if (part === '..') {\n      up++;\n    } else if (up > 0) {\n      if (part === '') {\n        // The first part is blank if the path is absolute. Trying to go\n        // above the root is a no-op. Therefore we can remove all '..' parts\n        // directly after the root.\n        parts.splice(i + 1, up);\n        up = 0;\n      } else {\n        parts.splice(i, 2);\n        up--;\n      }\n    }\n  }\n  path = parts.join('/');\n\n  if (path === '') {\n    path = isAbsolute ? '/' : '.';\n  }\n\n  if (url) {\n    url.path = path;\n    return urlGenerate(url);\n  }\n  return path;\n}\nexports.normalize = normalize;\n\n/**\n * Joins two paths/URLs.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be joined with the root.\n *\n * - If aPath is a URL or a data URI, aPath is returned, unless aPath is a\n *   scheme-relative URL: Then the scheme of aRoot, if any, is prepended\n *   first.\n * - Otherwise aPath is a path. If aRoot is a URL, then its path portion\n *   is updated with the result and aRoot is returned. Otherwise the result\n *   is returned.\n *   - If aPath is absolute, the result is aPath.\n *   - Otherwise the two paths are joined with a slash.\n * - Joining for example 'http://' and 'www.example.com' is also supported.\n */\nfunction join(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n  if (aPath === \"\") {\n    aPath = \".\";\n  }\n  var aPathUrl = urlParse(aPath);\n  var aRootUrl = urlParse(aRoot);\n  if (aRootUrl) {\n    aRoot = aRootUrl.path || '/';\n  }\n\n  // `join(foo, '//www.example.org')`\n  if (aPathUrl && !aPathUrl.scheme) {\n    if (aRootUrl) {\n      aPathUrl.scheme = aRootUrl.scheme;\n    }\n    return urlGenerate(aPathUrl);\n  }\n\n  if (aPathUrl || aPath.match(dataUrlRegexp)) {\n    return aPath;\n  }\n\n  // `join('http://', 'www.example.com')`\n  if (aRootUrl && !aRootUrl.host && !aRootUrl.path) {\n    aRootUrl.host = aPath;\n    return urlGenerate(aRootUrl);\n  }\n\n  var joined = aPath.charAt(0) === '/'\n    ? aPath\n    : normalize(aRoot.replace(/\\/+$/, '') + '/' + aPath);\n\n  if (aRootUrl) {\n    aRootUrl.path = joined;\n    return urlGenerate(aRootUrl);\n  }\n  return joined;\n}\nexports.join = join;\n\nexports.isAbsolute = function (aPath) {\n  return aPath.charAt(0) === '/' || !!aPath.match(urlRegexp);\n};\n\n/**\n * Make a path relative to a URL or another path.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be made relative to aRoot.\n */\nfunction relative(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n\n  aRoot = aRoot.replace(/\\/$/, '');\n\n  // It is possible for the path to be above the root. In this case, simply\n  // checking whether the root is a prefix of the path won't work. Instead, we\n  // need to remove components from the root one by one, until either we find\n  // a prefix that fits, or we run out of components to remove.\n  var level = 0;\n  while (aPath.indexOf(aRoot + '/') !== 0) {\n    var index = aRoot.lastIndexOf(\"/\");\n    if (index < 0) {\n      return aPath;\n    }\n\n    // If the only part of the root that is left is the scheme (i.e. http://,\n    // file:///, etc.), one or more slashes (/), or simply nothing at all, we\n    // have exhausted all components, so the path is not relative to the root.\n    aRoot = aRoot.slice(0, index);\n    if (aRoot.match(/^([^\\/]+:\\/)?\\/*$/)) {\n      return aPath;\n    }\n\n    ++level;\n  }\n\n  // Make sure we add a \"../\" for each component we removed from the root.\n  return Array(level + 1).join(\"../\") + aPath.substr(aRoot.length + 1);\n}\nexports.relative = relative;\n\nvar supportsNullProto = (function () {\n  var obj = Object.create(null);\n  return !('__proto__' in obj);\n}());\n\nfunction identity (s) {\n  return s;\n}\n\n/**\n * Because behavior goes wacky when you set `__proto__` on objects, we\n * have to prefix all the strings in our set with an arbitrary character.\n *\n * See https://github.com/mozilla/source-map/pull/31 and\n * https://github.com/mozilla/source-map/issues/30\n *\n * @param String aStr\n */\nfunction toSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return '$' + aStr;\n  }\n\n  return aStr;\n}\nexports.toSetString = supportsNullProto ? identity : toSetString;\n\nfunction fromSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return aStr.slice(1);\n  }\n\n  return aStr;\n}\nexports.fromSetString = supportsNullProto ? identity : fromSetString;\n\nfunction isProtoString(s) {\n  if (!s) {\n    return false;\n  }\n\n  var length = s.length;\n\n  if (length < 9 /* \"__proto__\".length */) {\n    return false;\n  }\n\n  if (s.charCodeAt(length - 1) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 2) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 3) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 4) !== 116 /* 't' */ ||\n      s.charCodeAt(length - 5) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 6) !== 114 /* 'r' */ ||\n      s.charCodeAt(length - 7) !== 112 /* 'p' */ ||\n      s.charCodeAt(length - 8) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 9) !== 95  /* '_' */) {\n    return false;\n  }\n\n  for (var i = length - 10; i >= 0; i--) {\n    if (s.charCodeAt(i) !== 36 /* '$' */) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Comparator between two mappings where the original positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same original source/line/column, but different generated\n * line and column the same. Useful when searching for a mapping with a\n * stubbed out mapping.\n */\nfunction compareByOriginalPositions(mappingA, mappingB, onlyCompareOriginal) {\n  var cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0 || onlyCompareOriginal) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByOriginalPositions = compareByOriginalPositions;\n\n/**\n * Comparator between two mappings with deflated source and name indices where\n * the generated positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same generated line and column, but different\n * source/name/original line and column the same. Useful when searching for a\n * mapping with a stubbed out mapping.\n */\nfunction compareByGeneratedPositionsDeflated(mappingA, mappingB, onlyCompareGenerated) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0 || onlyCompareGenerated) {\n    return cmp;\n  }\n\n  cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByGeneratedPositionsDeflated = compareByGeneratedPositionsDeflated;\n\nfunction strcmp(aStr1, aStr2) {\n  if (aStr1 === aStr2) {\n    return 0;\n  }\n\n  if (aStr1 > aStr2) {\n    return 1;\n  }\n\n  return -1;\n}\n\n/**\n * Comparator between two mappings with inflated source and name strings where\n * the generated positions are compared.\n */\nfunction compareByGeneratedPositionsInflated(mappingA, mappingB) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsInflated = compareByGeneratedPositionsInflated;\n","\n\"use strict\";\n\nvar algorithm = require('./lib/algorithm');\nvar Hash = require('./lib/Hash');\nvar register = require('./lib/register');\n\nexports.sum = algorithm.sum.bind(algorithm);\nexports.roll = algorithm.roll.bind(algorithm);\nexports.Hash = Hash;\nexports.register = register;\n","module.exports.createFsAdapter = () => {\n    const FsAdapter = require(\"./lib/FsAdapter\");\n    return new FsAdapter();\n};","\nconst ArchiveConfigurator = require(\"./lib/ArchiveConfigurator\");\nconst createFolderBrickStorage = require(\"./lib/FolderBrickStorage\").createFolderBrickStorage;\nconst createFileBrickStorage = require(\"./lib/FileBrickStorage\").createFileBrickStorage;\n\nArchiveConfigurator.prototype.registerStorageProvider(\"FolderBrickStorage\", createFolderBrickStorage);\nArchiveConfigurator.prototype.registerStorageProvider(\"FileBrickStorage\", createFileBrickStorage);\n\nmodule.exports.ArchiveConfigurator = ArchiveConfigurator;\nmodule.exports.createBrick = (config) => {\n    const Brick = require(\"./lib/Brick\");\n    return new Brick(config);\n};\n\nmodule.exports.createArchive = (archiveConfigurator) => {\n    const Archive = require(\"./lib/Archive\");\n    return new Archive(archiveConfigurator);\n};\nmodule.exports.createArchiveConfigurator = () => {\n    return new ArchiveConfigurator();\n};\n\nmodule.exports.createBarMap = (header) => {\n    const BarMap = require(\"./lib/FolderBarMap\");\n    return new BarMap(header);\n};\n\nmodule.exports.Seed = require('./lib/Seed');\nmodule.exports.createFolderBrickStorage = createFolderBrickStorage;\nmodule.exports.createFileBrickStorage = createFileBrickStorage;\n","var toString = Object.prototype.toString\n\nvar isModern = (\n  typeof Buffer.alloc === 'function' &&\n  typeof Buffer.allocUnsafe === 'function' &&\n  typeof Buffer.from === 'function'\n)\n\nfunction isArrayBuffer (input) {\n  return toString.call(input).slice(8, -1) === 'ArrayBuffer'\n}\n\nfunction fromArrayBuffer (obj, byteOffset, length) {\n  byteOffset >>>= 0\n\n  var maxLength = obj.byteLength - byteOffset\n\n  if (maxLength < 0) {\n    throw new RangeError(\"'offset' is out of bounds\")\n  }\n\n  if (length === undefined) {\n    length = maxLength\n  } else {\n    length >>>= 0\n\n    if (length > maxLength) {\n      throw new RangeError(\"'length' is out of bounds\")\n    }\n  }\n\n  return isModern\n    ? Buffer.from(obj.slice(byteOffset, byteOffset + length))\n    : new Buffer(new Uint8Array(obj.slice(byteOffset, byteOffset + length)))\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  return isModern\n    ? Buffer.from(string, encoding)\n    : new Buffer(string, encoding)\n}\n\nfunction bufferFrom (value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (isArrayBuffer(value)) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  return isModern\n    ? Buffer.from(value)\n    : new Buffer(value)\n}\n\nmodule.exports = bufferFrom\n","module.exports.create = (endpoint) => {\n    const EDFSBrickStorage = require(\"./EDFSBrickStorage\");\n    return new EDFSBrickStorage(endpoint)\n};\n","require(\"./brickTransportStrategies/brickTransportStrategiesRegistry\");\nconst constants = require(\"./moduleConstants\");\n\nconst or = require(\"overwrite-require\");\nconst browserContexts = [or.constants.SERVICE_WORKER_ENVIRONMENT_TYPE];\nconst cache = require('psk-cache').factory();\n\nif (browserContexts.indexOf($$.environmentType) !== -1) {\n    $$.brickTransportStrategiesRegistry.add(\"http\", require(\"./brickTransportStrategies/FetchBrickTransportStrategy\"));\n} else {\n    $$.brickTransportStrategiesRegistry.add(\"http\", require(\"./brickTransportStrategies/HTTPBrickTransportStrategy\"));\n}\n\nmodule.exports = {\n    attachToEndpoint(endpoint) {\n        const EDFS = require(\"./lib/EDFS\");\n        return new EDFS(endpoint, {\n            cache\n        });\n    },\n    attachWithSeed(compactSeed, callback) {\n        const SEED = require(\"bar\").Seed;\n        let seed;\n        try {\n            seed = new SEED(compactSeed);\n        } catch (err) {\n            return callback(err);\n        }\n\n        callback(undefined, this.attachToEndpoint(seed.getEndpoint()));\n    },\n    attachWithPassword(password, callback) {\n        require(\"./seedCage\").getSeed(password, (err, seed) => {\n            if (err) {\n                return callback(err);\n            }\n\n            this.attachWithSeed(seed, callback);\n        });\n    },\n    checkForSeedCage(callback) {\n        require(\"./seedCage\").check(callback);\n    },\n    constants: constants\n};\n","/*\n require and $$.require are overwriting the node.js defaults in loading modules for increasing security, speed and making it work to the privatesky runtime build with browserify.\n The privatesky code for domains should work in node and browsers.\n */\nfunction enableForEnvironment(envType){\n\n    const moduleConstants = require(\"./moduleConstants\");\n\n    /**\n     * Used to provide autocomplete for $$ variables\n     * @classdesc Interface for $$ object\n     *\n     * @name $$\n     * @class\n     *\n     */\n\n    switch (envType) {\n        case moduleConstants.BROWSER_ENVIRONMENT_TYPE :\n            global = window;\n            break;\n        case moduleConstants.SERVICE_WORKER_ENVIRONMENT_TYPE:\n            global = self;\n            break;\n    }\n\n    if (typeof(global.$$) == \"undefined\") {\n        /**\n         * Used to provide autocomplete for $$ variables\n         * @type {$$}\n         */\n        global.$$ = {};\n    }\n\n    if (typeof($$.__global) == \"undefined\") {\n        $$.__global = {};\n    }\n\n    Object.defineProperty($$, \"environmentType\", {\n        get: function(){\n            return envType;\n        },\n        set: function (value) {\n            throw Error(\"Environment type already set!\");\n        }\n    });\n\n\n    if (typeof($$.__global.requireLibrariesNames) == \"undefined\") {\n        $$.__global.currentLibraryName = null;\n        $$.__global.requireLibrariesNames = {};\n    }\n\n\n    if (typeof($$.__runtimeModules) == \"undefined\") {\n        $$.__runtimeModules = {};\n    }\n\n\n    if (typeof(global.functionUndefined) == \"undefined\") {\n        global.functionUndefined = function () {\n            console.log(\"Called of an undefined function!!!!\");\n            throw new Error(\"Called of an undefined function\");\n        };\n        if (typeof(global.webshimsRequire) == \"undefined\") {\n            global.webshimsRequire = global.functionUndefined;\n        }\n\n        if (typeof(global.domainRequire) == \"undefined\") {\n            global.domainRequire = global.functionUndefined;\n        }\n\n        if (typeof(global.pskruntimeRequire) == \"undefined\") {\n            global.pskruntimeRequire = global.functionUndefined;\n        }\n    }\n\n    const pastRequests = {};\n\n    function preventRecursiveRequire(request) {\n        if (pastRequests[request]) {\n            const err = new Error(\"Preventing recursive require for \" + request);\n            err.type = \"PSKIgnorableError\";\n            throw err;\n        }\n\n    }\n\n    function disableRequire(request) {\n        pastRequests[request] = true;\n    }\n\n    function enableRequire(request) {\n        pastRequests[request] = false;\n    }\n\n    function requireFromCache(request) {\n        const existingModule = $$.__runtimeModules[request];\n        return existingModule;\n    }\n\n    function wrapStep(callbackName) {\n        const callback = global[callbackName];\n\n        if (callback === undefined) {\n            return null;\n        }\n\n        if (callback === global.functionUndefined) {\n            return null;\n        }\n\n        return function (request) {\n            const result = callback(request);\n            $$.__runtimeModules[request] = result;\n            return result;\n        }\n    }\n\n\n    function tryRequireSequence(originalRequire, request) {\n        let arr;\n        if (originalRequire) {\n            arr = $$.__requireFunctionsChain.slice();\n            arr.push(originalRequire);\n        } else {\n            arr = $$.__requireFunctionsChain;\n        }\n\n        preventRecursiveRequire(request);\n        disableRequire(request);\n        let result;\n        const previousRequire = $$.__global.currentLibraryName;\n        let previousRequireChanged = false;\n\n        if (!previousRequire) {\n            // console.log(\"Loading library for require\", request);\n            $$.__global.currentLibraryName = request;\n\n            if (typeof $$.__global.requireLibrariesNames[request] == \"undefined\") {\n                $$.__global.requireLibrariesNames[request] = {};\n                //$$.__global.requireLibrariesDescriptions[request]   = {};\n            }\n            previousRequireChanged = true;\n        }\n        for (let i = 0; i < arr.length; i++) {\n            const func = arr[i];\n            try {\n\n                if (func === global.functionUndefined) continue;\n                result = func(request);\n\n                if (result) {\n                    break;\n                }\n\n            } catch (err) {\n                if (err.type !== \"PSKIgnorableError\") {\n                    //$$.err(\"Require encountered an error while loading \", request, \"\\nCause:\\n\", err.stack);\n                }\n            }\n        }\n\n        if (!result) {\n            $$.log(\"Failed to load module \", request, result);\n        }\n\n        enableRequire(request);\n        if (previousRequireChanged) {\n            //console.log(\"End loading library for require\", request, $$.__global.requireLibrariesNames[request]);\n            $$.__global.currentLibraryName = null;\n        }\n        return result;\n    }\n\n    function makeBrowserRequire(){\n        console.log(\"Defining global require in browser\");\n\n\n        global.require = function (request) {\n\n            ///*[requireFromCache, wrapStep(webshimsRequire), , wrapStep(pskruntimeRequire), wrapStep(domainRequire)*]\n            return tryRequireSequence(null, request);\n        }\n    }\n\n    function makeIsolateRequire(){\n        // require should be provided when code is loaded in browserify\n        const bundleRequire = require;\n\n        $$.requireBundle('sandboxBase');\n        // this should be set up by sandbox prior to\n        const sandboxRequire = global.require;\n        const cryptoModuleName = 'crypto';\n        global.crypto = require(cryptoModuleName);\n\n        function newLoader(request) {\n            // console.log(\"newLoader:\", request);\n            //preventRecursiveRequire(request);\n            const self = this;\n\n            // console.log('trying to load ', request);\n\n            function tryBundleRequire(...args) {\n                //return $$.__originalRequire.apply(self,args);\n                //return Module._load.apply(self,args)\n                let res;\n                try {\n                    res = sandboxRequire.apply(self, args);\n                } catch (err) {\n                    if (err.code === \"MODULE_NOT_FOUND\") {\n                        const p = path.join(process.cwd(), request);\n                        res = sandboxRequire.apply(self, [p]);\n                        request = p;\n                    } else {\n                        throw err;\n                    }\n                }\n                return res;\n            }\n\n            let res;\n\n\n            res = tryRequireSequence(tryBundleRequire, request);\n\n\n            return res;\n        }\n\n        global.require = newLoader;\n    }\n\n    function makeNodeJSRequire(){\n        const pathModuleName = 'path';\n        const path = require(pathModuleName);\n        const cryptoModuleName = 'crypto';\n        const utilModuleName = 'util';\n        $$.__runtimeModules[\"crypto\"] = require(cryptoModuleName);\n        $$.__runtimeModules[\"util\"] = require(utilModuleName);\n\n        const moduleModuleName = 'module';\n        const Module = require(moduleModuleName);\n        $$.__runtimeModules[\"module\"] = Module;\n\n        console.log(\"Redefining require for node\");\n\n        $$.__originalRequire = Module._load;\n        const moduleOriginalRequire = Module.prototype.require;\n\n        function newLoader(request) {\n            // console.log(\"newLoader:\", request);\n            //preventRecursiveRequire(request);\n            const self = this;\n\n            function originalRequire(...args) {\n                //return $$.__originalRequire.apply(self,args);\n                //return Module._load.apply(self,args)\n                let res;\n                try {\n                    res = moduleOriginalRequire.apply(self, args);\n                } catch (err) {\n                    if (err.code === \"MODULE_NOT_FOUND\") {\n                        let pathOrName = request;\n                        if(pathOrName.startsWith('/') || pathOrName.startsWith('./') || pathOrName.startsWith('../')){\n                            pathOrName = path.join(process.cwd(), request);\n                        }\n                        res = moduleOriginalRequire.call(self, pathOrName);\n                        request = pathOrName;\n                    } else {\n                        throw err;\n                    }\n                }\n                return res;\n            }\n\n            function currentFolderRequire(request) {\n                return\n            }\n\n            //[requireFromCache, wrapStep(pskruntimeRequire), wrapStep(domainRequire), originalRequire]\n            return tryRequireSequence(originalRequire, request);\n        }\n\n        Module.prototype.require = newLoader;\n        return newLoader;\n    }\n\n    require(\"./standardGlobalSymbols.js\");\n\n    if (typeof($$.require) == \"undefined\") {\n\n        $$.__requireList = [\"webshimsRequire\"];\n        $$.__requireFunctionsChain = [];\n\n        $$.requireBundle = function (name) {\n            name += \"Require\";\n            $$.__requireList.push(name);\n            const arr = [requireFromCache];\n            $$.__requireList.forEach(function (item) {\n                const callback = wrapStep(item);\n                if (callback) {\n                    arr.push(callback);\n                }\n            });\n\n            $$.__requireFunctionsChain = arr;\n        };\n\n        $$.requireBundle(\"init\");\n\n        switch ($$.environmentType) {\n            case moduleConstants.BROWSER_ENVIRONMENT_TYPE:\n                makeBrowserRequire();\n                $$.require = require;\n                break;\n            case moduleConstants.SERVICE_WORKER_ENVIRONMENT_TYPE:\n                makeBrowserRequire();\n                $$.require = require;\n                break;\n            case moduleConstants.ISOLATE_ENVIRONMENT_TYPE:\n                makeIsolateRequire();\n                $$.require = require;\n                break;\n            default:\n               $$.require = makeNodeJSRequire();\n        }\n\n    }\n};\n\n\n\nmodule.exports = {\n    enableForEnvironment,\n    constants: require(\"./moduleConstants\")\n};\n","const Cache = require(\"./lib/Cache\")\nlet cacheInstance;\n\nmodule.exports = {\n\n    /**\n     * Create a new cache instance\n     *\n     * @param {object} options\n     * @param {Number} options.maxLevels Number of storage levels. Defaults to 3\n     * @param {Number} options.limit Number of max items the cache can store per level.\n     *                               Defaults to 1000\n     * @return {Cache}\n     */\n    factory: function (options) {\n        return new Cache(options);\n    },\n\n    /**\n     * Get a reference to a singleton cache instance\n     *\n     * @param {object} options\n     * @param {Number} options.maxLevels Number of storage levels. Defaults to 3\n     * @param {Number} options.limit Number of max items the cache can store per level.\n     *                               Defaults to 1000\n     * @return {Cache}\n     */\n    getDefaultInstance: function (options) {\n        if (!cacheInstance) {\n            cacheInstance = new Cache(options);\n        }\n\n        return cacheInstance;\n    }\n};\n","//to look nice the requireModule on Node\nrequire(\"./lib/psk-abstract-client\");\nconst or = require('overwrite-require');\nif ($$.environmentType === or.constants.BROWSER_ENVIRONMENT_TYPE) {\n\trequire(\"./lib/psk-browser-client\");\n} else {\n\trequire(\"./lib/psk-node-client\");\n}","const PskCrypto = require(\"./lib/PskCrypto\");\nconst ssutil = require(\"./signsensusDS/ssutil\");\n\nmodule.exports = PskCrypto;\n\nmodule.exports.hashValues = ssutil.hashValues;\n\nmodule.exports.DuplexStream = require(\"./lib/utils/DuplexStream\");\n\nmodule.exports.isStream = require(\"./lib/utils/isStream\");","var SourceMapConsumer = require('source-map').SourceMapConsumer;\nvar path = require('path');\n\nvar fs;\ntry {\n  fs = require('fs');\n  if (!fs.existsSync || !fs.readFileSync) {\n    // fs doesn't have all methods we need\n    fs = null;\n  }\n} catch (err) {\n  /* nop */\n}\n\nvar bufferFrom = require('buffer-from');\n\n/**\n * Requires a module which is protected against bundler minification.\n *\n * @param {NodeModule} mod\n * @param {string} request\n */\nfunction dynamicRequire(mod, request) {\n  return mod.require(request);\n}\n\n// Only install once if called multiple times\nvar errorFormatterInstalled = false;\nvar uncaughtShimInstalled = false;\n\n// If true, the caches are reset before a stack trace formatting operation\nvar emptyCacheBetweenOperations = false;\n\n// Supports {browser, node, auto}\nvar environment = \"auto\";\n\n// Maps a file path to a string containing the file contents\nvar fileContentsCache = {};\n\n// Maps a file path to a source map for that file\nvar sourceMapCache = {};\n\n// Regex for detecting source maps\nvar reSourceMap = /^data:application\\/json[^,]+base64,/;\n\n// Priority list of retrieve handlers\nvar retrieveFileHandlers = [];\nvar retrieveMapHandlers = [];\n\nfunction isInBrowser() {\n  if (environment === \"browser\")\n    return true;\n  if (environment === \"node\")\n    return false;\n  return ((typeof window !== 'undefined') && (typeof XMLHttpRequest === 'function') && !(window.require && window.module && window.process && window.process.type === \"renderer\"));\n}\n\nfunction hasGlobalProcessEventEmitter() {\n  return ((typeof process === 'object') && (process !== null) && (typeof process.on === 'function'));\n}\n\nfunction handlerExec(list) {\n  return function(arg) {\n    for (var i = 0; i < list.length; i++) {\n      var ret = list[i](arg);\n      if (ret) {\n        return ret;\n      }\n    }\n    return null;\n  };\n}\n\nvar retrieveFile = handlerExec(retrieveFileHandlers);\n\nretrieveFileHandlers.push(function(path) {\n  // Trim the path to make sure there is no extra whitespace.\n  path = path.trim();\n  if (/^file:/.test(path)) {\n    // existsSync/readFileSync can't handle file protocol, but once stripped, it works\n    path = path.replace(/file:\\/\\/\\/(\\w:)?/, function(protocol, drive) {\n      return drive ?\n        '' : // file:///C:/dir/file -> C:/dir/file\n        '/'; // file:///root-dir/file -> /root-dir/file\n    });\n  }\n  if (path in fileContentsCache) {\n    return fileContentsCache[path];\n  }\n\n  var contents = '';\n  try {\n    if (!fs) {\n      // Use SJAX if we are in the browser\n      var xhr = new XMLHttpRequest();\n      xhr.open('GET', path, /** async */ false);\n      xhr.send(null);\n      if (xhr.readyState === 4 && xhr.status === 200) {\n        contents = xhr.responseText;\n      }\n    } else if (fs.existsSync(path)) {\n      // Otherwise, use the filesystem\n      contents = fs.readFileSync(path, 'utf8');\n    }\n  } catch (er) {\n    /* ignore any errors */\n  }\n\n  return fileContentsCache[path] = contents;\n});\n\n// Support URLs relative to a directory, but be careful about a protocol prefix\n// in case we are in the browser (i.e. directories may start with \"http://\" or \"file:///\")\nfunction supportRelativeURL(file, url) {\n  if (!file) return url;\n  var dir = path.dirname(file);\n  var match = /^\\w+:\\/\\/[^\\/]*/.exec(dir);\n  var protocol = match ? match[0] : '';\n  var startPath = dir.slice(protocol.length);\n  if (protocol && /^\\/\\w\\:/.test(startPath)) {\n    // handle file:///C:/ paths\n    protocol += '/';\n    return protocol + path.resolve(dir.slice(protocol.length), url).replace(/\\\\/g, '/');\n  }\n  return protocol + path.resolve(dir.slice(protocol.length), url);\n}\n\nfunction retrieveSourceMapURL(source) {\n  var fileData;\n\n  if (isInBrowser()) {\n     try {\n       var xhr = new XMLHttpRequest();\n       xhr.open('GET', source, false);\n       xhr.send(null);\n       fileData = xhr.readyState === 4 ? xhr.responseText : null;\n\n       // Support providing a sourceMappingURL via the SourceMap header\n       var sourceMapHeader = xhr.getResponseHeader(\"SourceMap\") ||\n                             xhr.getResponseHeader(\"X-SourceMap\");\n       if (sourceMapHeader) {\n         return sourceMapHeader;\n       }\n     } catch (e) {\n     }\n  }\n\n  // Get the URL of the source map\n  fileData = retrieveFile(source);\n  var re = /(?:\\/\\/[@#][\\s]*sourceMappingURL=([^\\s'\"]+)[\\s]*$)|(?:\\/\\*[@#][\\s]*sourceMappingURL=([^\\s*'\"]+)[\\s]*(?:\\*\\/)[\\s]*$)/mg;\n  // Keep executing the search to find the *last* sourceMappingURL to avoid\n  // picking up sourceMappingURLs from comments, strings, etc.\n  var lastMatch, match;\n  while (match = re.exec(fileData)) lastMatch = match;\n  if (!lastMatch) return null;\n  return lastMatch[1];\n};\n\n// Can be overridden by the retrieveSourceMap option to install. Takes a\n// generated source filename; returns a {map, optional url} object, or null if\n// there is no source map.  The map field may be either a string or the parsed\n// JSON object (ie, it must be a valid argument to the SourceMapConsumer\n// constructor).\nvar retrieveSourceMap = handlerExec(retrieveMapHandlers);\nretrieveMapHandlers.push(function(source) {\n  var sourceMappingURL = retrieveSourceMapURL(source);\n  if (!sourceMappingURL) return null;\n\n  // Read the contents of the source map\n  var sourceMapData;\n  if (reSourceMap.test(sourceMappingURL)) {\n    // Support source map URL as a data url\n    var rawData = sourceMappingURL.slice(sourceMappingURL.indexOf(',') + 1);\n    sourceMapData = bufferFrom(rawData, \"base64\").toString();\n    sourceMappingURL = source;\n  } else {\n    // Support source map URLs relative to the source URL\n    sourceMappingURL = supportRelativeURL(source, sourceMappingURL);\n    sourceMapData = retrieveFile(sourceMappingURL);\n  }\n\n  if (!sourceMapData) {\n    return null;\n  }\n\n  return {\n    url: sourceMappingURL,\n    map: sourceMapData\n  };\n});\n\nfunction mapSourcePosition(position) {\n  var sourceMap = sourceMapCache[position.source];\n  if (!sourceMap) {\n    // Call the (overrideable) retrieveSourceMap function to get the source map.\n    var urlAndMap = retrieveSourceMap(position.source);\n    if (urlAndMap) {\n      sourceMap = sourceMapCache[position.source] = {\n        url: urlAndMap.url,\n        map: new SourceMapConsumer(urlAndMap.map)\n      };\n\n      // Load all sources stored inline with the source map into the file cache\n      // to pretend like they are already loaded. They may not exist on disk.\n      if (sourceMap.map.sourcesContent) {\n        sourceMap.map.sources.forEach(function(source, i) {\n          var contents = sourceMap.map.sourcesContent[i];\n          if (contents) {\n            var url = supportRelativeURL(sourceMap.url, source);\n            fileContentsCache[url] = contents;\n          }\n        });\n      }\n    } else {\n      sourceMap = sourceMapCache[position.source] = {\n        url: null,\n        map: null\n      };\n    }\n  }\n\n  // Resolve the source URL relative to the URL of the source map\n  if (sourceMap && sourceMap.map && typeof sourceMap.map.originalPositionFor === 'function') {\n    var originalPosition = sourceMap.map.originalPositionFor(position);\n\n    // Only return the original position if a matching line was found. If no\n    // matching line is found then we return position instead, which will cause\n    // the stack trace to print the path and line for the compiled file. It is\n    // better to give a precise location in the compiled file than a vague\n    // location in the original file.\n    if (originalPosition.source !== null) {\n      originalPosition.source = supportRelativeURL(\n        sourceMap.url, originalPosition.source);\n      return originalPosition;\n    }\n  }\n\n  return position;\n}\n\n// Parses code generated by FormatEvalOrigin(), a function inside V8:\n// https://code.google.com/p/v8/source/browse/trunk/src/messages.js\nfunction mapEvalOrigin(origin) {\n  // Most eval() calls are in this format\n  var match = /^eval at ([^(]+) \\((.+):(\\d+):(\\d+)\\)$/.exec(origin);\n  if (match) {\n    var position = mapSourcePosition({\n      source: match[2],\n      line: +match[3],\n      column: match[4] - 1\n    });\n    return 'eval at ' + match[1] + ' (' + position.source + ':' +\n      position.line + ':' + (position.column + 1) + ')';\n  }\n\n  // Parse nested eval() calls using recursion\n  match = /^eval at ([^(]+) \\((.+)\\)$/.exec(origin);\n  if (match) {\n    return 'eval at ' + match[1] + ' (' + mapEvalOrigin(match[2]) + ')';\n  }\n\n  // Make sure we still return useful information if we didn't find anything\n  return origin;\n}\n\n// This is copied almost verbatim from the V8 source code at\n// https://code.google.com/p/v8/source/browse/trunk/src/messages.js. The\n// implementation of wrapCallSite() used to just forward to the actual source\n// code of CallSite.prototype.toString but unfortunately a new release of V8\n// did something to the prototype chain and broke the shim. The only fix I\n// could find was copy/paste.\nfunction CallSiteToString() {\n  var fileName;\n  var fileLocation = \"\";\n  if (this.isNative()) {\n    fileLocation = \"native\";\n  } else {\n    fileName = this.getScriptNameOrSourceURL();\n    if (!fileName && this.isEval()) {\n      fileLocation = this.getEvalOrigin();\n      fileLocation += \", \";  // Expecting source position to follow.\n    }\n\n    if (fileName) {\n      fileLocation += fileName;\n    } else {\n      // Source code does not originate from a file and is not native, but we\n      // can still get the source position inside the source string, e.g. in\n      // an eval string.\n      fileLocation += \"<anonymous>\";\n    }\n    var lineNumber = this.getLineNumber();\n    if (lineNumber != null) {\n      fileLocation += \":\" + lineNumber;\n      var columnNumber = this.getColumnNumber();\n      if (columnNumber) {\n        fileLocation += \":\" + columnNumber;\n      }\n    }\n  }\n\n  var line = \"\";\n  var functionName = this.getFunctionName();\n  var addSuffix = true;\n  var isConstructor = this.isConstructor();\n  var isMethodCall = !(this.isToplevel() || isConstructor);\n  if (isMethodCall) {\n    var typeName = this.getTypeName();\n    // Fixes shim to be backward compatable with Node v0 to v4\n    if (typeName === \"[object Object]\") {\n      typeName = \"null\";\n    }\n    var methodName = this.getMethodName();\n    if (functionName) {\n      if (typeName && functionName.indexOf(typeName) != 0) {\n        line += typeName + \".\";\n      }\n      line += functionName;\n      if (methodName && functionName.indexOf(\".\" + methodName) != functionName.length - methodName.length - 1) {\n        line += \" [as \" + methodName + \"]\";\n      }\n    } else {\n      line += typeName + \".\" + (methodName || \"<anonymous>\");\n    }\n  } else if (isConstructor) {\n    line += \"new \" + (functionName || \"<anonymous>\");\n  } else if (functionName) {\n    line += functionName;\n  } else {\n    line += fileLocation;\n    addSuffix = false;\n  }\n  if (addSuffix) {\n    line += \" (\" + fileLocation + \")\";\n  }\n  return line;\n}\n\nfunction cloneCallSite(frame) {\n  var object = {};\n  Object.getOwnPropertyNames(Object.getPrototypeOf(frame)).forEach(function(name) {\n    object[name] = /^(?:is|get)/.test(name) ? function() { return frame[name].call(frame); } : frame[name];\n  });\n  object.toString = CallSiteToString;\n  return object;\n}\n\nfunction wrapCallSite(frame, state) {\n  // provides interface backward compatibility\n  if (state === undefined) {\n    state = { nextPosition: null, curPosition: null }\n  }\n  if(frame.isNative()) {\n    state.curPosition = null;\n    return frame;\n  }\n\n  // Most call sites will return the source file from getFileName(), but code\n  // passed to eval() ending in \"//# sourceURL=...\" will return the source file\n  // from getScriptNameOrSourceURL() instead\n  var source = frame.getFileName() || frame.getScriptNameOrSourceURL();\n  if (source) {\n    var line = frame.getLineNumber();\n    var column = frame.getColumnNumber() - 1;\n\n    // Fix position in Node where some (internal) code is prepended.\n    // See https://github.com/evanw/node-source-map-support/issues/36\n    // Header removed in node at ^10.16 || >=11.11.0\n    // v11 is not an LTS candidate, we can just test the one version with it.\n    // Test node versions for: 10.16-19, 10.20+, 12-19, 20-99, 100+, or 11.11\n    var noHeader = /^v(10\\.1[6-9]|10\\.[2-9][0-9]|10\\.[0-9]{3,}|1[2-9]\\d*|[2-9]\\d|\\d{3,}|11\\.11)/;\n    var headerLength = noHeader.test(process.version) ? 0 : 62;\n    if (line === 1 && column > headerLength && !isInBrowser() && !frame.isEval()) {\n      column -= headerLength;\n    }\n\n    var position = mapSourcePosition({\n      source: source,\n      line: line,\n      column: column\n    });\n    state.curPosition = position;\n    frame = cloneCallSite(frame);\n    var originalFunctionName = frame.getFunctionName;\n    frame.getFunctionName = function() {\n      if (state.nextPosition == null) {\n        return originalFunctionName();\n      }\n      return state.nextPosition.name || originalFunctionName();\n    };\n    frame.getFileName = function() { return position.source; };\n    frame.getLineNumber = function() { return position.line; };\n    frame.getColumnNumber = function() { return position.column + 1; };\n    frame.getScriptNameOrSourceURL = function() { return position.source; };\n    return frame;\n  }\n\n  // Code called using eval() needs special handling\n  var origin = frame.isEval() && frame.getEvalOrigin();\n  if (origin) {\n    origin = mapEvalOrigin(origin);\n    frame = cloneCallSite(frame);\n    frame.getEvalOrigin = function() { return origin; };\n    return frame;\n  }\n\n  // If we get here then we were unable to change the source position\n  return frame;\n}\n\n// This function is part of the V8 stack trace API, for more info see:\n// https://v8.dev/docs/stack-trace-api\nfunction prepareStackTrace(error, stack) {\n  if (emptyCacheBetweenOperations) {\n    fileContentsCache = {};\n    sourceMapCache = {};\n  }\n\n  var name = error.name || 'Error';\n  var message = error.message || '';\n  var errorString = name + \": \" + message;\n\n  var state = { nextPosition: null, curPosition: null };\n  var processedStack = [];\n  for (var i = stack.length - 1; i >= 0; i--) {\n    processedStack.push('\\n    at ' + wrapCallSite(stack[i], state));\n    state.nextPosition = state.curPosition;\n  }\n  state.curPosition = state.nextPosition = null;\n  return errorString + processedStack.reverse().join('');\n}\n\n// Generate position and snippet of original source with pointer\nfunction getErrorSource(error) {\n  var match = /\\n    at [^(]+ \\((.*):(\\d+):(\\d+)\\)/.exec(error.stack);\n  if (match) {\n    var source = match[1];\n    var line = +match[2];\n    var column = +match[3];\n\n    // Support the inline sourceContents inside the source map\n    var contents = fileContentsCache[source];\n\n    // Support files on disk\n    if (!contents && fs && fs.existsSync(source)) {\n      try {\n        contents = fs.readFileSync(source, 'utf8');\n      } catch (er) {\n        contents = '';\n      }\n    }\n\n    // Format the line from the original source code like node does\n    if (contents) {\n      var code = contents.split(/(?:\\r\\n|\\r|\\n)/)[line - 1];\n      if (code) {\n        return source + ':' + line + '\\n' + code + '\\n' +\n          new Array(column).join(' ') + '^';\n      }\n    }\n  }\n  return null;\n}\n\nfunction printErrorAndExit (error) {\n  var source = getErrorSource(error);\n\n  // Ensure error is printed synchronously and not truncated\n  if (process.stderr._handle && process.stderr._handle.setBlocking) {\n    process.stderr._handle.setBlocking(true);\n  }\n\n  if (source) {\n    console.error();\n    console.error(source);\n  }\n\n  console.error(error.stack);\n  process.exit(1);\n}\n\nfunction shimEmitUncaughtException () {\n  var origEmit = process.emit;\n\n  process.emit = function (type) {\n    if (type === 'uncaughtException') {\n      var hasStack = (arguments[1] && arguments[1].stack);\n      var hasListeners = (this.listeners(type).length > 0);\n\n      if (hasStack && !hasListeners) {\n        return printErrorAndExit(arguments[1]);\n      }\n    }\n\n    return origEmit.apply(this, arguments);\n  };\n}\n\nvar originalRetrieveFileHandlers = retrieveFileHandlers.slice(0);\nvar originalRetrieveMapHandlers = retrieveMapHandlers.slice(0);\n\nexports.wrapCallSite = wrapCallSite;\nexports.getErrorSource = getErrorSource;\nexports.mapSourcePosition = mapSourcePosition;\nexports.retrieveSourceMap = retrieveSourceMap;\n\nexports.install = function(options) {\n  options = options || {};\n\n  if (options.environment) {\n    environment = options.environment;\n    if ([\"node\", \"browser\", \"auto\"].indexOf(environment) === -1) {\n      throw new Error(\"environment \" + environment + \" was unknown. Available options are {auto, browser, node}\")\n    }\n  }\n\n  // Allow sources to be found by methods other than reading the files\n  // directly from disk.\n  if (options.retrieveFile) {\n    if (options.overrideRetrieveFile) {\n      retrieveFileHandlers.length = 0;\n    }\n\n    retrieveFileHandlers.unshift(options.retrieveFile);\n  }\n\n  // Allow source maps to be found by methods other than reading the files\n  // directly from disk.\n  if (options.retrieveSourceMap) {\n    if (options.overrideRetrieveSourceMap) {\n      retrieveMapHandlers.length = 0;\n    }\n\n    retrieveMapHandlers.unshift(options.retrieveSourceMap);\n  }\n\n  // Support runtime transpilers that include inline source maps\n  if (options.hookRequire && !isInBrowser()) {\n    // Use dynamicRequire to avoid including in browser bundles\n    var Module = dynamicRequire(module, 'module');\n    var $compile = Module.prototype._compile;\n\n    if (!$compile.__sourceMapSupport) {\n      Module.prototype._compile = function(content, filename) {\n        fileContentsCache[filename] = content;\n        sourceMapCache[filename] = undefined;\n        return $compile.call(this, content, filename);\n      };\n\n      Module.prototype._compile.__sourceMapSupport = true;\n    }\n  }\n\n  // Configure options\n  if (!emptyCacheBetweenOperations) {\n    emptyCacheBetweenOperations = 'emptyCacheBetweenOperations' in options ?\n      options.emptyCacheBetweenOperations : false;\n  }\n\n  // Install the error reformatter\n  if (!errorFormatterInstalled) {\n    errorFormatterInstalled = true;\n    Error.prepareStackTrace = prepareStackTrace;\n  }\n\n  if (!uncaughtShimInstalled) {\n    var installHandler = 'handleUncaughtExceptions' in options ?\n      options.handleUncaughtExceptions : true;\n\n    // Do not override 'uncaughtException' with our own handler in Node.js\n    // Worker threads. Workers pass the error to the main thread as an event,\n    // rather than printing something to stderr and exiting.\n    try {\n      // We need to use `dynamicRequire` because `require` on it's own will be optimized by WebPack/Browserify.\n      var worker_threads = dynamicRequire(module, 'worker_threads');\n      if (worker_threads.isMainThread === false) {\n        installHandler = false;\n      }\n    } catch(e) {}\n\n    // Provide the option to not install the uncaught exception handler. This is\n    // to support other uncaught exception handlers (in test frameworks, for\n    // example). If this handler is not installed and there are no other uncaught\n    // exception handlers, uncaught exceptions will be caught by node's built-in\n    // exception handler and the process will still be terminated. However, the\n    // generated JavaScript code will be shown above the stack trace instead of\n    // the original source code.\n    if (installHandler && hasGlobalProcessEventEmitter()) {\n      uncaughtShimInstalled = true;\n      shimEmitUncaughtException();\n    }\n  }\n};\n\nexports.resetRetrieveHandlers = function() {\n  retrieveFileHandlers.length = 0;\n  retrieveMapHandlers.length = 0;\n\n  retrieveFileHandlers = originalRetrieveFileHandlers.slice(0);\n  retrieveMapHandlers = originalRetrieveMapHandlers.slice(0);\n\n  retrieveSourceMap = handlerExec(retrieveMapHandlers);\n  retrieveFile = handlerExec(retrieveFileHandlers);\n}\n","/*\n * Copyright 2009-2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE.txt or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\nexports.SourceMapGenerator = require('./lib/source-map-generator').SourceMapGenerator;\nexports.SourceMapConsumer = require('./lib/source-map-consumer').SourceMapConsumer;\nexports.SourceNode = require('./lib/source-node').SourceNode;\n","function boot() {\n    const worker_threads ='worker_threads';\n    const {parentPort, workerData} = require(worker_threads);\n\n    process.on(\"uncaughtException\", (err) => {\n        console.error('unchaughtException inside worker', err);\n        setTimeout(() => {\n            process.exit(1);\n        }, 100);\n    });\n\n    function getSeed(callback){\n        let err;\n        if (!workerData.hasOwnProperty('constitutionSeed') || typeof workerData.constitutionSeed !== \"string\") {\n            err = new Error(`Missing or wrong type of constitutionSeed in worker data configuration: ${JSON.stringify(workerData)}`);\n            if(!callback){\n                throw err;\n            }\n        }\n        if(callback){\n            return callback(err, workerData.constitutionSeed);\n        }\n        return workerData.constitutionSeed;\n    }\n\n    let edfs;\n    function getEDFS(callback){\n        const EDFS = require(\"edfs\");\n        EDFS.attachWithSeed(getSeed(), (err, edfsInst) => {\n            if (err) {\n                return callback(err);\n            }\n\n            edfs = edfsInst;\n            callback(null, edfs);\n        });\n    }\n\n    function initializeSwarmEngine(callback){\n        require('callflow').initialise();\n        const swarmEngine = require('swarm-engine');\n\n        swarmEngine.initialise(process.env.IDENTITY);\n        const powerCord = new swarmEngine.InnerThreadPowerCord();\n\n        $$.swarmEngine.plug($$.swarmEngine.WILD_CARD_IDENTITY, powerCord);\n\n        parentPort.on('message', (packedSwarm) => {\n            powerCord.transfer(packedSwarm);\n        });\n\n        edfs.bootRawDossier(workerData.constitutionSeed, (err, csbhandler) =>{\n            if(err){\n                $$.throwError(err);\n            }\n            callback();\n        });\n    }\n\n    const BootEngine = require(\"./BootEngine.js\");\n\n    const booter = new BootEngine(getSeed, getEDFS, initializeSwarmEngine, [\"pskruntime.js\", \"blockchain.js\"], [\"domain.js\"]);\n\n    booter.boot((err) => {\n        if(err){\n            throw err;\n        }\n        parentPort.postMessage('ready');\n    });\n}\n\nboot();\n//module.exports = boot.toString();\n","module.exports.OwM = require(\"./lib/OwM\");\nmodule.exports.beesHealer = require(\"./lib/beesHealer\");\n\nconst uidGenerator = require(\"./lib/uidGenerator\").createUidGenerator(200, 32);\n\nmodule.exports.safe_uuid = require(\"./lib/safe-uuid\").init(uidGenerator);\n\nmodule.exports.Queue = require(\"./lib/Queue\");\nmodule.exports.combos = require(\"./lib/Combos\");\n\nmodule.exports.uidGenerator = uidGenerator;\nmodule.exports.generateUid = uidGenerator.generateUid;\nmodule.exports.TaskCounter = require(\"./lib/TaskCounter\");\nmodule.exports.SwarmPacker = require(\"./lib/SwarmPacker\");\nmodule.exports.path = require(\"./lib/path\");\nmodule.exports.createPskConsole = function () {\n  return require('./lib/pskconsole');\n};\n\nmodule.exports.pingPongFork = require('./lib/pingpongFork');\n\n\nif(typeof global.$$ == \"undefined\"){\n  global.$$ = {};\n}\n\nif(typeof global.$$.uidGenerator == \"undefined\"){\n    $$.uidGenerator = module.exports.safe_uuid;\n}\n"]}